// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: hdfs.proto

package ds.hdfs;

public final class HdfsProto {
  private HdfsProto() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface OpenFileRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.OpenFileRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string filename = 1;</code>
     * @return Whether the filename field is set.
     */
    boolean hasFilename();
    /**
     * <code>required string filename = 1;</code>
     * @return The filename.
     */
    java.lang.String getFilename();
    /**
     * <code>required string filename = 1;</code>
     * @return The bytes for filename.
     */
    com.google.protobuf.ByteString
        getFilenameBytes();

    /**
     * <code>optional .hdfs.OpenFileRequest.Flag flag = 2 [default = O_RDONLY];</code>
     * @return Whether the flag field is set.
     */
    boolean hasFlag();
    /**
     * <code>optional .hdfs.OpenFileRequest.Flag flag = 2 [default = O_RDONLY];</code>
     * @return The flag.
     */
    ds.hdfs.HdfsProto.OpenFileRequest.Flag getFlag();
  }
  /**
   * <pre>
   *message to open a file with read or write permission
   * </pre>
   *
   * Protobuf type {@code hdfs.OpenFileRequest}
   */
  public  static final class OpenFileRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.OpenFileRequest)
      OpenFileRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use OpenFileRequest.newBuilder() to construct.
    private OpenFileRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private OpenFileRequest() {
      filename_ = "";
      flag_ = 0;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new OpenFileRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private OpenFileRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              filename_ = bs;
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
                @SuppressWarnings("deprecation")
              ds.hdfs.HdfsProto.OpenFileRequest.Flag value = ds.hdfs.HdfsProto.OpenFileRequest.Flag.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000002;
                flag_ = rawValue;
              }
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_OpenFileRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_OpenFileRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.OpenFileRequest.class, ds.hdfs.HdfsProto.OpenFileRequest.Builder.class);
    }

    /**
     * Protobuf enum {@code hdfs.OpenFileRequest.Flag}
     */
    public enum Flag
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <pre>
       *read only
       * </pre>
       *
       * <code>O_RDONLY = 0;</code>
       */
      O_RDONLY(0),
      /**
       * <pre>
       *write and create
       * </pre>
       *
       * <code>O_WRONLY = 1;</code>
       */
      O_WRONLY(1),
      /**
       * <pre>
       *write and update
       * </pre>
       *
       * <code>O_RDWR = 2;</code>
       */
      O_RDWR(2),
      ;

      /**
       * <pre>
       *read only
       * </pre>
       *
       * <code>O_RDONLY = 0;</code>
       */
      public static final int O_RDONLY_VALUE = 0;
      /**
       * <pre>
       *write and create
       * </pre>
       *
       * <code>O_WRONLY = 1;</code>
       */
      public static final int O_WRONLY_VALUE = 1;
      /**
       * <pre>
       *write and update
       * </pre>
       *
       * <code>O_RDWR = 2;</code>
       */
      public static final int O_RDWR_VALUE = 2;


      public final int getNumber() {
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static Flag valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static Flag forNumber(int value) {
        switch (value) {
          case 0: return O_RDONLY;
          case 1: return O_WRONLY;
          case 2: return O_RDWR;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Flag>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          Flag> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Flag>() {
              public Flag findValueByNumber(int number) {
                return Flag.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.OpenFileRequest.getDescriptor().getEnumTypes().get(0);
      }

      private static final Flag[] VALUES = values();

      public static Flag valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Flag(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:hdfs.OpenFileRequest.Flag)
    }

    private int bitField0_;
    public static final int FILENAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object filename_;
    /**
     * <code>required string filename = 1;</code>
     * @return Whether the filename field is set.
     */
    public boolean hasFilename() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string filename = 1;</code>
     * @return The filename.
     */
    public java.lang.String getFilename() {
      java.lang.Object ref = filename_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          filename_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string filename = 1;</code>
     * @return The bytes for filename.
     */
    public com.google.protobuf.ByteString
        getFilenameBytes() {
      java.lang.Object ref = filename_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        filename_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int FLAG_FIELD_NUMBER = 2;
    private int flag_;
    /**
     * <code>optional .hdfs.OpenFileRequest.Flag flag = 2 [default = O_RDONLY];</code>
     * @return Whether the flag field is set.
     */
    public boolean hasFlag() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hdfs.OpenFileRequest.Flag flag = 2 [default = O_RDONLY];</code>
     * @return The flag.
     */
    public ds.hdfs.HdfsProto.OpenFileRequest.Flag getFlag() {
      @SuppressWarnings("deprecation")
      ds.hdfs.HdfsProto.OpenFileRequest.Flag result = ds.hdfs.HdfsProto.OpenFileRequest.Flag.valueOf(flag_);
      return result == null ? ds.hdfs.HdfsProto.OpenFileRequest.Flag.O_RDONLY : result;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasFilename()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, filename_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeEnum(2, flag_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, filename_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, flag_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.OpenFileRequest)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.OpenFileRequest other = (ds.hdfs.HdfsProto.OpenFileRequest) obj;

      if (hasFilename() != other.hasFilename()) return false;
      if (hasFilename()) {
        if (!getFilename()
            .equals(other.getFilename())) return false;
      }
      if (hasFlag() != other.hasFlag()) return false;
      if (hasFlag()) {
        if (flag_ != other.flag_) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFilename()) {
        hash = (37 * hash) + FILENAME_FIELD_NUMBER;
        hash = (53 * hash) + getFilename().hashCode();
      }
      if (hasFlag()) {
        hash = (37 * hash) + FLAG_FIELD_NUMBER;
        hash = (53 * hash) + flag_;
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.OpenFileRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.OpenFileRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.OpenFileRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.OpenFileRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.OpenFileRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.OpenFileRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.OpenFileRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.OpenFileRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.OpenFileRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.OpenFileRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.OpenFileRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.OpenFileRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.OpenFileRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *message to open a file with read or write permission
     * </pre>
     *
     * Protobuf type {@code hdfs.OpenFileRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.OpenFileRequest)
        ds.hdfs.HdfsProto.OpenFileRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_OpenFileRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_OpenFileRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.OpenFileRequest.class, ds.hdfs.HdfsProto.OpenFileRequest.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.OpenFileRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        filename_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        flag_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_OpenFileRequest_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.OpenFileRequest getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.OpenFileRequest.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.OpenFileRequest build() {
        ds.hdfs.HdfsProto.OpenFileRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.OpenFileRequest buildPartial() {
        ds.hdfs.HdfsProto.OpenFileRequest result = new ds.hdfs.HdfsProto.OpenFileRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.filename_ = filename_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          to_bitField0_ |= 0x00000002;
        }
        result.flag_ = flag_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.OpenFileRequest) {
          return mergeFrom((ds.hdfs.HdfsProto.OpenFileRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.OpenFileRequest other) {
        if (other == ds.hdfs.HdfsProto.OpenFileRequest.getDefaultInstance()) return this;
        if (other.hasFilename()) {
          bitField0_ |= 0x00000001;
          filename_ = other.filename_;
          onChanged();
        }
        if (other.hasFlag()) {
          setFlag(other.getFlag());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasFilename()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.OpenFileRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.OpenFileRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object filename_ = "";
      /**
       * <code>required string filename = 1;</code>
       * @return Whether the filename field is set.
       */
      public boolean hasFilename() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string filename = 1;</code>
       * @return The filename.
       */
      public java.lang.String getFilename() {
        java.lang.Object ref = filename_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            filename_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string filename = 1;</code>
       * @return The bytes for filename.
       */
      public com.google.protobuf.ByteString
          getFilenameBytes() {
        java.lang.Object ref = filename_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          filename_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string filename = 1;</code>
       * @param value The filename to set.
       * @return This builder for chaining.
       */
      public Builder setFilename(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        filename_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string filename = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearFilename() {
        bitField0_ = (bitField0_ & ~0x00000001);
        filename_ = getDefaultInstance().getFilename();
        onChanged();
        return this;
      }
      /**
       * <code>required string filename = 1;</code>
       * @param value The bytes for filename to set.
       * @return This builder for chaining.
       */
      public Builder setFilenameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        filename_ = value;
        onChanged();
        return this;
      }

      private int flag_ = 0;
      /**
       * <code>optional .hdfs.OpenFileRequest.Flag flag = 2 [default = O_RDONLY];</code>
       * @return Whether the flag field is set.
       */
      public boolean hasFlag() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hdfs.OpenFileRequest.Flag flag = 2 [default = O_RDONLY];</code>
       * @return The flag.
       */
      public ds.hdfs.HdfsProto.OpenFileRequest.Flag getFlag() {
        @SuppressWarnings("deprecation")
        ds.hdfs.HdfsProto.OpenFileRequest.Flag result = ds.hdfs.HdfsProto.OpenFileRequest.Flag.valueOf(flag_);
        return result == null ? ds.hdfs.HdfsProto.OpenFileRequest.Flag.O_RDONLY : result;
      }
      /**
       * <code>optional .hdfs.OpenFileRequest.Flag flag = 2 [default = O_RDONLY];</code>
       * @param value The flag to set.
       * @return This builder for chaining.
       */
      public Builder setFlag(ds.hdfs.HdfsProto.OpenFileRequest.Flag value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        flag_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hdfs.OpenFileRequest.Flag flag = 2 [default = O_RDONLY];</code>
       * @return This builder for chaining.
       */
      public Builder clearFlag() {
        bitField0_ = (bitField0_ & ~0x00000002);
        flag_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.OpenFileRequest)
    }

    // @@protoc_insertion_point(class_scope:hdfs.OpenFileRequest)
    private static final ds.hdfs.HdfsProto.OpenFileRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.OpenFileRequest();
    }

    public static ds.hdfs.HdfsProto.OpenFileRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<OpenFileRequest>
        PARSER = new com.google.protobuf.AbstractParser<OpenFileRequest>() {
      @java.lang.Override
      public OpenFileRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new OpenFileRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<OpenFileRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<OpenFileRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.OpenFileRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface OpenFileResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.OpenFileResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *On error, -1 is returned
     * </pre>
     *
     * <code>required int32 filedescriptor = 1 [default = -1];</code>
     * @return Whether the filedescriptor field is set.
     */
    boolean hasFiledescriptor();
    /**
     * <pre>
     *On error, -1 is returned
     * </pre>
     *
     * <code>required int32 filedescriptor = 1 [default = -1];</code>
     * @return The filedescriptor.
     */
    int getFiledescriptor();

    /**
     * <pre>
     *If File is for reading, return all blocknumbers
     * </pre>
     *
     * <code>repeated int32 blocknumber = 2;</code>
     * @return A list containing the blocknumber.
     */
    java.util.List<java.lang.Integer> getBlocknumberList();
    /**
     * <pre>
     *If File is for reading, return all blocknumbers
     * </pre>
     *
     * <code>repeated int32 blocknumber = 2;</code>
     * @return The count of blocknumber.
     */
    int getBlocknumberCount();
    /**
     * <pre>
     *If File is for reading, return all blocknumbers
     * </pre>
     *
     * <code>repeated int32 blocknumber = 2;</code>
     * @param index The index of the element to return.
     * @return The blocknumber at the given index.
     */
    int getBlocknumber(int index);
  }
  /**
   * Protobuf type {@code hdfs.OpenFileResponse}
   */
  public  static final class OpenFileResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.OpenFileResponse)
      OpenFileResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use OpenFileResponse.newBuilder() to construct.
    private OpenFileResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private OpenFileResponse() {
      filedescriptor_ = -1;
      blocknumber_ = emptyIntList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new OpenFileResponse();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private OpenFileResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              filedescriptor_ = input.readInt32();
              break;
            }
            case 16: {
              if (!((mutable_bitField0_ & 0x00000002) != 0)) {
                blocknumber_ = newIntList();
                mutable_bitField0_ |= 0x00000002;
              }
              blocknumber_.addInt(input.readInt32());
              break;
            }
            case 18: {
              int length = input.readRawVarint32();
              int limit = input.pushLimit(length);
              if (!((mutable_bitField0_ & 0x00000002) != 0) && input.getBytesUntilLimit() > 0) {
                blocknumber_ = newIntList();
                mutable_bitField0_ |= 0x00000002;
              }
              while (input.getBytesUntilLimit() > 0) {
                blocknumber_.addInt(input.readInt32());
              }
              input.popLimit(limit);
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) != 0)) {
          blocknumber_.makeImmutable(); // C
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_OpenFileResponse_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_OpenFileResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.OpenFileResponse.class, ds.hdfs.HdfsProto.OpenFileResponse.Builder.class);
    }

    private int bitField0_;
    public static final int FILEDESCRIPTOR_FIELD_NUMBER = 1;
    private int filedescriptor_;
    /**
     * <pre>
     *On error, -1 is returned
     * </pre>
     *
     * <code>required int32 filedescriptor = 1 [default = -1];</code>
     * @return Whether the filedescriptor field is set.
     */
    public boolean hasFiledescriptor() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     *On error, -1 is returned
     * </pre>
     *
     * <code>required int32 filedescriptor = 1 [default = -1];</code>
     * @return The filedescriptor.
     */
    public int getFiledescriptor() {
      return filedescriptor_;
    }

    public static final int BLOCKNUMBER_FIELD_NUMBER = 2;
    private com.google.protobuf.Internal.IntList blocknumber_;
    /**
     * <pre>
     *If File is for reading, return all blocknumbers
     * </pre>
     *
     * <code>repeated int32 blocknumber = 2;</code>
     * @return A list containing the blocknumber.
     */
    public java.util.List<java.lang.Integer>
        getBlocknumberList() {
      return blocknumber_;
    }
    /**
     * <pre>
     *If File is for reading, return all blocknumbers
     * </pre>
     *
     * <code>repeated int32 blocknumber = 2;</code>
     * @return The count of blocknumber.
     */
    public int getBlocknumberCount() {
      return blocknumber_.size();
    }
    /**
     * <pre>
     *If File is for reading, return all blocknumbers
     * </pre>
     *
     * <code>repeated int32 blocknumber = 2;</code>
     * @param index The index of the element to return.
     * @return The blocknumber at the given index.
     */
    public int getBlocknumber(int index) {
      return blocknumber_.getInt(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasFiledescriptor()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(1, filedescriptor_);
      }
      for (int i = 0; i < blocknumber_.size(); i++) {
        output.writeInt32(2, blocknumber_.getInt(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, filedescriptor_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < blocknumber_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeInt32SizeNoTag(blocknumber_.getInt(i));
        }
        size += dataSize;
        size += 1 * getBlocknumberList().size();
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.OpenFileResponse)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.OpenFileResponse other = (ds.hdfs.HdfsProto.OpenFileResponse) obj;

      if (hasFiledescriptor() != other.hasFiledescriptor()) return false;
      if (hasFiledescriptor()) {
        if (getFiledescriptor()
            != other.getFiledescriptor()) return false;
      }
      if (!getBlocknumberList()
          .equals(other.getBlocknumberList())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFiledescriptor()) {
        hash = (37 * hash) + FILEDESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getFiledescriptor();
      }
      if (getBlocknumberCount() > 0) {
        hash = (37 * hash) + BLOCKNUMBER_FIELD_NUMBER;
        hash = (53 * hash) + getBlocknumberList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.OpenFileResponse parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.OpenFileResponse parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.OpenFileResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.OpenFileResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.OpenFileResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.OpenFileResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.OpenFileResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.OpenFileResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.OpenFileResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.OpenFileResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.OpenFileResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.OpenFileResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.OpenFileResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hdfs.OpenFileResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.OpenFileResponse)
        ds.hdfs.HdfsProto.OpenFileResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_OpenFileResponse_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_OpenFileResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.OpenFileResponse.class, ds.hdfs.HdfsProto.OpenFileResponse.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.OpenFileResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        filedescriptor_ = -1;
        bitField0_ = (bitField0_ & ~0x00000001);
        blocknumber_ = emptyIntList();
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_OpenFileResponse_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.OpenFileResponse getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.OpenFileResponse.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.OpenFileResponse build() {
        ds.hdfs.HdfsProto.OpenFileResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.OpenFileResponse buildPartial() {
        ds.hdfs.HdfsProto.OpenFileResponse result = new ds.hdfs.HdfsProto.OpenFileResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.filedescriptor_ = filedescriptor_;
        if (((bitField0_ & 0x00000002) != 0)) {
          blocknumber_.makeImmutable();
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.blocknumber_ = blocknumber_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.OpenFileResponse) {
          return mergeFrom((ds.hdfs.HdfsProto.OpenFileResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.OpenFileResponse other) {
        if (other == ds.hdfs.HdfsProto.OpenFileResponse.getDefaultInstance()) return this;
        if (other.hasFiledescriptor()) {
          setFiledescriptor(other.getFiledescriptor());
        }
        if (!other.blocknumber_.isEmpty()) {
          if (blocknumber_.isEmpty()) {
            blocknumber_ = other.blocknumber_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureBlocknumberIsMutable();
            blocknumber_.addAll(other.blocknumber_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasFiledescriptor()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.OpenFileResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.OpenFileResponse) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int filedescriptor_ = -1;
      /**
       * <pre>
       *On error, -1 is returned
       * </pre>
       *
       * <code>required int32 filedescriptor = 1 [default = -1];</code>
       * @return Whether the filedescriptor field is set.
       */
      public boolean hasFiledescriptor() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       *On error, -1 is returned
       * </pre>
       *
       * <code>required int32 filedescriptor = 1 [default = -1];</code>
       * @return The filedescriptor.
       */
      public int getFiledescriptor() {
        return filedescriptor_;
      }
      /**
       * <pre>
       *On error, -1 is returned
       * </pre>
       *
       * <code>required int32 filedescriptor = 1 [default = -1];</code>
       * @param value The filedescriptor to set.
       * @return This builder for chaining.
       */
      public Builder setFiledescriptor(int value) {
        bitField0_ |= 0x00000001;
        filedescriptor_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *On error, -1 is returned
       * </pre>
       *
       * <code>required int32 filedescriptor = 1 [default = -1];</code>
       * @return This builder for chaining.
       */
      public Builder clearFiledescriptor() {
        bitField0_ = (bitField0_ & ~0x00000001);
        filedescriptor_ = -1;
        onChanged();
        return this;
      }

      private com.google.protobuf.Internal.IntList blocknumber_ = emptyIntList();
      private void ensureBlocknumberIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          blocknumber_ = mutableCopy(blocknumber_);
          bitField0_ |= 0x00000002;
         }
      }
      /**
       * <pre>
       *If File is for reading, return all blocknumbers
       * </pre>
       *
       * <code>repeated int32 blocknumber = 2;</code>
       * @return A list containing the blocknumber.
       */
      public java.util.List<java.lang.Integer>
          getBlocknumberList() {
        return ((bitField0_ & 0x00000002) != 0) ?
                 java.util.Collections.unmodifiableList(blocknumber_) : blocknumber_;
      }
      /**
       * <pre>
       *If File is for reading, return all blocknumbers
       * </pre>
       *
       * <code>repeated int32 blocknumber = 2;</code>
       * @return The count of blocknumber.
       */
      public int getBlocknumberCount() {
        return blocknumber_.size();
      }
      /**
       * <pre>
       *If File is for reading, return all blocknumbers
       * </pre>
       *
       * <code>repeated int32 blocknumber = 2;</code>
       * @param index The index of the element to return.
       * @return The blocknumber at the given index.
       */
      public int getBlocknumber(int index) {
        return blocknumber_.getInt(index);
      }
      /**
       * <pre>
       *If File is for reading, return all blocknumbers
       * </pre>
       *
       * <code>repeated int32 blocknumber = 2;</code>
       * @param index The index to set the value at.
       * @param value The blocknumber to set.
       * @return This builder for chaining.
       */
      public Builder setBlocknumber(
          int index, int value) {
        ensureBlocknumberIsMutable();
        blocknumber_.setInt(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *If File is for reading, return all blocknumbers
       * </pre>
       *
       * <code>repeated int32 blocknumber = 2;</code>
       * @param value The blocknumber to add.
       * @return This builder for chaining.
       */
      public Builder addBlocknumber(int value) {
        ensureBlocknumberIsMutable();
        blocknumber_.addInt(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *If File is for reading, return all blocknumbers
       * </pre>
       *
       * <code>repeated int32 blocknumber = 2;</code>
       * @param values The blocknumber to add.
       * @return This builder for chaining.
       */
      public Builder addAllBlocknumber(
          java.lang.Iterable<? extends java.lang.Integer> values) {
        ensureBlocknumberIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, blocknumber_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *If File is for reading, return all blocknumbers
       * </pre>
       *
       * <code>repeated int32 blocknumber = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearBlocknumber() {
        blocknumber_ = emptyIntList();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.OpenFileResponse)
    }

    // @@protoc_insertion_point(class_scope:hdfs.OpenFileResponse)
    private static final ds.hdfs.HdfsProto.OpenFileResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.OpenFileResponse();
    }

    public static ds.hdfs.HdfsProto.OpenFileResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<OpenFileResponse>
        PARSER = new com.google.protobuf.AbstractParser<OpenFileResponse>() {
      @java.lang.Override
      public OpenFileResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new OpenFileResponse(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<OpenFileResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<OpenFileResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.OpenFileResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CloseFileRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.CloseFileRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int32 filedescriptor = 1;</code>
     * @return Whether the filedescriptor field is set.
     */
    boolean hasFiledescriptor();
    /**
     * <code>optional int32 filedescriptor = 1;</code>
     * @return The filedescriptor.
     */
    int getFiledescriptor();
  }
  /**
   * <pre>
   *message to close a file with a open filedescriptor
   *returns zero on success. On error, -1 is returned.
   * </pre>
   *
   * Protobuf type {@code hdfs.CloseFileRequest}
   */
  public  static final class CloseFileRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.CloseFileRequest)
      CloseFileRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CloseFileRequest.newBuilder() to construct.
    private CloseFileRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CloseFileRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CloseFileRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private CloseFileRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              filedescriptor_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_CloseFileRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_CloseFileRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.CloseFileRequest.class, ds.hdfs.HdfsProto.CloseFileRequest.Builder.class);
    }

    private int bitField0_;
    public static final int FILEDESCRIPTOR_FIELD_NUMBER = 1;
    private int filedescriptor_;
    /**
     * <code>optional int32 filedescriptor = 1;</code>
     * @return Whether the filedescriptor field is set.
     */
    public boolean hasFiledescriptor() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional int32 filedescriptor = 1;</code>
     * @return The filedescriptor.
     */
    public int getFiledescriptor() {
      return filedescriptor_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(1, filedescriptor_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, filedescriptor_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.CloseFileRequest)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.CloseFileRequest other = (ds.hdfs.HdfsProto.CloseFileRequest) obj;

      if (hasFiledescriptor() != other.hasFiledescriptor()) return false;
      if (hasFiledescriptor()) {
        if (getFiledescriptor()
            != other.getFiledescriptor()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFiledescriptor()) {
        hash = (37 * hash) + FILEDESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getFiledescriptor();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.CloseFileRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.CloseFileRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.CloseFileRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.CloseFileRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.CloseFileRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.CloseFileRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.CloseFileRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.CloseFileRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.CloseFileRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.CloseFileRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.CloseFileRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.CloseFileRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.CloseFileRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *message to close a file with a open filedescriptor
     *returns zero on success. On error, -1 is returned.
     * </pre>
     *
     * Protobuf type {@code hdfs.CloseFileRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.CloseFileRequest)
        ds.hdfs.HdfsProto.CloseFileRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_CloseFileRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_CloseFileRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.CloseFileRequest.class, ds.hdfs.HdfsProto.CloseFileRequest.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.CloseFileRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        filedescriptor_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_CloseFileRequest_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.CloseFileRequest getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.CloseFileRequest.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.CloseFileRequest build() {
        ds.hdfs.HdfsProto.CloseFileRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.CloseFileRequest buildPartial() {
        ds.hdfs.HdfsProto.CloseFileRequest result = new ds.hdfs.HdfsProto.CloseFileRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.filedescriptor_ = filedescriptor_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.CloseFileRequest) {
          return mergeFrom((ds.hdfs.HdfsProto.CloseFileRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.CloseFileRequest other) {
        if (other == ds.hdfs.HdfsProto.CloseFileRequest.getDefaultInstance()) return this;
        if (other.hasFiledescriptor()) {
          setFiledescriptor(other.getFiledescriptor());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.CloseFileRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.CloseFileRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int filedescriptor_ ;
      /**
       * <code>optional int32 filedescriptor = 1;</code>
       * @return Whether the filedescriptor field is set.
       */
      public boolean hasFiledescriptor() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional int32 filedescriptor = 1;</code>
       * @return The filedescriptor.
       */
      public int getFiledescriptor() {
        return filedescriptor_;
      }
      /**
       * <code>optional int32 filedescriptor = 1;</code>
       * @param value The filedescriptor to set.
       * @return This builder for chaining.
       */
      public Builder setFiledescriptor(int value) {
        bitField0_ |= 0x00000001;
        filedescriptor_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 filedescriptor = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearFiledescriptor() {
        bitField0_ = (bitField0_ & ~0x00000001);
        filedescriptor_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.CloseFileRequest)
    }

    // @@protoc_insertion_point(class_scope:hdfs.CloseFileRequest)
    private static final ds.hdfs.HdfsProto.CloseFileRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.CloseFileRequest();
    }

    public static ds.hdfs.HdfsProto.CloseFileRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<CloseFileRequest>
        PARSER = new com.google.protobuf.AbstractParser<CloseFileRequest>() {
      @java.lang.Override
      public CloseFileRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new CloseFileRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<CloseFileRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<CloseFileRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.CloseFileRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CloseFileResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.CloseFileResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int32 status = 1 [default = -1];</code>
     * @return Whether the status field is set.
     */
    boolean hasStatus();
    /**
     * <code>optional int32 status = 1 [default = -1];</code>
     * @return The status.
     */
    int getStatus();
  }
  /**
   * Protobuf type {@code hdfs.CloseFileResponse}
   */
  public  static final class CloseFileResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.CloseFileResponse)
      CloseFileResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CloseFileResponse.newBuilder() to construct.
    private CloseFileResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CloseFileResponse() {
      status_ = -1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CloseFileResponse();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private CloseFileResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              status_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_CloseFileResponse_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_CloseFileResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.CloseFileResponse.class, ds.hdfs.HdfsProto.CloseFileResponse.Builder.class);
    }

    private int bitField0_;
    public static final int STATUS_FIELD_NUMBER = 1;
    private int status_;
    /**
     * <code>optional int32 status = 1 [default = -1];</code>
     * @return Whether the status field is set.
     */
    public boolean hasStatus() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional int32 status = 1 [default = -1];</code>
     * @return The status.
     */
    public int getStatus() {
      return status_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(1, status_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, status_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.CloseFileResponse)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.CloseFileResponse other = (ds.hdfs.HdfsProto.CloseFileResponse) obj;

      if (hasStatus() != other.hasStatus()) return false;
      if (hasStatus()) {
        if (getStatus()
            != other.getStatus()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasStatus()) {
        hash = (37 * hash) + STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getStatus();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.CloseFileResponse parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.CloseFileResponse parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.CloseFileResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.CloseFileResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.CloseFileResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.CloseFileResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.CloseFileResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.CloseFileResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.CloseFileResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.CloseFileResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.CloseFileResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.CloseFileResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.CloseFileResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hdfs.CloseFileResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.CloseFileResponse)
        ds.hdfs.HdfsProto.CloseFileResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_CloseFileResponse_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_CloseFileResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.CloseFileResponse.class, ds.hdfs.HdfsProto.CloseFileResponse.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.CloseFileResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        status_ = -1;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_CloseFileResponse_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.CloseFileResponse getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.CloseFileResponse.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.CloseFileResponse build() {
        ds.hdfs.HdfsProto.CloseFileResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.CloseFileResponse buildPartial() {
        ds.hdfs.HdfsProto.CloseFileResponse result = new ds.hdfs.HdfsProto.CloseFileResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.status_ = status_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.CloseFileResponse) {
          return mergeFrom((ds.hdfs.HdfsProto.CloseFileResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.CloseFileResponse other) {
        if (other == ds.hdfs.HdfsProto.CloseFileResponse.getDefaultInstance()) return this;
        if (other.hasStatus()) {
          setStatus(other.getStatus());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.CloseFileResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.CloseFileResponse) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int status_ = -1;
      /**
       * <code>optional int32 status = 1 [default = -1];</code>
       * @return Whether the status field is set.
       */
      public boolean hasStatus() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional int32 status = 1 [default = -1];</code>
       * @return The status.
       */
      public int getStatus() {
        return status_;
      }
      /**
       * <code>optional int32 status = 1 [default = -1];</code>
       * @param value The status to set.
       * @return This builder for chaining.
       */
      public Builder setStatus(int value) {
        bitField0_ |= 0x00000001;
        status_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 status = 1 [default = -1];</code>
       * @return This builder for chaining.
       */
      public Builder clearStatus() {
        bitField0_ = (bitField0_ & ~0x00000001);
        status_ = -1;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.CloseFileResponse)
    }

    // @@protoc_insertion_point(class_scope:hdfs.CloseFileResponse)
    private static final ds.hdfs.HdfsProto.CloseFileResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.CloseFileResponse();
    }

    public static ds.hdfs.HdfsProto.CloseFileResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<CloseFileResponse>
        PARSER = new com.google.protobuf.AbstractParser<CloseFileResponse>() {
      @java.lang.Override
      public CloseFileResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new CloseFileResponse(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<CloseFileResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<CloseFileResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.CloseFileResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface AssignBlockRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.AssignBlockRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int32 filedescriptor = 1;</code>
     * @return Whether the filedescriptor field is set.
     */
    boolean hasFiledescriptor();
    /**
     * <code>optional int32 filedescriptor = 1;</code>
     * @return The filedescriptor.
     */
    int getFiledescriptor();
  }
  /**
   * <pre>
   *message to assign a block number to Data Node ips.
   * </pre>
   *
   * Protobuf type {@code hdfs.AssignBlockRequest}
   */
  public  static final class AssignBlockRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.AssignBlockRequest)
      AssignBlockRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use AssignBlockRequest.newBuilder() to construct.
    private AssignBlockRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private AssignBlockRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new AssignBlockRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private AssignBlockRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              filedescriptor_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_AssignBlockRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_AssignBlockRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.AssignBlockRequest.class, ds.hdfs.HdfsProto.AssignBlockRequest.Builder.class);
    }

    private int bitField0_;
    public static final int FILEDESCRIPTOR_FIELD_NUMBER = 1;
    private int filedescriptor_;
    /**
     * <code>optional int32 filedescriptor = 1;</code>
     * @return Whether the filedescriptor field is set.
     */
    public boolean hasFiledescriptor() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional int32 filedescriptor = 1;</code>
     * @return The filedescriptor.
     */
    public int getFiledescriptor() {
      return filedescriptor_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(1, filedescriptor_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, filedescriptor_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.AssignBlockRequest)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.AssignBlockRequest other = (ds.hdfs.HdfsProto.AssignBlockRequest) obj;

      if (hasFiledescriptor() != other.hasFiledescriptor()) return false;
      if (hasFiledescriptor()) {
        if (getFiledescriptor()
            != other.getFiledescriptor()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFiledescriptor()) {
        hash = (37 * hash) + FILEDESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getFiledescriptor();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.AssignBlockRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.AssignBlockRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.AssignBlockRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.AssignBlockRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.AssignBlockRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.AssignBlockRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.AssignBlockRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.AssignBlockRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.AssignBlockRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.AssignBlockRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.AssignBlockRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.AssignBlockRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.AssignBlockRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *message to assign a block number to Data Node ips.
     * </pre>
     *
     * Protobuf type {@code hdfs.AssignBlockRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.AssignBlockRequest)
        ds.hdfs.HdfsProto.AssignBlockRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_AssignBlockRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_AssignBlockRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.AssignBlockRequest.class, ds.hdfs.HdfsProto.AssignBlockRequest.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.AssignBlockRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        filedescriptor_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_AssignBlockRequest_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.AssignBlockRequest getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.AssignBlockRequest.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.AssignBlockRequest build() {
        ds.hdfs.HdfsProto.AssignBlockRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.AssignBlockRequest buildPartial() {
        ds.hdfs.HdfsProto.AssignBlockRequest result = new ds.hdfs.HdfsProto.AssignBlockRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.filedescriptor_ = filedescriptor_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.AssignBlockRequest) {
          return mergeFrom((ds.hdfs.HdfsProto.AssignBlockRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.AssignBlockRequest other) {
        if (other == ds.hdfs.HdfsProto.AssignBlockRequest.getDefaultInstance()) return this;
        if (other.hasFiledescriptor()) {
          setFiledescriptor(other.getFiledescriptor());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.AssignBlockRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.AssignBlockRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int filedescriptor_ ;
      /**
       * <code>optional int32 filedescriptor = 1;</code>
       * @return Whether the filedescriptor field is set.
       */
      public boolean hasFiledescriptor() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional int32 filedescriptor = 1;</code>
       * @return The filedescriptor.
       */
      public int getFiledescriptor() {
        return filedescriptor_;
      }
      /**
       * <code>optional int32 filedescriptor = 1;</code>
       * @param value The filedescriptor to set.
       * @return This builder for chaining.
       */
      public Builder setFiledescriptor(int value) {
        bitField0_ |= 0x00000001;
        filedescriptor_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 filedescriptor = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearFiledescriptor() {
        bitField0_ = (bitField0_ & ~0x00000001);
        filedescriptor_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.AssignBlockRequest)
    }

    // @@protoc_insertion_point(class_scope:hdfs.AssignBlockRequest)
    private static final ds.hdfs.HdfsProto.AssignBlockRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.AssignBlockRequest();
    }

    public static ds.hdfs.HdfsProto.AssignBlockRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<AssignBlockRequest>
        PARSER = new com.google.protobuf.AbstractParser<AssignBlockRequest>() {
      @java.lang.Override
      public AssignBlockRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new AssignBlockRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<AssignBlockRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<AssignBlockRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.AssignBlockRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface AssignBlockResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.AssignBlockResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int32 blocknumber = 1;</code>
     * @return Whether the blocknumber field is set.
     */
    boolean hasBlocknumber();
    /**
     * <code>optional int32 blocknumber = 1;</code>
     * @return The blocknumber.
     */
    int getBlocknumber();

    /**
     * <pre>
     *message DataNode{
     *optional string servername = 1;
     *optional string ipaddr = 2;
     *optional int32  portnum = 3;
     *}
     * </pre>
     *
     * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
     */
    java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> 
        getDatanodeList();
    /**
     * <pre>
     *message DataNode{
     *optional string servername = 1;
     *optional string ipaddr = 2;
     *optional int32  portnum = 3;
     *}
     * </pre>
     *
     * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
     */
    ds.hdfs.HdfsProto.DataNodeInfo getDatanode(int index);
    /**
     * <pre>
     *message DataNode{
     *optional string servername = 1;
     *optional string ipaddr = 2;
     *optional int32  portnum = 3;
     *}
     * </pre>
     *
     * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
     */
    int getDatanodeCount();
    /**
     * <pre>
     *message DataNode{
     *optional string servername = 1;
     *optional string ipaddr = 2;
     *optional int32  portnum = 3;
     *}
     * </pre>
     *
     * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
     */
    java.util.List<? extends ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
        getDatanodeOrBuilderList();
    /**
     * <pre>
     *message DataNode{
     *optional string servername = 1;
     *optional string ipaddr = 2;
     *optional int32  portnum = 3;
     *}
     * </pre>
     *
     * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
     */
    ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getDatanodeOrBuilder(
        int index);

    /**
     * <code>optional int32 status = 3 [default = -1];</code>
     * @return Whether the status field is set.
     */
    boolean hasStatus();
    /**
     * <code>optional int32 status = 3 [default = -1];</code>
     * @return The status.
     */
    int getStatus();
  }
  /**
   * Protobuf type {@code hdfs.AssignBlockResponse}
   */
  public  static final class AssignBlockResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.AssignBlockResponse)
      AssignBlockResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use AssignBlockResponse.newBuilder() to construct.
    private AssignBlockResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private AssignBlockResponse() {
      datanode_ = java.util.Collections.emptyList();
      status_ = -1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new AssignBlockResponse();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private AssignBlockResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              blocknumber_ = input.readInt32();
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) != 0)) {
                datanode_ = new java.util.ArrayList<ds.hdfs.HdfsProto.DataNodeInfo>();
                mutable_bitField0_ |= 0x00000002;
              }
              datanode_.add(
                  input.readMessage(ds.hdfs.HdfsProto.DataNodeInfo.PARSER, extensionRegistry));
              break;
            }
            case 24: {
              bitField0_ |= 0x00000002;
              status_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) != 0)) {
          datanode_ = java.util.Collections.unmodifiableList(datanode_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_AssignBlockResponse_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_AssignBlockResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.AssignBlockResponse.class, ds.hdfs.HdfsProto.AssignBlockResponse.Builder.class);
    }

    private int bitField0_;
    public static final int BLOCKNUMBER_FIELD_NUMBER = 1;
    private int blocknumber_;
    /**
     * <code>optional int32 blocknumber = 1;</code>
     * @return Whether the blocknumber field is set.
     */
    public boolean hasBlocknumber() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional int32 blocknumber = 1;</code>
     * @return The blocknumber.
     */
    public int getBlocknumber() {
      return blocknumber_;
    }

    public static final int DATANODE_FIELD_NUMBER = 2;
    private java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> datanode_;
    /**
     * <pre>
     *message DataNode{
     *optional string servername = 1;
     *optional string ipaddr = 2;
     *optional int32  portnum = 3;
     *}
     * </pre>
     *
     * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
     */
    public java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> getDatanodeList() {
      return datanode_;
    }
    /**
     * <pre>
     *message DataNode{
     *optional string servername = 1;
     *optional string ipaddr = 2;
     *optional int32  portnum = 3;
     *}
     * </pre>
     *
     * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
     */
    public java.util.List<? extends ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
        getDatanodeOrBuilderList() {
      return datanode_;
    }
    /**
     * <pre>
     *message DataNode{
     *optional string servername = 1;
     *optional string ipaddr = 2;
     *optional int32  portnum = 3;
     *}
     * </pre>
     *
     * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
     */
    public int getDatanodeCount() {
      return datanode_.size();
    }
    /**
     * <pre>
     *message DataNode{
     *optional string servername = 1;
     *optional string ipaddr = 2;
     *optional int32  portnum = 3;
     *}
     * </pre>
     *
     * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
     */
    public ds.hdfs.HdfsProto.DataNodeInfo getDatanode(int index) {
      return datanode_.get(index);
    }
    /**
     * <pre>
     *message DataNode{
     *optional string servername = 1;
     *optional string ipaddr = 2;
     *optional int32  portnum = 3;
     *}
     * </pre>
     *
     * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
     */
    public ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getDatanodeOrBuilder(
        int index) {
      return datanode_.get(index);
    }

    public static final int STATUS_FIELD_NUMBER = 3;
    private int status_;
    /**
     * <code>optional int32 status = 3 [default = -1];</code>
     * @return Whether the status field is set.
     */
    public boolean hasStatus() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional int32 status = 3 [default = -1];</code>
     * @return The status.
     */
    public int getStatus() {
      return status_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(1, blocknumber_);
      }
      for (int i = 0; i < datanode_.size(); i++) {
        output.writeMessage(2, datanode_.get(i));
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeInt32(3, status_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, blocknumber_);
      }
      for (int i = 0; i < datanode_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, datanode_.get(i));
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, status_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.AssignBlockResponse)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.AssignBlockResponse other = (ds.hdfs.HdfsProto.AssignBlockResponse) obj;

      if (hasBlocknumber() != other.hasBlocknumber()) return false;
      if (hasBlocknumber()) {
        if (getBlocknumber()
            != other.getBlocknumber()) return false;
      }
      if (!getDatanodeList()
          .equals(other.getDatanodeList())) return false;
      if (hasStatus() != other.hasStatus()) return false;
      if (hasStatus()) {
        if (getStatus()
            != other.getStatus()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasBlocknumber()) {
        hash = (37 * hash) + BLOCKNUMBER_FIELD_NUMBER;
        hash = (53 * hash) + getBlocknumber();
      }
      if (getDatanodeCount() > 0) {
        hash = (37 * hash) + DATANODE_FIELD_NUMBER;
        hash = (53 * hash) + getDatanodeList().hashCode();
      }
      if (hasStatus()) {
        hash = (37 * hash) + STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getStatus();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.AssignBlockResponse parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.AssignBlockResponse parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.AssignBlockResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.AssignBlockResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.AssignBlockResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.AssignBlockResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.AssignBlockResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.AssignBlockResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.AssignBlockResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.AssignBlockResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.AssignBlockResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.AssignBlockResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.AssignBlockResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hdfs.AssignBlockResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.AssignBlockResponse)
        ds.hdfs.HdfsProto.AssignBlockResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_AssignBlockResponse_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_AssignBlockResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.AssignBlockResponse.class, ds.hdfs.HdfsProto.AssignBlockResponse.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.AssignBlockResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getDatanodeFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        blocknumber_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (datanodeBuilder_ == null) {
          datanode_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          datanodeBuilder_.clear();
        }
        status_ = -1;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_AssignBlockResponse_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.AssignBlockResponse getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.AssignBlockResponse.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.AssignBlockResponse build() {
        ds.hdfs.HdfsProto.AssignBlockResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.AssignBlockResponse buildPartial() {
        ds.hdfs.HdfsProto.AssignBlockResponse result = new ds.hdfs.HdfsProto.AssignBlockResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.blocknumber_ = blocknumber_;
          to_bitField0_ |= 0x00000001;
        }
        if (datanodeBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0)) {
            datanode_ = java.util.Collections.unmodifiableList(datanode_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.datanode_ = datanode_;
        } else {
          result.datanode_ = datanodeBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          to_bitField0_ |= 0x00000002;
        }
        result.status_ = status_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.AssignBlockResponse) {
          return mergeFrom((ds.hdfs.HdfsProto.AssignBlockResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.AssignBlockResponse other) {
        if (other == ds.hdfs.HdfsProto.AssignBlockResponse.getDefaultInstance()) return this;
        if (other.hasBlocknumber()) {
          setBlocknumber(other.getBlocknumber());
        }
        if (datanodeBuilder_ == null) {
          if (!other.datanode_.isEmpty()) {
            if (datanode_.isEmpty()) {
              datanode_ = other.datanode_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureDatanodeIsMutable();
              datanode_.addAll(other.datanode_);
            }
            onChanged();
          }
        } else {
          if (!other.datanode_.isEmpty()) {
            if (datanodeBuilder_.isEmpty()) {
              datanodeBuilder_.dispose();
              datanodeBuilder_ = null;
              datanode_ = other.datanode_;
              bitField0_ = (bitField0_ & ~0x00000002);
              datanodeBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getDatanodeFieldBuilder() : null;
            } else {
              datanodeBuilder_.addAllMessages(other.datanode_);
            }
          }
        }
        if (other.hasStatus()) {
          setStatus(other.getStatus());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.AssignBlockResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.AssignBlockResponse) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int blocknumber_ ;
      /**
       * <code>optional int32 blocknumber = 1;</code>
       * @return Whether the blocknumber field is set.
       */
      public boolean hasBlocknumber() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional int32 blocknumber = 1;</code>
       * @return The blocknumber.
       */
      public int getBlocknumber() {
        return blocknumber_;
      }
      /**
       * <code>optional int32 blocknumber = 1;</code>
       * @param value The blocknumber to set.
       * @return This builder for chaining.
       */
      public Builder setBlocknumber(int value) {
        bitField0_ |= 0x00000001;
        blocknumber_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 blocknumber = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearBlocknumber() {
        bitField0_ = (bitField0_ & ~0x00000001);
        blocknumber_ = 0;
        onChanged();
        return this;
      }

      private java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> datanode_ =
        java.util.Collections.emptyList();
      private void ensureDatanodeIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          datanode_ = new java.util.ArrayList<ds.hdfs.HdfsProto.DataNodeInfo>(datanode_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> datanodeBuilder_;

      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> getDatanodeList() {
        if (datanodeBuilder_ == null) {
          return java.util.Collections.unmodifiableList(datanode_);
        } else {
          return datanodeBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public int getDatanodeCount() {
        if (datanodeBuilder_ == null) {
          return datanode_.size();
        } else {
          return datanodeBuilder_.getCount();
        }
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfo getDatanode(int index) {
        if (datanodeBuilder_ == null) {
          return datanode_.get(index);
        } else {
          return datanodeBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public Builder setDatanode(
          int index, ds.hdfs.HdfsProto.DataNodeInfo value) {
        if (datanodeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDatanodeIsMutable();
          datanode_.set(index, value);
          onChanged();
        } else {
          datanodeBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public Builder setDatanode(
          int index, ds.hdfs.HdfsProto.DataNodeInfo.Builder builderForValue) {
        if (datanodeBuilder_ == null) {
          ensureDatanodeIsMutable();
          datanode_.set(index, builderForValue.build());
          onChanged();
        } else {
          datanodeBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public Builder addDatanode(ds.hdfs.HdfsProto.DataNodeInfo value) {
        if (datanodeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDatanodeIsMutable();
          datanode_.add(value);
          onChanged();
        } else {
          datanodeBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public Builder addDatanode(
          int index, ds.hdfs.HdfsProto.DataNodeInfo value) {
        if (datanodeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDatanodeIsMutable();
          datanode_.add(index, value);
          onChanged();
        } else {
          datanodeBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public Builder addDatanode(
          ds.hdfs.HdfsProto.DataNodeInfo.Builder builderForValue) {
        if (datanodeBuilder_ == null) {
          ensureDatanodeIsMutable();
          datanode_.add(builderForValue.build());
          onChanged();
        } else {
          datanodeBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public Builder addDatanode(
          int index, ds.hdfs.HdfsProto.DataNodeInfo.Builder builderForValue) {
        if (datanodeBuilder_ == null) {
          ensureDatanodeIsMutable();
          datanode_.add(index, builderForValue.build());
          onChanged();
        } else {
          datanodeBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public Builder addAllDatanode(
          java.lang.Iterable<? extends ds.hdfs.HdfsProto.DataNodeInfo> values) {
        if (datanodeBuilder_ == null) {
          ensureDatanodeIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, datanode_);
          onChanged();
        } else {
          datanodeBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public Builder clearDatanode() {
        if (datanodeBuilder_ == null) {
          datanode_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          datanodeBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public Builder removeDatanode(int index) {
        if (datanodeBuilder_ == null) {
          ensureDatanodeIsMutable();
          datanode_.remove(index);
          onChanged();
        } else {
          datanodeBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfo.Builder getDatanodeBuilder(
          int index) {
        return getDatanodeFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getDatanodeOrBuilder(
          int index) {
        if (datanodeBuilder_ == null) {
          return datanode_.get(index);  } else {
          return datanodeBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public java.util.List<? extends ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
           getDatanodeOrBuilderList() {
        if (datanodeBuilder_ != null) {
          return datanodeBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(datanode_);
        }
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfo.Builder addDatanodeBuilder() {
        return getDatanodeFieldBuilder().addBuilder(
            ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance());
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfo.Builder addDatanodeBuilder(
          int index) {
        return getDatanodeFieldBuilder().addBuilder(
            index, ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance());
      }
      /**
       * <pre>
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public java.util.List<ds.hdfs.HdfsProto.DataNodeInfo.Builder> 
           getDatanodeBuilderList() {
        return getDatanodeFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
          getDatanodeFieldBuilder() {
        if (datanodeBuilder_ == null) {
          datanodeBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder>(
                  datanode_,
                  ((bitField0_ & 0x00000002) != 0),
                  getParentForChildren(),
                  isClean());
          datanode_ = null;
        }
        return datanodeBuilder_;
      }

      private int status_ = -1;
      /**
       * <code>optional int32 status = 3 [default = -1];</code>
       * @return Whether the status field is set.
       */
      public boolean hasStatus() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional int32 status = 3 [default = -1];</code>
       * @return The status.
       */
      public int getStatus() {
        return status_;
      }
      /**
       * <code>optional int32 status = 3 [default = -1];</code>
       * @param value The status to set.
       * @return This builder for chaining.
       */
      public Builder setStatus(int value) {
        bitField0_ |= 0x00000004;
        status_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 status = 3 [default = -1];</code>
       * @return This builder for chaining.
       */
      public Builder clearStatus() {
        bitField0_ = (bitField0_ & ~0x00000004);
        status_ = -1;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.AssignBlockResponse)
    }

    // @@protoc_insertion_point(class_scope:hdfs.AssignBlockResponse)
    private static final ds.hdfs.HdfsProto.AssignBlockResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.AssignBlockResponse();
    }

    public static ds.hdfs.HdfsProto.AssignBlockResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<AssignBlockResponse>
        PARSER = new com.google.protobuf.AbstractParser<AssignBlockResponse>() {
      @java.lang.Override
      public AssignBlockResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new AssignBlockResponse(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<AssignBlockResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<AssignBlockResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.AssignBlockResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ListFileRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.ListFileRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *no use for directory in this project
     * </pre>
     *
     * <code>optional string dir = 1;</code>
     * @return Whether the dir field is set.
     */
    boolean hasDir();
    /**
     * <pre>
     *no use for directory in this project
     * </pre>
     *
     * <code>optional string dir = 1;</code>
     * @return The dir.
     */
    java.lang.String getDir();
    /**
     * <pre>
     *no use for directory in this project
     * </pre>
     *
     * <code>optional string dir = 1;</code>
     * @return The bytes for dir.
     */
    com.google.protobuf.ByteString
        getDirBytes();
  }
  /**
   * <pre>
   *message to list all files
   *On error, negative number is returned.
   * </pre>
   *
   * Protobuf type {@code hdfs.ListFileRequest}
   */
  public  static final class ListFileRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.ListFileRequest)
      ListFileRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ListFileRequest.newBuilder() to construct.
    private ListFileRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ListFileRequest() {
      dir_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ListFileRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ListFileRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              dir_ = bs;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_ListFileRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_ListFileRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.ListFileRequest.class, ds.hdfs.HdfsProto.ListFileRequest.Builder.class);
    }

    private int bitField0_;
    public static final int DIR_FIELD_NUMBER = 1;
    private volatile java.lang.Object dir_;
    /**
     * <pre>
     *no use for directory in this project
     * </pre>
     *
     * <code>optional string dir = 1;</code>
     * @return Whether the dir field is set.
     */
    public boolean hasDir() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     *no use for directory in this project
     * </pre>
     *
     * <code>optional string dir = 1;</code>
     * @return The dir.
     */
    public java.lang.String getDir() {
      java.lang.Object ref = dir_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          dir_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     *no use for directory in this project
     * </pre>
     *
     * <code>optional string dir = 1;</code>
     * @return The bytes for dir.
     */
    public com.google.protobuf.ByteString
        getDirBytes() {
      java.lang.Object ref = dir_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        dir_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, dir_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, dir_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.ListFileRequest)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.ListFileRequest other = (ds.hdfs.HdfsProto.ListFileRequest) obj;

      if (hasDir() != other.hasDir()) return false;
      if (hasDir()) {
        if (!getDir()
            .equals(other.getDir())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasDir()) {
        hash = (37 * hash) + DIR_FIELD_NUMBER;
        hash = (53 * hash) + getDir().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.ListFileRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.ListFileRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ListFileRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.ListFileRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ListFileRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.ListFileRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ListFileRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.ListFileRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ListFileRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.ListFileRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ListFileRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.ListFileRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.ListFileRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *message to list all files
     *On error, negative number is returned.
     * </pre>
     *
     * Protobuf type {@code hdfs.ListFileRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.ListFileRequest)
        ds.hdfs.HdfsProto.ListFileRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_ListFileRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_ListFileRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.ListFileRequest.class, ds.hdfs.HdfsProto.ListFileRequest.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.ListFileRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        dir_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_ListFileRequest_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.ListFileRequest getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.ListFileRequest.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.ListFileRequest build() {
        ds.hdfs.HdfsProto.ListFileRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.ListFileRequest buildPartial() {
        ds.hdfs.HdfsProto.ListFileRequest result = new ds.hdfs.HdfsProto.ListFileRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.dir_ = dir_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.ListFileRequest) {
          return mergeFrom((ds.hdfs.HdfsProto.ListFileRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.ListFileRequest other) {
        if (other == ds.hdfs.HdfsProto.ListFileRequest.getDefaultInstance()) return this;
        if (other.hasDir()) {
          bitField0_ |= 0x00000001;
          dir_ = other.dir_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.ListFileRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.ListFileRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object dir_ = "";
      /**
       * <pre>
       *no use for directory in this project
       * </pre>
       *
       * <code>optional string dir = 1;</code>
       * @return Whether the dir field is set.
       */
      public boolean hasDir() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       *no use for directory in this project
       * </pre>
       *
       * <code>optional string dir = 1;</code>
       * @return The dir.
       */
      public java.lang.String getDir() {
        java.lang.Object ref = dir_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            dir_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       *no use for directory in this project
       * </pre>
       *
       * <code>optional string dir = 1;</code>
       * @return The bytes for dir.
       */
      public com.google.protobuf.ByteString
          getDirBytes() {
        java.lang.Object ref = dir_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          dir_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *no use for directory in this project
       * </pre>
       *
       * <code>optional string dir = 1;</code>
       * @param value The dir to set.
       * @return This builder for chaining.
       */
      public Builder setDir(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        dir_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *no use for directory in this project
       * </pre>
       *
       * <code>optional string dir = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearDir() {
        bitField0_ = (bitField0_ & ~0x00000001);
        dir_ = getDefaultInstance().getDir();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *no use for directory in this project
       * </pre>
       *
       * <code>optional string dir = 1;</code>
       * @param value The bytes for dir to set.
       * @return This builder for chaining.
       */
      public Builder setDirBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        dir_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.ListFileRequest)
    }

    // @@protoc_insertion_point(class_scope:hdfs.ListFileRequest)
    private static final ds.hdfs.HdfsProto.ListFileRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.ListFileRequest();
    }

    public static ds.hdfs.HdfsProto.ListFileRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ListFileRequest>
        PARSER = new com.google.protobuf.AbstractParser<ListFileRequest>() {
      @java.lang.Override
      public ListFileRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ListFileRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ListFileRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ListFileRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.ListFileRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ListFileResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.ListFileResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated string filename = 1;</code>
     * @return A list containing the filename.
     */
    java.util.List<java.lang.String>
        getFilenameList();
    /**
     * <code>repeated string filename = 1;</code>
     * @return The count of filename.
     */
    int getFilenameCount();
    /**
     * <code>repeated string filename = 1;</code>
     * @param index The index of the element to return.
     * @return The filename at the given index.
     */
    java.lang.String getFilename(int index);
    /**
     * <code>repeated string filename = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the filename at the given index.
     */
    com.google.protobuf.ByteString
        getFilenameBytes(int index);

    /**
     * <code>optional int32 status = 2 [default = -1];</code>
     * @return Whether the status field is set.
     */
    boolean hasStatus();
    /**
     * <code>optional int32 status = 2 [default = -1];</code>
     * @return The status.
     */
    int getStatus();
  }
  /**
   * Protobuf type {@code hdfs.ListFileResponse}
   */
  public  static final class ListFileResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.ListFileResponse)
      ListFileResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ListFileResponse.newBuilder() to construct.
    private ListFileResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ListFileResponse() {
      filename_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      status_ = -1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ListFileResponse();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ListFileResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                filename_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000001;
              }
              filename_.add(bs);
              break;
            }
            case 16: {
              bitField0_ |= 0x00000001;
              status_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          filename_ = filename_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_ListFileResponse_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_ListFileResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.ListFileResponse.class, ds.hdfs.HdfsProto.ListFileResponse.Builder.class);
    }

    private int bitField0_;
    public static final int FILENAME_FIELD_NUMBER = 1;
    private com.google.protobuf.LazyStringList filename_;
    /**
     * <code>repeated string filename = 1;</code>
     * @return A list containing the filename.
     */
    public com.google.protobuf.ProtocolStringList
        getFilenameList() {
      return filename_;
    }
    /**
     * <code>repeated string filename = 1;</code>
     * @return The count of filename.
     */
    public int getFilenameCount() {
      return filename_.size();
    }
    /**
     * <code>repeated string filename = 1;</code>
     * @param index The index of the element to return.
     * @return The filename at the given index.
     */
    public java.lang.String getFilename(int index) {
      return filename_.get(index);
    }
    /**
     * <code>repeated string filename = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the filename at the given index.
     */
    public com.google.protobuf.ByteString
        getFilenameBytes(int index) {
      return filename_.getByteString(index);
    }

    public static final int STATUS_FIELD_NUMBER = 2;
    private int status_;
    /**
     * <code>optional int32 status = 2 [default = -1];</code>
     * @return Whether the status field is set.
     */
    public boolean hasStatus() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional int32 status = 2 [default = -1];</code>
     * @return The status.
     */
    public int getStatus() {
      return status_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < filename_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, filename_.getRaw(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(2, status_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < filename_.size(); i++) {
          dataSize += computeStringSizeNoTag(filename_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getFilenameList().size();
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, status_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.ListFileResponse)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.ListFileResponse other = (ds.hdfs.HdfsProto.ListFileResponse) obj;

      if (!getFilenameList()
          .equals(other.getFilenameList())) return false;
      if (hasStatus() != other.hasStatus()) return false;
      if (hasStatus()) {
        if (getStatus()
            != other.getStatus()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getFilenameCount() > 0) {
        hash = (37 * hash) + FILENAME_FIELD_NUMBER;
        hash = (53 * hash) + getFilenameList().hashCode();
      }
      if (hasStatus()) {
        hash = (37 * hash) + STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getStatus();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.ListFileResponse parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.ListFileResponse parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ListFileResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.ListFileResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ListFileResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.ListFileResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ListFileResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.ListFileResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ListFileResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.ListFileResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ListFileResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.ListFileResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.ListFileResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hdfs.ListFileResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.ListFileResponse)
        ds.hdfs.HdfsProto.ListFileResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_ListFileResponse_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_ListFileResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.ListFileResponse.class, ds.hdfs.HdfsProto.ListFileResponse.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.ListFileResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        filename_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        status_ = -1;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_ListFileResponse_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.ListFileResponse getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.ListFileResponse.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.ListFileResponse build() {
        ds.hdfs.HdfsProto.ListFileResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.ListFileResponse buildPartial() {
        ds.hdfs.HdfsProto.ListFileResponse result = new ds.hdfs.HdfsProto.ListFileResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((bitField0_ & 0x00000001) != 0)) {
          filename_ = filename_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.filename_ = filename_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.status_ = status_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.ListFileResponse) {
          return mergeFrom((ds.hdfs.HdfsProto.ListFileResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.ListFileResponse other) {
        if (other == ds.hdfs.HdfsProto.ListFileResponse.getDefaultInstance()) return this;
        if (!other.filename_.isEmpty()) {
          if (filename_.isEmpty()) {
            filename_ = other.filename_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureFilenameIsMutable();
            filename_.addAll(other.filename_);
          }
          onChanged();
        }
        if (other.hasStatus()) {
          setStatus(other.getStatus());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.ListFileResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.ListFileResponse) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private com.google.protobuf.LazyStringList filename_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureFilenameIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          filename_ = new com.google.protobuf.LazyStringArrayList(filename_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <code>repeated string filename = 1;</code>
       * @return A list containing the filename.
       */
      public com.google.protobuf.ProtocolStringList
          getFilenameList() {
        return filename_.getUnmodifiableView();
      }
      /**
       * <code>repeated string filename = 1;</code>
       * @return The count of filename.
       */
      public int getFilenameCount() {
        return filename_.size();
      }
      /**
       * <code>repeated string filename = 1;</code>
       * @param index The index of the element to return.
       * @return The filename at the given index.
       */
      public java.lang.String getFilename(int index) {
        return filename_.get(index);
      }
      /**
       * <code>repeated string filename = 1;</code>
       * @param index The index of the value to return.
       * @return The bytes of the filename at the given index.
       */
      public com.google.protobuf.ByteString
          getFilenameBytes(int index) {
        return filename_.getByteString(index);
      }
      /**
       * <code>repeated string filename = 1;</code>
       * @param index The index to set the value at.
       * @param value The filename to set.
       * @return This builder for chaining.
       */
      public Builder setFilename(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureFilenameIsMutable();
        filename_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string filename = 1;</code>
       * @param value The filename to add.
       * @return This builder for chaining.
       */
      public Builder addFilename(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureFilenameIsMutable();
        filename_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string filename = 1;</code>
       * @param values The filename to add.
       * @return This builder for chaining.
       */
      public Builder addAllFilename(
          java.lang.Iterable<java.lang.String> values) {
        ensureFilenameIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, filename_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string filename = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearFilename() {
        filename_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string filename = 1;</code>
       * @param value The bytes of the filename to add.
       * @return This builder for chaining.
       */
      public Builder addFilenameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureFilenameIsMutable();
        filename_.add(value);
        onChanged();
        return this;
      }

      private int status_ = -1;
      /**
       * <code>optional int32 status = 2 [default = -1];</code>
       * @return Whether the status field is set.
       */
      public boolean hasStatus() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional int32 status = 2 [default = -1];</code>
       * @return The status.
       */
      public int getStatus() {
        return status_;
      }
      /**
       * <code>optional int32 status = 2 [default = -1];</code>
       * @param value The status to set.
       * @return This builder for chaining.
       */
      public Builder setStatus(int value) {
        bitField0_ |= 0x00000002;
        status_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 status = 2 [default = -1];</code>
       * @return This builder for chaining.
       */
      public Builder clearStatus() {
        bitField0_ = (bitField0_ & ~0x00000002);
        status_ = -1;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.ListFileResponse)
    }

    // @@protoc_insertion_point(class_scope:hdfs.ListFileResponse)
    private static final ds.hdfs.HdfsProto.ListFileResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.ListFileResponse();
    }

    public static ds.hdfs.HdfsProto.ListFileResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ListFileResponse>
        PARSER = new com.google.protobuf.AbstractParser<ListFileResponse>() {
      @java.lang.Override
      public ListFileResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ListFileResponse(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ListFileResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ListFileResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.ListFileResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface BlockLocationsRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.BlockLocationsRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int32 blocknumber = 1;</code>
     * @return Whether the blocknumber field is set.
     */
    boolean hasBlocknumber();
    /**
     * <code>optional int32 blocknumber = 1;</code>
     * @return The blocknumber.
     */
    int getBlocknumber();
  }
  /**
   * <pre>
   *message for block locations
   * </pre>
   *
   * Protobuf type {@code hdfs.BlockLocationsRequest}
   */
  public  static final class BlockLocationsRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.BlockLocationsRequest)
      BlockLocationsRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use BlockLocationsRequest.newBuilder() to construct.
    private BlockLocationsRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private BlockLocationsRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new BlockLocationsRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private BlockLocationsRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              blocknumber_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_BlockLocationsRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_BlockLocationsRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.BlockLocationsRequest.class, ds.hdfs.HdfsProto.BlockLocationsRequest.Builder.class);
    }

    private int bitField0_;
    public static final int BLOCKNUMBER_FIELD_NUMBER = 1;
    private int blocknumber_;
    /**
     * <code>optional int32 blocknumber = 1;</code>
     * @return Whether the blocknumber field is set.
     */
    public boolean hasBlocknumber() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional int32 blocknumber = 1;</code>
     * @return The blocknumber.
     */
    public int getBlocknumber() {
      return blocknumber_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(1, blocknumber_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, blocknumber_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.BlockLocationsRequest)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.BlockLocationsRequest other = (ds.hdfs.HdfsProto.BlockLocationsRequest) obj;

      if (hasBlocknumber() != other.hasBlocknumber()) return false;
      if (hasBlocknumber()) {
        if (getBlocknumber()
            != other.getBlocknumber()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasBlocknumber()) {
        hash = (37 * hash) + BLOCKNUMBER_FIELD_NUMBER;
        hash = (53 * hash) + getBlocknumber();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.BlockLocationsRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.BlockLocationsRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *message for block locations
     * </pre>
     *
     * Protobuf type {@code hdfs.BlockLocationsRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.BlockLocationsRequest)
        ds.hdfs.HdfsProto.BlockLocationsRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlockLocationsRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlockLocationsRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.BlockLocationsRequest.class, ds.hdfs.HdfsProto.BlockLocationsRequest.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.BlockLocationsRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        blocknumber_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlockLocationsRequest_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlockLocationsRequest getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.BlockLocationsRequest.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlockLocationsRequest build() {
        ds.hdfs.HdfsProto.BlockLocationsRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlockLocationsRequest buildPartial() {
        ds.hdfs.HdfsProto.BlockLocationsRequest result = new ds.hdfs.HdfsProto.BlockLocationsRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.blocknumber_ = blocknumber_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.BlockLocationsRequest) {
          return mergeFrom((ds.hdfs.HdfsProto.BlockLocationsRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.BlockLocationsRequest other) {
        if (other == ds.hdfs.HdfsProto.BlockLocationsRequest.getDefaultInstance()) return this;
        if (other.hasBlocknumber()) {
          setBlocknumber(other.getBlocknumber());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.BlockLocationsRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.BlockLocationsRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int blocknumber_ ;
      /**
       * <code>optional int32 blocknumber = 1;</code>
       * @return Whether the blocknumber field is set.
       */
      public boolean hasBlocknumber() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional int32 blocknumber = 1;</code>
       * @return The blocknumber.
       */
      public int getBlocknumber() {
        return blocknumber_;
      }
      /**
       * <code>optional int32 blocknumber = 1;</code>
       * @param value The blocknumber to set.
       * @return This builder for chaining.
       */
      public Builder setBlocknumber(int value) {
        bitField0_ |= 0x00000001;
        blocknumber_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 blocknumber = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearBlocknumber() {
        bitField0_ = (bitField0_ & ~0x00000001);
        blocknumber_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.BlockLocationsRequest)
    }

    // @@protoc_insertion_point(class_scope:hdfs.BlockLocationsRequest)
    private static final ds.hdfs.HdfsProto.BlockLocationsRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.BlockLocationsRequest();
    }

    public static ds.hdfs.HdfsProto.BlockLocationsRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<BlockLocationsRequest>
        PARSER = new com.google.protobuf.AbstractParser<BlockLocationsRequest>() {
      @java.lang.Override
      public BlockLocationsRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new BlockLocationsRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<BlockLocationsRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<BlockLocationsRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.BlockLocationsRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface BlockLocationsResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.BlockLocationsResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
     */
    java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> 
        getDatanodeList();
    /**
     * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
     */
    ds.hdfs.HdfsProto.DataNodeInfo getDatanode(int index);
    /**
     * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
     */
    int getDatanodeCount();
    /**
     * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
     */
    java.util.List<? extends ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
        getDatanodeOrBuilderList();
    /**
     * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
     */
    ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getDatanodeOrBuilder(
        int index);

    /**
     * <code>optional int32 status = 2 [default = -1];</code>
     * @return Whether the status field is set.
     */
    boolean hasStatus();
    /**
     * <code>optional int32 status = 2 [default = -1];</code>
     * @return The status.
     */
    int getStatus();
  }
  /**
   * Protobuf type {@code hdfs.BlockLocationsResponse}
   */
  public  static final class BlockLocationsResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.BlockLocationsResponse)
      BlockLocationsResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use BlockLocationsResponse.newBuilder() to construct.
    private BlockLocationsResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private BlockLocationsResponse() {
      datanode_ = java.util.Collections.emptyList();
      status_ = -1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new BlockLocationsResponse();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private BlockLocationsResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                datanode_ = new java.util.ArrayList<ds.hdfs.HdfsProto.DataNodeInfo>();
                mutable_bitField0_ |= 0x00000001;
              }
              datanode_.add(
                  input.readMessage(ds.hdfs.HdfsProto.DataNodeInfo.PARSER, extensionRegistry));
              break;
            }
            case 16: {
              bitField0_ |= 0x00000001;
              status_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          datanode_ = java.util.Collections.unmodifiableList(datanode_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_BlockLocationsResponse_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_BlockLocationsResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.BlockLocationsResponse.class, ds.hdfs.HdfsProto.BlockLocationsResponse.Builder.class);
    }

    private int bitField0_;
    public static final int DATANODE_FIELD_NUMBER = 1;
    private java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> datanode_;
    /**
     * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
     */
    public java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> getDatanodeList() {
      return datanode_;
    }
    /**
     * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
     */
    public java.util.List<? extends ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
        getDatanodeOrBuilderList() {
      return datanode_;
    }
    /**
     * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
     */
    public int getDatanodeCount() {
      return datanode_.size();
    }
    /**
     * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
     */
    public ds.hdfs.HdfsProto.DataNodeInfo getDatanode(int index) {
      return datanode_.get(index);
    }
    /**
     * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
     */
    public ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getDatanodeOrBuilder(
        int index) {
      return datanode_.get(index);
    }

    public static final int STATUS_FIELD_NUMBER = 2;
    private int status_;
    /**
     * <code>optional int32 status = 2 [default = -1];</code>
     * @return Whether the status field is set.
     */
    public boolean hasStatus() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional int32 status = 2 [default = -1];</code>
     * @return The status.
     */
    public int getStatus() {
      return status_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < datanode_.size(); i++) {
        output.writeMessage(1, datanode_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(2, status_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < datanode_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, datanode_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, status_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.BlockLocationsResponse)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.BlockLocationsResponse other = (ds.hdfs.HdfsProto.BlockLocationsResponse) obj;

      if (!getDatanodeList()
          .equals(other.getDatanodeList())) return false;
      if (hasStatus() != other.hasStatus()) return false;
      if (hasStatus()) {
        if (getStatus()
            != other.getStatus()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getDatanodeCount() > 0) {
        hash = (37 * hash) + DATANODE_FIELD_NUMBER;
        hash = (53 * hash) + getDatanodeList().hashCode();
      }
      if (hasStatus()) {
        hash = (37 * hash) + STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getStatus();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.BlockLocationsResponse parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsResponse parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.BlockLocationsResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.BlockLocationsResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hdfs.BlockLocationsResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.BlockLocationsResponse)
        ds.hdfs.HdfsProto.BlockLocationsResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlockLocationsResponse_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlockLocationsResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.BlockLocationsResponse.class, ds.hdfs.HdfsProto.BlockLocationsResponse.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.BlockLocationsResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getDatanodeFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (datanodeBuilder_ == null) {
          datanode_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          datanodeBuilder_.clear();
        }
        status_ = -1;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlockLocationsResponse_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlockLocationsResponse getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.BlockLocationsResponse.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlockLocationsResponse build() {
        ds.hdfs.HdfsProto.BlockLocationsResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlockLocationsResponse buildPartial() {
        ds.hdfs.HdfsProto.BlockLocationsResponse result = new ds.hdfs.HdfsProto.BlockLocationsResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (datanodeBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            datanode_ = java.util.Collections.unmodifiableList(datanode_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.datanode_ = datanode_;
        } else {
          result.datanode_ = datanodeBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.status_ = status_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.BlockLocationsResponse) {
          return mergeFrom((ds.hdfs.HdfsProto.BlockLocationsResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.BlockLocationsResponse other) {
        if (other == ds.hdfs.HdfsProto.BlockLocationsResponse.getDefaultInstance()) return this;
        if (datanodeBuilder_ == null) {
          if (!other.datanode_.isEmpty()) {
            if (datanode_.isEmpty()) {
              datanode_ = other.datanode_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureDatanodeIsMutable();
              datanode_.addAll(other.datanode_);
            }
            onChanged();
          }
        } else {
          if (!other.datanode_.isEmpty()) {
            if (datanodeBuilder_.isEmpty()) {
              datanodeBuilder_.dispose();
              datanodeBuilder_ = null;
              datanode_ = other.datanode_;
              bitField0_ = (bitField0_ & ~0x00000001);
              datanodeBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getDatanodeFieldBuilder() : null;
            } else {
              datanodeBuilder_.addAllMessages(other.datanode_);
            }
          }
        }
        if (other.hasStatus()) {
          setStatus(other.getStatus());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.BlockLocationsResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.BlockLocationsResponse) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> datanode_ =
        java.util.Collections.emptyList();
      private void ensureDatanodeIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          datanode_ = new java.util.ArrayList<ds.hdfs.HdfsProto.DataNodeInfo>(datanode_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> datanodeBuilder_;

      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> getDatanodeList() {
        if (datanodeBuilder_ == null) {
          return java.util.Collections.unmodifiableList(datanode_);
        } else {
          return datanodeBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public int getDatanodeCount() {
        if (datanodeBuilder_ == null) {
          return datanode_.size();
        } else {
          return datanodeBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfo getDatanode(int index) {
        if (datanodeBuilder_ == null) {
          return datanode_.get(index);
        } else {
          return datanodeBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public Builder setDatanode(
          int index, ds.hdfs.HdfsProto.DataNodeInfo value) {
        if (datanodeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDatanodeIsMutable();
          datanode_.set(index, value);
          onChanged();
        } else {
          datanodeBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public Builder setDatanode(
          int index, ds.hdfs.HdfsProto.DataNodeInfo.Builder builderForValue) {
        if (datanodeBuilder_ == null) {
          ensureDatanodeIsMutable();
          datanode_.set(index, builderForValue.build());
          onChanged();
        } else {
          datanodeBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public Builder addDatanode(ds.hdfs.HdfsProto.DataNodeInfo value) {
        if (datanodeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDatanodeIsMutable();
          datanode_.add(value);
          onChanged();
        } else {
          datanodeBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public Builder addDatanode(
          int index, ds.hdfs.HdfsProto.DataNodeInfo value) {
        if (datanodeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDatanodeIsMutable();
          datanode_.add(index, value);
          onChanged();
        } else {
          datanodeBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public Builder addDatanode(
          ds.hdfs.HdfsProto.DataNodeInfo.Builder builderForValue) {
        if (datanodeBuilder_ == null) {
          ensureDatanodeIsMutable();
          datanode_.add(builderForValue.build());
          onChanged();
        } else {
          datanodeBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public Builder addDatanode(
          int index, ds.hdfs.HdfsProto.DataNodeInfo.Builder builderForValue) {
        if (datanodeBuilder_ == null) {
          ensureDatanodeIsMutable();
          datanode_.add(index, builderForValue.build());
          onChanged();
        } else {
          datanodeBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public Builder addAllDatanode(
          java.lang.Iterable<? extends ds.hdfs.HdfsProto.DataNodeInfo> values) {
        if (datanodeBuilder_ == null) {
          ensureDatanodeIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, datanode_);
          onChanged();
        } else {
          datanodeBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public Builder clearDatanode() {
        if (datanodeBuilder_ == null) {
          datanode_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          datanodeBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public Builder removeDatanode(int index) {
        if (datanodeBuilder_ == null) {
          ensureDatanodeIsMutable();
          datanode_.remove(index);
          onChanged();
        } else {
          datanodeBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfo.Builder getDatanodeBuilder(
          int index) {
        return getDatanodeFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getDatanodeOrBuilder(
          int index) {
        if (datanodeBuilder_ == null) {
          return datanode_.get(index);  } else {
          return datanodeBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public java.util.List<? extends ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
           getDatanodeOrBuilderList() {
        if (datanodeBuilder_ != null) {
          return datanodeBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(datanode_);
        }
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfo.Builder addDatanodeBuilder() {
        return getDatanodeFieldBuilder().addBuilder(
            ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfo.Builder addDatanodeBuilder(
          int index) {
        return getDatanodeFieldBuilder().addBuilder(
            index, ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public java.util.List<ds.hdfs.HdfsProto.DataNodeInfo.Builder> 
           getDatanodeBuilderList() {
        return getDatanodeFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
          getDatanodeFieldBuilder() {
        if (datanodeBuilder_ == null) {
          datanodeBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder>(
                  datanode_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          datanode_ = null;
        }
        return datanodeBuilder_;
      }

      private int status_ = -1;
      /**
       * <code>optional int32 status = 2 [default = -1];</code>
       * @return Whether the status field is set.
       */
      public boolean hasStatus() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional int32 status = 2 [default = -1];</code>
       * @return The status.
       */
      public int getStatus() {
        return status_;
      }
      /**
       * <code>optional int32 status = 2 [default = -1];</code>
       * @param value The status to set.
       * @return This builder for chaining.
       */
      public Builder setStatus(int value) {
        bitField0_ |= 0x00000002;
        status_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 status = 2 [default = -1];</code>
       * @return This builder for chaining.
       */
      public Builder clearStatus() {
        bitField0_ = (bitField0_ & ~0x00000002);
        status_ = -1;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.BlockLocationsResponse)
    }

    // @@protoc_insertion_point(class_scope:hdfs.BlockLocationsResponse)
    private static final ds.hdfs.HdfsProto.BlockLocationsResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.BlockLocationsResponse();
    }

    public static ds.hdfs.HdfsProto.BlockLocationsResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<BlockLocationsResponse>
        PARSER = new com.google.protobuf.AbstractParser<BlockLocationsResponse>() {
      @java.lang.Override
      public BlockLocationsResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new BlockLocationsResponse(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<BlockLocationsResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<BlockLocationsResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.BlockLocationsResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface BlockReportRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.BlockReportRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated int32 blocks = 1;</code>
     * @return A list containing the blocks.
     */
    java.util.List<java.lang.Integer> getBlocksList();
    /**
     * <code>repeated int32 blocks = 1;</code>
     * @return The count of blocks.
     */
    int getBlocksCount();
    /**
     * <code>repeated int32 blocks = 1;</code>
     * @param index The index of the element to return.
     * @return The blocks at the given index.
     */
    int getBlocks(int index);

    /**
     * <code>required .hdfs.DataNodeInfo datanode = 2;</code>
     * @return Whether the datanode field is set.
     */
    boolean hasDatanode();
    /**
     * <code>required .hdfs.DataNodeInfo datanode = 2;</code>
     * @return The datanode.
     */
    ds.hdfs.HdfsProto.DataNodeInfo getDatanode();
    /**
     * <code>required .hdfs.DataNodeInfo datanode = 2;</code>
     */
    ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getDatanodeOrBuilder();
  }
  /**
   * <pre>
   *message to report blocks in Data Node
   * </pre>
   *
   * Protobuf type {@code hdfs.BlockReportRequest}
   */
  public  static final class BlockReportRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.BlockReportRequest)
      BlockReportRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use BlockReportRequest.newBuilder() to construct.
    private BlockReportRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private BlockReportRequest() {
      blocks_ = emptyIntList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new BlockReportRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private BlockReportRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                blocks_ = newIntList();
                mutable_bitField0_ |= 0x00000001;
              }
              blocks_.addInt(input.readInt32());
              break;
            }
            case 10: {
              int length = input.readRawVarint32();
              int limit = input.pushLimit(length);
              if (!((mutable_bitField0_ & 0x00000001) != 0) && input.getBytesUntilLimit() > 0) {
                blocks_ = newIntList();
                mutable_bitField0_ |= 0x00000001;
              }
              while (input.getBytesUntilLimit() > 0) {
                blocks_.addInt(input.readInt32());
              }
              input.popLimit(limit);
              break;
            }
            case 18: {
              ds.hdfs.HdfsProto.DataNodeInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) != 0)) {
                subBuilder = datanode_.toBuilder();
              }
              datanode_ = input.readMessage(ds.hdfs.HdfsProto.DataNodeInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(datanode_);
                datanode_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          blocks_.makeImmutable(); // C
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_BlockReportRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_BlockReportRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.BlockReportRequest.class, ds.hdfs.HdfsProto.BlockReportRequest.Builder.class);
    }

    private int bitField0_;
    public static final int BLOCKS_FIELD_NUMBER = 1;
    private com.google.protobuf.Internal.IntList blocks_;
    /**
     * <code>repeated int32 blocks = 1;</code>
     * @return A list containing the blocks.
     */
    public java.util.List<java.lang.Integer>
        getBlocksList() {
      return blocks_;
    }
    /**
     * <code>repeated int32 blocks = 1;</code>
     * @return The count of blocks.
     */
    public int getBlocksCount() {
      return blocks_.size();
    }
    /**
     * <code>repeated int32 blocks = 1;</code>
     * @param index The index of the element to return.
     * @return The blocks at the given index.
     */
    public int getBlocks(int index) {
      return blocks_.getInt(index);
    }

    public static final int DATANODE_FIELD_NUMBER = 2;
    private ds.hdfs.HdfsProto.DataNodeInfo datanode_;
    /**
     * <code>required .hdfs.DataNodeInfo datanode = 2;</code>
     * @return Whether the datanode field is set.
     */
    public boolean hasDatanode() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hdfs.DataNodeInfo datanode = 2;</code>
     * @return The datanode.
     */
    public ds.hdfs.HdfsProto.DataNodeInfo getDatanode() {
      return datanode_ == null ? ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance() : datanode_;
    }
    /**
     * <code>required .hdfs.DataNodeInfo datanode = 2;</code>
     */
    public ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getDatanodeOrBuilder() {
      return datanode_ == null ? ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance() : datanode_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasDatanode()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < blocks_.size(); i++) {
        output.writeInt32(1, blocks_.getInt(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(2, getDatanode());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < blocks_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeInt32SizeNoTag(blocks_.getInt(i));
        }
        size += dataSize;
        size += 1 * getBlocksList().size();
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getDatanode());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.BlockReportRequest)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.BlockReportRequest other = (ds.hdfs.HdfsProto.BlockReportRequest) obj;

      if (!getBlocksList()
          .equals(other.getBlocksList())) return false;
      if (hasDatanode() != other.hasDatanode()) return false;
      if (hasDatanode()) {
        if (!getDatanode()
            .equals(other.getDatanode())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getBlocksCount() > 0) {
        hash = (37 * hash) + BLOCKS_FIELD_NUMBER;
        hash = (53 * hash) + getBlocksList().hashCode();
      }
      if (hasDatanode()) {
        hash = (37 * hash) + DATANODE_FIELD_NUMBER;
        hash = (53 * hash) + getDatanode().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.BlockReportRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.BlockReportRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockReportRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.BlockReportRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockReportRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.BlockReportRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockReportRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.BlockReportRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockReportRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.BlockReportRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockReportRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.BlockReportRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.BlockReportRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *message to report blocks in Data Node
     * </pre>
     *
     * Protobuf type {@code hdfs.BlockReportRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.BlockReportRequest)
        ds.hdfs.HdfsProto.BlockReportRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlockReportRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlockReportRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.BlockReportRequest.class, ds.hdfs.HdfsProto.BlockReportRequest.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.BlockReportRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getDatanodeFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        blocks_ = emptyIntList();
        bitField0_ = (bitField0_ & ~0x00000001);
        if (datanodeBuilder_ == null) {
          datanode_ = null;
        } else {
          datanodeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlockReportRequest_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlockReportRequest getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.BlockReportRequest.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlockReportRequest build() {
        ds.hdfs.HdfsProto.BlockReportRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlockReportRequest buildPartial() {
        ds.hdfs.HdfsProto.BlockReportRequest result = new ds.hdfs.HdfsProto.BlockReportRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((bitField0_ & 0x00000001) != 0)) {
          blocks_.makeImmutable();
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.blocks_ = blocks_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          if (datanodeBuilder_ == null) {
            result.datanode_ = datanode_;
          } else {
            result.datanode_ = datanodeBuilder_.build();
          }
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.BlockReportRequest) {
          return mergeFrom((ds.hdfs.HdfsProto.BlockReportRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.BlockReportRequest other) {
        if (other == ds.hdfs.HdfsProto.BlockReportRequest.getDefaultInstance()) return this;
        if (!other.blocks_.isEmpty()) {
          if (blocks_.isEmpty()) {
            blocks_ = other.blocks_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureBlocksIsMutable();
            blocks_.addAll(other.blocks_);
          }
          onChanged();
        }
        if (other.hasDatanode()) {
          mergeDatanode(other.getDatanode());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasDatanode()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.BlockReportRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.BlockReportRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private com.google.protobuf.Internal.IntList blocks_ = emptyIntList();
      private void ensureBlocksIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          blocks_ = mutableCopy(blocks_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <code>repeated int32 blocks = 1;</code>
       * @return A list containing the blocks.
       */
      public java.util.List<java.lang.Integer>
          getBlocksList() {
        return ((bitField0_ & 0x00000001) != 0) ?
                 java.util.Collections.unmodifiableList(blocks_) : blocks_;
      }
      /**
       * <code>repeated int32 blocks = 1;</code>
       * @return The count of blocks.
       */
      public int getBlocksCount() {
        return blocks_.size();
      }
      /**
       * <code>repeated int32 blocks = 1;</code>
       * @param index The index of the element to return.
       * @return The blocks at the given index.
       */
      public int getBlocks(int index) {
        return blocks_.getInt(index);
      }
      /**
       * <code>repeated int32 blocks = 1;</code>
       * @param index The index to set the value at.
       * @param value The blocks to set.
       * @return This builder for chaining.
       */
      public Builder setBlocks(
          int index, int value) {
        ensureBlocksIsMutable();
        blocks_.setInt(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated int32 blocks = 1;</code>
       * @param value The blocks to add.
       * @return This builder for chaining.
       */
      public Builder addBlocks(int value) {
        ensureBlocksIsMutable();
        blocks_.addInt(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated int32 blocks = 1;</code>
       * @param values The blocks to add.
       * @return This builder for chaining.
       */
      public Builder addAllBlocks(
          java.lang.Iterable<? extends java.lang.Integer> values) {
        ensureBlocksIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, blocks_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated int32 blocks = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearBlocks() {
        blocks_ = emptyIntList();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }

      private ds.hdfs.HdfsProto.DataNodeInfo datanode_;
      private com.google.protobuf.SingleFieldBuilderV3<
          ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> datanodeBuilder_;
      /**
       * <code>required .hdfs.DataNodeInfo datanode = 2;</code>
       * @return Whether the datanode field is set.
       */
      public boolean hasDatanode() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hdfs.DataNodeInfo datanode = 2;</code>
       * @return The datanode.
       */
      public ds.hdfs.HdfsProto.DataNodeInfo getDatanode() {
        if (datanodeBuilder_ == null) {
          return datanode_ == null ? ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance() : datanode_;
        } else {
          return datanodeBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public Builder setDatanode(ds.hdfs.HdfsProto.DataNodeInfo value) {
        if (datanodeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          datanode_ = value;
          onChanged();
        } else {
          datanodeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public Builder setDatanode(
          ds.hdfs.HdfsProto.DataNodeInfo.Builder builderForValue) {
        if (datanodeBuilder_ == null) {
          datanode_ = builderForValue.build();
          onChanged();
        } else {
          datanodeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public Builder mergeDatanode(ds.hdfs.HdfsProto.DataNodeInfo value) {
        if (datanodeBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
              datanode_ != null &&
              datanode_ != ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance()) {
            datanode_ =
              ds.hdfs.HdfsProto.DataNodeInfo.newBuilder(datanode_).mergeFrom(value).buildPartial();
          } else {
            datanode_ = value;
          }
          onChanged();
        } else {
          datanodeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public Builder clearDatanode() {
        if (datanodeBuilder_ == null) {
          datanode_ = null;
          onChanged();
        } else {
          datanodeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfo.Builder getDatanodeBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getDatanodeFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getDatanodeOrBuilder() {
        if (datanodeBuilder_ != null) {
          return datanodeBuilder_.getMessageOrBuilder();
        } else {
          return datanode_ == null ?
              ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance() : datanode_;
        }
      }
      /**
       * <code>required .hdfs.DataNodeInfo datanode = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
          getDatanodeFieldBuilder() {
        if (datanodeBuilder_ == null) {
          datanodeBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder>(
                  getDatanode(),
                  getParentForChildren(),
                  isClean());
          datanode_ = null;
        }
        return datanodeBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.BlockReportRequest)
    }

    // @@protoc_insertion_point(class_scope:hdfs.BlockReportRequest)
    private static final ds.hdfs.HdfsProto.BlockReportRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.BlockReportRequest();
    }

    public static ds.hdfs.HdfsProto.BlockReportRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<BlockReportRequest>
        PARSER = new com.google.protobuf.AbstractParser<BlockReportRequest>() {
      @java.lang.Override
      public BlockReportRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new BlockReportRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<BlockReportRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<BlockReportRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.BlockReportRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface BlockReportResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.BlockReportResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int32 status = 1 [default = -1];</code>
     * @return Whether the status field is set.
     */
    boolean hasStatus();
    /**
     * <code>optional int32 status = 1 [default = -1];</code>
     * @return The status.
     */
    int getStatus();
  }
  /**
   * Protobuf type {@code hdfs.BlockReportResponse}
   */
  public  static final class BlockReportResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.BlockReportResponse)
      BlockReportResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use BlockReportResponse.newBuilder() to construct.
    private BlockReportResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private BlockReportResponse() {
      status_ = -1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new BlockReportResponse();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private BlockReportResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              status_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_BlockReportResponse_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_BlockReportResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.BlockReportResponse.class, ds.hdfs.HdfsProto.BlockReportResponse.Builder.class);
    }

    private int bitField0_;
    public static final int STATUS_FIELD_NUMBER = 1;
    private int status_;
    /**
     * <code>optional int32 status = 1 [default = -1];</code>
     * @return Whether the status field is set.
     */
    public boolean hasStatus() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional int32 status = 1 [default = -1];</code>
     * @return The status.
     */
    public int getStatus() {
      return status_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(1, status_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, status_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.BlockReportResponse)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.BlockReportResponse other = (ds.hdfs.HdfsProto.BlockReportResponse) obj;

      if (hasStatus() != other.hasStatus()) return false;
      if (hasStatus()) {
        if (getStatus()
            != other.getStatus()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasStatus()) {
        hash = (37 * hash) + STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getStatus();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.BlockReportResponse parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.BlockReportResponse parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockReportResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.BlockReportResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockReportResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.BlockReportResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockReportResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.BlockReportResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockReportResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.BlockReportResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlockReportResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.BlockReportResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.BlockReportResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hdfs.BlockReportResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.BlockReportResponse)
        ds.hdfs.HdfsProto.BlockReportResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlockReportResponse_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlockReportResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.BlockReportResponse.class, ds.hdfs.HdfsProto.BlockReportResponse.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.BlockReportResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        status_ = -1;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlockReportResponse_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlockReportResponse getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.BlockReportResponse.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlockReportResponse build() {
        ds.hdfs.HdfsProto.BlockReportResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlockReportResponse buildPartial() {
        ds.hdfs.HdfsProto.BlockReportResponse result = new ds.hdfs.HdfsProto.BlockReportResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.status_ = status_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.BlockReportResponse) {
          return mergeFrom((ds.hdfs.HdfsProto.BlockReportResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.BlockReportResponse other) {
        if (other == ds.hdfs.HdfsProto.BlockReportResponse.getDefaultInstance()) return this;
        if (other.hasStatus()) {
          setStatus(other.getStatus());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.BlockReportResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.BlockReportResponse) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int status_ = -1;
      /**
       * <code>optional int32 status = 1 [default = -1];</code>
       * @return Whether the status field is set.
       */
      public boolean hasStatus() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional int32 status = 1 [default = -1];</code>
       * @return The status.
       */
      public int getStatus() {
        return status_;
      }
      /**
       * <code>optional int32 status = 1 [default = -1];</code>
       * @param value The status to set.
       * @return This builder for chaining.
       */
      public Builder setStatus(int value) {
        bitField0_ |= 0x00000001;
        status_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 status = 1 [default = -1];</code>
       * @return This builder for chaining.
       */
      public Builder clearStatus() {
        bitField0_ = (bitField0_ & ~0x00000001);
        status_ = -1;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.BlockReportResponse)
    }

    // @@protoc_insertion_point(class_scope:hdfs.BlockReportResponse)
    private static final ds.hdfs.HdfsProto.BlockReportResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.BlockReportResponse();
    }

    public static ds.hdfs.HdfsProto.BlockReportResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<BlockReportResponse>
        PARSER = new com.google.protobuf.AbstractParser<BlockReportResponse>() {
      @java.lang.Override
      public BlockReportResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new BlockReportResponse(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<BlockReportResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<BlockReportResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.BlockReportResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface HeartBeatRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.HeartBeatRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hdfs.DataNodeInfo datanode = 1;</code>
     * @return Whether the datanode field is set.
     */
    boolean hasDatanode();
    /**
     * <code>optional .hdfs.DataNodeInfo datanode = 1;</code>
     * @return The datanode.
     */
    ds.hdfs.HdfsProto.DataNodeInfo getDatanode();
    /**
     * <code>optional .hdfs.DataNodeInfo datanode = 1;</code>
     */
    ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getDatanodeOrBuilder();
  }
  /**
   * <pre>
   *message for HeartBeat
   * </pre>
   *
   * Protobuf type {@code hdfs.HeartBeatRequest}
   */
  public  static final class HeartBeatRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.HeartBeatRequest)
      HeartBeatRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use HeartBeatRequest.newBuilder() to construct.
    private HeartBeatRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private HeartBeatRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new HeartBeatRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private HeartBeatRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              ds.hdfs.HdfsProto.DataNodeInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) != 0)) {
                subBuilder = datanode_.toBuilder();
              }
              datanode_ = input.readMessage(ds.hdfs.HdfsProto.DataNodeInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(datanode_);
                datanode_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_HeartBeatRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_HeartBeatRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.HeartBeatRequest.class, ds.hdfs.HdfsProto.HeartBeatRequest.Builder.class);
    }

    private int bitField0_;
    public static final int DATANODE_FIELD_NUMBER = 1;
    private ds.hdfs.HdfsProto.DataNodeInfo datanode_;
    /**
     * <code>optional .hdfs.DataNodeInfo datanode = 1;</code>
     * @return Whether the datanode field is set.
     */
    public boolean hasDatanode() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional .hdfs.DataNodeInfo datanode = 1;</code>
     * @return The datanode.
     */
    public ds.hdfs.HdfsProto.DataNodeInfo getDatanode() {
      return datanode_ == null ? ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance() : datanode_;
    }
    /**
     * <code>optional .hdfs.DataNodeInfo datanode = 1;</code>
     */
    public ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getDatanodeOrBuilder() {
      return datanode_ == null ? ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance() : datanode_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getDatanode());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getDatanode());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.HeartBeatRequest)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.HeartBeatRequest other = (ds.hdfs.HdfsProto.HeartBeatRequest) obj;

      if (hasDatanode() != other.hasDatanode()) return false;
      if (hasDatanode()) {
        if (!getDatanode()
            .equals(other.getDatanode())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasDatanode()) {
        hash = (37 * hash) + DATANODE_FIELD_NUMBER;
        hash = (53 * hash) + getDatanode().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.HeartBeatRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.HeartBeatRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.HeartBeatRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.HeartBeatRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.HeartBeatRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.HeartBeatRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.HeartBeatRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.HeartBeatRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.HeartBeatRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.HeartBeatRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.HeartBeatRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.HeartBeatRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.HeartBeatRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *message for HeartBeat
     * </pre>
     *
     * Protobuf type {@code hdfs.HeartBeatRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.HeartBeatRequest)
        ds.hdfs.HdfsProto.HeartBeatRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_HeartBeatRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_HeartBeatRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.HeartBeatRequest.class, ds.hdfs.HdfsProto.HeartBeatRequest.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.HeartBeatRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getDatanodeFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (datanodeBuilder_ == null) {
          datanode_ = null;
        } else {
          datanodeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_HeartBeatRequest_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.HeartBeatRequest getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.HeartBeatRequest.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.HeartBeatRequest build() {
        ds.hdfs.HdfsProto.HeartBeatRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.HeartBeatRequest buildPartial() {
        ds.hdfs.HdfsProto.HeartBeatRequest result = new ds.hdfs.HdfsProto.HeartBeatRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          if (datanodeBuilder_ == null) {
            result.datanode_ = datanode_;
          } else {
            result.datanode_ = datanodeBuilder_.build();
          }
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.HeartBeatRequest) {
          return mergeFrom((ds.hdfs.HdfsProto.HeartBeatRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.HeartBeatRequest other) {
        if (other == ds.hdfs.HdfsProto.HeartBeatRequest.getDefaultInstance()) return this;
        if (other.hasDatanode()) {
          mergeDatanode(other.getDatanode());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.HeartBeatRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.HeartBeatRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private ds.hdfs.HdfsProto.DataNodeInfo datanode_;
      private com.google.protobuf.SingleFieldBuilderV3<
          ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> datanodeBuilder_;
      /**
       * <code>optional .hdfs.DataNodeInfo datanode = 1;</code>
       * @return Whether the datanode field is set.
       */
      public boolean hasDatanode() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional .hdfs.DataNodeInfo datanode = 1;</code>
       * @return The datanode.
       */
      public ds.hdfs.HdfsProto.DataNodeInfo getDatanode() {
        if (datanodeBuilder_ == null) {
          return datanode_ == null ? ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance() : datanode_;
        } else {
          return datanodeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public Builder setDatanode(ds.hdfs.HdfsProto.DataNodeInfo value) {
        if (datanodeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          datanode_ = value;
          onChanged();
        } else {
          datanodeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public Builder setDatanode(
          ds.hdfs.HdfsProto.DataNodeInfo.Builder builderForValue) {
        if (datanodeBuilder_ == null) {
          datanode_ = builderForValue.build();
          onChanged();
        } else {
          datanodeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public Builder mergeDatanode(ds.hdfs.HdfsProto.DataNodeInfo value) {
        if (datanodeBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
              datanode_ != null &&
              datanode_ != ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance()) {
            datanode_ =
              ds.hdfs.HdfsProto.DataNodeInfo.newBuilder(datanode_).mergeFrom(value).buildPartial();
          } else {
            datanode_ = value;
          }
          onChanged();
        } else {
          datanodeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public Builder clearDatanode() {
        if (datanodeBuilder_ == null) {
          datanode_ = null;
          onChanged();
        } else {
          datanodeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfo.Builder getDatanodeBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getDatanodeFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hdfs.DataNodeInfo datanode = 1;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getDatanodeOrBuilder() {
        if (datanodeBuilder_ != null) {
          return datanodeBuilder_.getMessageOrBuilder();
        } else {
          return datanode_ == null ?
              ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance() : datanode_;
        }
      }
      /**
       * <code>optional .hdfs.DataNodeInfo datanode = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
          getDatanodeFieldBuilder() {
        if (datanodeBuilder_ == null) {
          datanodeBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder>(
                  getDatanode(),
                  getParentForChildren(),
                  isClean());
          datanode_ = null;
        }
        return datanodeBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.HeartBeatRequest)
    }

    // @@protoc_insertion_point(class_scope:hdfs.HeartBeatRequest)
    private static final ds.hdfs.HdfsProto.HeartBeatRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.HeartBeatRequest();
    }

    public static ds.hdfs.HdfsProto.HeartBeatRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<HeartBeatRequest>
        PARSER = new com.google.protobuf.AbstractParser<HeartBeatRequest>() {
      @java.lang.Override
      public HeartBeatRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new HeartBeatRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<HeartBeatRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<HeartBeatRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.HeartBeatRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface HeartBeatResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.HeartBeatResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int32 status = 1 [default = -1];</code>
     * @return Whether the status field is set.
     */
    boolean hasStatus();
    /**
     * <code>optional int32 status = 1 [default = -1];</code>
     * @return The status.
     */
    int getStatus();
  }
  /**
   * Protobuf type {@code hdfs.HeartBeatResponse}
   */
  public  static final class HeartBeatResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.HeartBeatResponse)
      HeartBeatResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use HeartBeatResponse.newBuilder() to construct.
    private HeartBeatResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private HeartBeatResponse() {
      status_ = -1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new HeartBeatResponse();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private HeartBeatResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              status_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_HeartBeatResponse_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_HeartBeatResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.HeartBeatResponse.class, ds.hdfs.HdfsProto.HeartBeatResponse.Builder.class);
    }

    private int bitField0_;
    public static final int STATUS_FIELD_NUMBER = 1;
    private int status_;
    /**
     * <code>optional int32 status = 1 [default = -1];</code>
     * @return Whether the status field is set.
     */
    public boolean hasStatus() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional int32 status = 1 [default = -1];</code>
     * @return The status.
     */
    public int getStatus() {
      return status_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(1, status_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, status_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.HeartBeatResponse)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.HeartBeatResponse other = (ds.hdfs.HdfsProto.HeartBeatResponse) obj;

      if (hasStatus() != other.hasStatus()) return false;
      if (hasStatus()) {
        if (getStatus()
            != other.getStatus()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasStatus()) {
        hash = (37 * hash) + STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getStatus();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.HeartBeatResponse parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.HeartBeatResponse parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.HeartBeatResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.HeartBeatResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.HeartBeatResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.HeartBeatResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.HeartBeatResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.HeartBeatResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.HeartBeatResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.HeartBeatResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.HeartBeatResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.HeartBeatResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.HeartBeatResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hdfs.HeartBeatResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.HeartBeatResponse)
        ds.hdfs.HdfsProto.HeartBeatResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_HeartBeatResponse_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_HeartBeatResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.HeartBeatResponse.class, ds.hdfs.HdfsProto.HeartBeatResponse.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.HeartBeatResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        status_ = -1;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_HeartBeatResponse_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.HeartBeatResponse getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.HeartBeatResponse.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.HeartBeatResponse build() {
        ds.hdfs.HdfsProto.HeartBeatResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.HeartBeatResponse buildPartial() {
        ds.hdfs.HdfsProto.HeartBeatResponse result = new ds.hdfs.HdfsProto.HeartBeatResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.status_ = status_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.HeartBeatResponse) {
          return mergeFrom((ds.hdfs.HdfsProto.HeartBeatResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.HeartBeatResponse other) {
        if (other == ds.hdfs.HdfsProto.HeartBeatResponse.getDefaultInstance()) return this;
        if (other.hasStatus()) {
          setStatus(other.getStatus());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.HeartBeatResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.HeartBeatResponse) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int status_ = -1;
      /**
       * <code>optional int32 status = 1 [default = -1];</code>
       * @return Whether the status field is set.
       */
      public boolean hasStatus() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional int32 status = 1 [default = -1];</code>
       * @return The status.
       */
      public int getStatus() {
        return status_;
      }
      /**
       * <code>optional int32 status = 1 [default = -1];</code>
       * @param value The status to set.
       * @return This builder for chaining.
       */
      public Builder setStatus(int value) {
        bitField0_ |= 0x00000001;
        status_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 status = 1 [default = -1];</code>
       * @return This builder for chaining.
       */
      public Builder clearStatus() {
        bitField0_ = (bitField0_ & ~0x00000001);
        status_ = -1;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.HeartBeatResponse)
    }

    // @@protoc_insertion_point(class_scope:hdfs.HeartBeatResponse)
    private static final ds.hdfs.HdfsProto.HeartBeatResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.HeartBeatResponse();
    }

    public static ds.hdfs.HdfsProto.HeartBeatResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<HeartBeatResponse>
        PARSER = new com.google.protobuf.AbstractParser<HeartBeatResponse>() {
      @java.lang.Override
      public HeartBeatResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new HeartBeatResponse(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<HeartBeatResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<HeartBeatResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.HeartBeatResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FileInfoInNameNodeOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.FileInfoInNameNode)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string filename = 1;</code>
     * @return Whether the filename field is set.
     */
    boolean hasFilename();
    /**
     * <code>required string filename = 1;</code>
     * @return The filename.
     */
    java.lang.String getFilename();
    /**
     * <code>required string filename = 1;</code>
     * @return The bytes for filename.
     */
    com.google.protobuf.ByteString
        getFilenameBytes();

    /**
     * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
     */
    java.util.List<ds.hdfs.HdfsProto.FileInfoInNameNode.Block> 
        getBlockList();
    /**
     * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
     */
    ds.hdfs.HdfsProto.FileInfoInNameNode.Block getBlock(int index);
    /**
     * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
     */
    int getBlockCount();
    /**
     * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
     */
    java.util.List<? extends ds.hdfs.HdfsProto.FileInfoInNameNode.BlockOrBuilder> 
        getBlockOrBuilderList();
    /**
     * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
     */
    ds.hdfs.HdfsProto.FileInfoInNameNode.BlockOrBuilder getBlockOrBuilder(
        int index);

    /**
     * <code>optional bool writemode = 3;</code>
     * @return Whether the writemode field is set.
     */
    boolean hasWritemode();
    /**
     * <code>optional bool writemode = 3;</code>
     * @return The writemode.
     */
    boolean getWritemode();
  }
  /**
   * <pre>
   * message for NameNode to map a file to blocks distributed in different Data Nodes
   * </pre>
   *
   * Protobuf type {@code hdfs.FileInfoInNameNode}
   */
  public  static final class FileInfoInNameNode extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.FileInfoInNameNode)
      FileInfoInNameNodeOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use FileInfoInNameNode.newBuilder() to construct.
    private FileInfoInNameNode(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FileInfoInNameNode() {
      filename_ = "";
      block_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new FileInfoInNameNode();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private FileInfoInNameNode(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              filename_ = bs;
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) != 0)) {
                block_ = new java.util.ArrayList<ds.hdfs.HdfsProto.FileInfoInNameNode.Block>();
                mutable_bitField0_ |= 0x00000002;
              }
              block_.add(
                  input.readMessage(ds.hdfs.HdfsProto.FileInfoInNameNode.Block.PARSER, extensionRegistry));
              break;
            }
            case 24: {
              bitField0_ |= 0x00000002;
              writemode_ = input.readBool();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) != 0)) {
          block_ = java.util.Collections.unmodifiableList(block_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_FileInfoInNameNode_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_FileInfoInNameNode_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.FileInfoInNameNode.class, ds.hdfs.HdfsProto.FileInfoInNameNode.Builder.class);
    }

    public interface BlockOrBuilder extends
        // @@protoc_insertion_point(interface_extends:hdfs.FileInfoInNameNode.Block)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <code>required int32 blocknumber = 1;</code>
       * @return Whether the blocknumber field is set.
       */
      boolean hasBlocknumber();
      /**
       * <code>required int32 blocknumber = 1;</code>
       * @return The blocknumber.
       */
      int getBlocknumber();

      /**
       * <pre>
       * // message for NameNode to map the block to Data Node ips
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> 
          getDatanodeList();
      /**
       * <pre>
       * // message for NameNode to map the block to Data Node ips
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      ds.hdfs.HdfsProto.DataNodeInfo getDatanode(int index);
      /**
       * <pre>
       * // message for NameNode to map the block to Data Node ips
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      int getDatanodeCount();
      /**
       * <pre>
       * // message for NameNode to map the block to Data Node ips
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      java.util.List<? extends ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
          getDatanodeOrBuilderList();
      /**
       * <pre>
       * // message for NameNode to map the block to Data Node ips
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getDatanodeOrBuilder(
          int index);
    }
    /**
     * <pre>
     * message for NameNode to map a File to block numbers
     * </pre>
     *
     * Protobuf type {@code hdfs.FileInfoInNameNode.Block}
     */
    public  static final class Block extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:hdfs.FileInfoInNameNode.Block)
        BlockOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use Block.newBuilder() to construct.
      private Block(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Block() {
        datanode_ = java.util.Collections.emptyList();
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(
          UnusedPrivateParameter unused) {
        return new Block();
      }

      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return this.unknownFields;
      }
      private Block(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        int mutable_bitField0_ = 0;
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                bitField0_ |= 0x00000001;
                blocknumber_ = input.readInt32();
                break;
              }
              case 18: {
                if (!((mutable_bitField0_ & 0x00000002) != 0)) {
                  datanode_ = new java.util.ArrayList<ds.hdfs.HdfsProto.DataNodeInfo>();
                  mutable_bitField0_ |= 0x00000002;
                }
                datanode_.add(
                    input.readMessage(ds.hdfs.HdfsProto.DataNodeInfo.PARSER, extensionRegistry));
                break;
              }
              default: {
                if (!parseUnknownField(
                    input, unknownFields, extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          if (((mutable_bitField0_ & 0x00000002) != 0)) {
            datanode_ = java.util.Collections.unmodifiableList(datanode_);
          }
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_FileInfoInNameNode_Block_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_FileInfoInNameNode_Block_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.FileInfoInNameNode.Block.class, ds.hdfs.HdfsProto.FileInfoInNameNode.Block.Builder.class);
      }

      private int bitField0_;
      public static final int BLOCKNUMBER_FIELD_NUMBER = 1;
      private int blocknumber_;
      /**
       * <code>required int32 blocknumber = 1;</code>
       * @return Whether the blocknumber field is set.
       */
      public boolean hasBlocknumber() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required int32 blocknumber = 1;</code>
       * @return The blocknumber.
       */
      public int getBlocknumber() {
        return blocknumber_;
      }

      public static final int DATANODE_FIELD_NUMBER = 2;
      private java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> datanode_;
      /**
       * <pre>
       * // message for NameNode to map the block to Data Node ips
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> getDatanodeList() {
        return datanode_;
      }
      /**
       * <pre>
       * // message for NameNode to map the block to Data Node ips
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public java.util.List<? extends ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
          getDatanodeOrBuilderList() {
        return datanode_;
      }
      /**
       * <pre>
       * // message for NameNode to map the block to Data Node ips
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public int getDatanodeCount() {
        return datanode_.size();
      }
      /**
       * <pre>
       * // message for NameNode to map the block to Data Node ips
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfo getDatanode(int index) {
        return datanode_.get(index);
      }
      /**
       * <pre>
       * // message for NameNode to map the block to Data Node ips
       *message DataNode{
       *optional string servername = 1;
       *optional string ipaddr = 2;
       *optional int32  portnum = 3;
       *}
       * </pre>
       *
       * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getDatanodeOrBuilder(
          int index) {
        return datanode_.get(index);
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        if (!hasBlocknumber()) {
          memoizedIsInitialized = 0;
          return false;
        }
        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (((bitField0_ & 0x00000001) != 0)) {
          output.writeInt32(1, blocknumber_);
        }
        for (int i = 0; i < datanode_.size(); i++) {
          output.writeMessage(2, datanode_.get(i));
        }
        unknownFields.writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (((bitField0_ & 0x00000001) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt32Size(1, blocknumber_);
        }
        for (int i = 0; i < datanode_.size(); i++) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(2, datanode_.get(i));
        }
        size += unknownFields.getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof ds.hdfs.HdfsProto.FileInfoInNameNode.Block)) {
          return super.equals(obj);
        }
        ds.hdfs.HdfsProto.FileInfoInNameNode.Block other = (ds.hdfs.HdfsProto.FileInfoInNameNode.Block) obj;

        if (hasBlocknumber() != other.hasBlocknumber()) return false;
        if (hasBlocknumber()) {
          if (getBlocknumber()
              != other.getBlocknumber()) return false;
        }
        if (!getDatanodeList()
            .equals(other.getDatanodeList())) return false;
        if (!unknownFields.equals(other.unknownFields)) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        if (hasBlocknumber()) {
          hash = (37 * hash) + BLOCKNUMBER_FIELD_NUMBER;
          hash = (53 * hash) + getBlocknumber();
        }
        if (getDatanodeCount() > 0) {
          hash = (37 * hash) + DATANODE_FIELD_NUMBER;
          hash = (53 * hash) + getDatanodeList().hashCode();
        }
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static ds.hdfs.HdfsProto.FileInfoInNameNode.Block parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ds.hdfs.HdfsProto.FileInfoInNameNode.Block parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ds.hdfs.HdfsProto.FileInfoInNameNode.Block parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ds.hdfs.HdfsProto.FileInfoInNameNode.Block parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ds.hdfs.HdfsProto.FileInfoInNameNode.Block parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ds.hdfs.HdfsProto.FileInfoInNameNode.Block parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ds.hdfs.HdfsProto.FileInfoInNameNode.Block parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ds.hdfs.HdfsProto.FileInfoInNameNode.Block parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static ds.hdfs.HdfsProto.FileInfoInNameNode.Block parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static ds.hdfs.HdfsProto.FileInfoInNameNode.Block parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static ds.hdfs.HdfsProto.FileInfoInNameNode.Block parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ds.hdfs.HdfsProto.FileInfoInNameNode.Block parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(ds.hdfs.HdfsProto.FileInfoInNameNode.Block prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       * message for NameNode to map a File to block numbers
       * </pre>
       *
       * Protobuf type {@code hdfs.FileInfoInNameNode.Block}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:hdfs.FileInfoInNameNode.Block)
          ds.hdfs.HdfsProto.FileInfoInNameNode.BlockOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ds.hdfs.HdfsProto.internal_static_hdfs_FileInfoInNameNode_Block_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ds.hdfs.HdfsProto.internal_static_hdfs_FileInfoInNameNode_Block_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ds.hdfs.HdfsProto.FileInfoInNameNode.Block.class, ds.hdfs.HdfsProto.FileInfoInNameNode.Block.Builder.class);
        }

        // Construct using ds.hdfs.HdfsProto.FileInfoInNameNode.Block.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
            getDatanodeFieldBuilder();
          }
        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          blocknumber_ = 0;
          bitField0_ = (bitField0_ & ~0x00000001);
          if (datanodeBuilder_ == null) {
            datanode_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            datanodeBuilder_.clear();
          }
          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return ds.hdfs.HdfsProto.internal_static_hdfs_FileInfoInNameNode_Block_descriptor;
        }

        @java.lang.Override
        public ds.hdfs.HdfsProto.FileInfoInNameNode.Block getDefaultInstanceForType() {
          return ds.hdfs.HdfsProto.FileInfoInNameNode.Block.getDefaultInstance();
        }

        @java.lang.Override
        public ds.hdfs.HdfsProto.FileInfoInNameNode.Block build() {
          ds.hdfs.HdfsProto.FileInfoInNameNode.Block result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public ds.hdfs.HdfsProto.FileInfoInNameNode.Block buildPartial() {
          ds.hdfs.HdfsProto.FileInfoInNameNode.Block result = new ds.hdfs.HdfsProto.FileInfoInNameNode.Block(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) != 0)) {
            result.blocknumber_ = blocknumber_;
            to_bitField0_ |= 0x00000001;
          }
          if (datanodeBuilder_ == null) {
            if (((bitField0_ & 0x00000002) != 0)) {
              datanode_ = java.util.Collections.unmodifiableList(datanode_);
              bitField0_ = (bitField0_ & ~0x00000002);
            }
            result.datanode_ = datanode_;
          } else {
            result.datanode_ = datanodeBuilder_.build();
          }
          result.bitField0_ = to_bitField0_;
          onBuilt();
          return result;
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }
        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof ds.hdfs.HdfsProto.FileInfoInNameNode.Block) {
            return mergeFrom((ds.hdfs.HdfsProto.FileInfoInNameNode.Block)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(ds.hdfs.HdfsProto.FileInfoInNameNode.Block other) {
          if (other == ds.hdfs.HdfsProto.FileInfoInNameNode.Block.getDefaultInstance()) return this;
          if (other.hasBlocknumber()) {
            setBlocknumber(other.getBlocknumber());
          }
          if (datanodeBuilder_ == null) {
            if (!other.datanode_.isEmpty()) {
              if (datanode_.isEmpty()) {
                datanode_ = other.datanode_;
                bitField0_ = (bitField0_ & ~0x00000002);
              } else {
                ensureDatanodeIsMutable();
                datanode_.addAll(other.datanode_);
              }
              onChanged();
            }
          } else {
            if (!other.datanode_.isEmpty()) {
              if (datanodeBuilder_.isEmpty()) {
                datanodeBuilder_.dispose();
                datanodeBuilder_ = null;
                datanode_ = other.datanode_;
                bitField0_ = (bitField0_ & ~0x00000002);
                datanodeBuilder_ = 
                  com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                     getDatanodeFieldBuilder() : null;
              } else {
                datanodeBuilder_.addAllMessages(other.datanode_);
              }
            }
          }
          this.mergeUnknownFields(other.unknownFields);
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          if (!hasBlocknumber()) {
            return false;
          }
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          ds.hdfs.HdfsProto.FileInfoInNameNode.Block parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (ds.hdfs.HdfsProto.FileInfoInNameNode.Block) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int bitField0_;

        private int blocknumber_ ;
        /**
         * <code>required int32 blocknumber = 1;</code>
         * @return Whether the blocknumber field is set.
         */
        public boolean hasBlocknumber() {
          return ((bitField0_ & 0x00000001) != 0);
        }
        /**
         * <code>required int32 blocknumber = 1;</code>
         * @return The blocknumber.
         */
        public int getBlocknumber() {
          return blocknumber_;
        }
        /**
         * <code>required int32 blocknumber = 1;</code>
         * @param value The blocknumber to set.
         * @return This builder for chaining.
         */
        public Builder setBlocknumber(int value) {
          bitField0_ |= 0x00000001;
          blocknumber_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>required int32 blocknumber = 1;</code>
         * @return This builder for chaining.
         */
        public Builder clearBlocknumber() {
          bitField0_ = (bitField0_ & ~0x00000001);
          blocknumber_ = 0;
          onChanged();
          return this;
        }

        private java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> datanode_ =
          java.util.Collections.emptyList();
        private void ensureDatanodeIsMutable() {
          if (!((bitField0_ & 0x00000002) != 0)) {
            datanode_ = new java.util.ArrayList<ds.hdfs.HdfsProto.DataNodeInfo>(datanode_);
            bitField0_ |= 0x00000002;
           }
        }

        private com.google.protobuf.RepeatedFieldBuilderV3<
            ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> datanodeBuilder_;

        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> getDatanodeList() {
          if (datanodeBuilder_ == null) {
            return java.util.Collections.unmodifiableList(datanode_);
          } else {
            return datanodeBuilder_.getMessageList();
          }
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public int getDatanodeCount() {
          if (datanodeBuilder_ == null) {
            return datanode_.size();
          } else {
            return datanodeBuilder_.getCount();
          }
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public ds.hdfs.HdfsProto.DataNodeInfo getDatanode(int index) {
          if (datanodeBuilder_ == null) {
            return datanode_.get(index);
          } else {
            return datanodeBuilder_.getMessage(index);
          }
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public Builder setDatanode(
            int index, ds.hdfs.HdfsProto.DataNodeInfo value) {
          if (datanodeBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureDatanodeIsMutable();
            datanode_.set(index, value);
            onChanged();
          } else {
            datanodeBuilder_.setMessage(index, value);
          }
          return this;
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public Builder setDatanode(
            int index, ds.hdfs.HdfsProto.DataNodeInfo.Builder builderForValue) {
          if (datanodeBuilder_ == null) {
            ensureDatanodeIsMutable();
            datanode_.set(index, builderForValue.build());
            onChanged();
          } else {
            datanodeBuilder_.setMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public Builder addDatanode(ds.hdfs.HdfsProto.DataNodeInfo value) {
          if (datanodeBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureDatanodeIsMutable();
            datanode_.add(value);
            onChanged();
          } else {
            datanodeBuilder_.addMessage(value);
          }
          return this;
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public Builder addDatanode(
            int index, ds.hdfs.HdfsProto.DataNodeInfo value) {
          if (datanodeBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureDatanodeIsMutable();
            datanode_.add(index, value);
            onChanged();
          } else {
            datanodeBuilder_.addMessage(index, value);
          }
          return this;
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public Builder addDatanode(
            ds.hdfs.HdfsProto.DataNodeInfo.Builder builderForValue) {
          if (datanodeBuilder_ == null) {
            ensureDatanodeIsMutable();
            datanode_.add(builderForValue.build());
            onChanged();
          } else {
            datanodeBuilder_.addMessage(builderForValue.build());
          }
          return this;
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public Builder addDatanode(
            int index, ds.hdfs.HdfsProto.DataNodeInfo.Builder builderForValue) {
          if (datanodeBuilder_ == null) {
            ensureDatanodeIsMutable();
            datanode_.add(index, builderForValue.build());
            onChanged();
          } else {
            datanodeBuilder_.addMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public Builder addAllDatanode(
            java.lang.Iterable<? extends ds.hdfs.HdfsProto.DataNodeInfo> values) {
          if (datanodeBuilder_ == null) {
            ensureDatanodeIsMutable();
            com.google.protobuf.AbstractMessageLite.Builder.addAll(
                values, datanode_);
            onChanged();
          } else {
            datanodeBuilder_.addAllMessages(values);
          }
          return this;
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public Builder clearDatanode() {
          if (datanodeBuilder_ == null) {
            datanode_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
            onChanged();
          } else {
            datanodeBuilder_.clear();
          }
          return this;
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public Builder removeDatanode(int index) {
          if (datanodeBuilder_ == null) {
            ensureDatanodeIsMutable();
            datanode_.remove(index);
            onChanged();
          } else {
            datanodeBuilder_.remove(index);
          }
          return this;
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public ds.hdfs.HdfsProto.DataNodeInfo.Builder getDatanodeBuilder(
            int index) {
          return getDatanodeFieldBuilder().getBuilder(index);
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getDatanodeOrBuilder(
            int index) {
          if (datanodeBuilder_ == null) {
            return datanode_.get(index);  } else {
            return datanodeBuilder_.getMessageOrBuilder(index);
          }
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public java.util.List<? extends ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
             getDatanodeOrBuilderList() {
          if (datanodeBuilder_ != null) {
            return datanodeBuilder_.getMessageOrBuilderList();
          } else {
            return java.util.Collections.unmodifiableList(datanode_);
          }
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public ds.hdfs.HdfsProto.DataNodeInfo.Builder addDatanodeBuilder() {
          return getDatanodeFieldBuilder().addBuilder(
              ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance());
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public ds.hdfs.HdfsProto.DataNodeInfo.Builder addDatanodeBuilder(
            int index) {
          return getDatanodeFieldBuilder().addBuilder(
              index, ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance());
        }
        /**
         * <pre>
         * // message for NameNode to map the block to Data Node ips
         *message DataNode{
         *optional string servername = 1;
         *optional string ipaddr = 2;
         *optional int32  portnum = 3;
         *}
         * </pre>
         *
         * <code>repeated .hdfs.DataNodeInfo datanode = 2;</code>
         */
        public java.util.List<ds.hdfs.HdfsProto.DataNodeInfo.Builder> 
             getDatanodeBuilderList() {
          return getDatanodeFieldBuilder().getBuilderList();
        }
        private com.google.protobuf.RepeatedFieldBuilderV3<
            ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
            getDatanodeFieldBuilder() {
          if (datanodeBuilder_ == null) {
            datanodeBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
                ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder>(
                    datanode_,
                    ((bitField0_ & 0x00000002) != 0),
                    getParentForChildren(),
                    isClean());
            datanode_ = null;
          }
          return datanodeBuilder_;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:hdfs.FileInfoInNameNode.Block)
      }

      // @@protoc_insertion_point(class_scope:hdfs.FileInfoInNameNode.Block)
      private static final ds.hdfs.HdfsProto.FileInfoInNameNode.Block DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.FileInfoInNameNode.Block();
      }

      public static ds.hdfs.HdfsProto.FileInfoInNameNode.Block getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      @java.lang.Deprecated public static final com.google.protobuf.Parser<Block>
          PARSER = new com.google.protobuf.AbstractParser<Block>() {
        @java.lang.Override
        public Block parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new Block(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Block> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<Block> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.FileInfoInNameNode.Block getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    private int bitField0_;
    public static final int FILENAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object filename_;
    /**
     * <code>required string filename = 1;</code>
     * @return Whether the filename field is set.
     */
    public boolean hasFilename() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string filename = 1;</code>
     * @return The filename.
     */
    public java.lang.String getFilename() {
      java.lang.Object ref = filename_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          filename_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string filename = 1;</code>
     * @return The bytes for filename.
     */
    public com.google.protobuf.ByteString
        getFilenameBytes() {
      java.lang.Object ref = filename_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        filename_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int BLOCK_FIELD_NUMBER = 2;
    private java.util.List<ds.hdfs.HdfsProto.FileInfoInNameNode.Block> block_;
    /**
     * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
     */
    public java.util.List<ds.hdfs.HdfsProto.FileInfoInNameNode.Block> getBlockList() {
      return block_;
    }
    /**
     * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
     */
    public java.util.List<? extends ds.hdfs.HdfsProto.FileInfoInNameNode.BlockOrBuilder> 
        getBlockOrBuilderList() {
      return block_;
    }
    /**
     * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
     */
    public int getBlockCount() {
      return block_.size();
    }
    /**
     * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
     */
    public ds.hdfs.HdfsProto.FileInfoInNameNode.Block getBlock(int index) {
      return block_.get(index);
    }
    /**
     * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
     */
    public ds.hdfs.HdfsProto.FileInfoInNameNode.BlockOrBuilder getBlockOrBuilder(
        int index) {
      return block_.get(index);
    }

    public static final int WRITEMODE_FIELD_NUMBER = 3;
    private boolean writemode_;
    /**
     * <code>optional bool writemode = 3;</code>
     * @return Whether the writemode field is set.
     */
    public boolean hasWritemode() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bool writemode = 3;</code>
     * @return The writemode.
     */
    public boolean getWritemode() {
      return writemode_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasFilename()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getBlockCount(); i++) {
        if (!getBlock(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, filename_);
      }
      for (int i = 0; i < block_.size(); i++) {
        output.writeMessage(2, block_.get(i));
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(3, writemode_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, filename_);
      }
      for (int i = 0; i < block_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, block_.get(i));
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, writemode_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.FileInfoInNameNode)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.FileInfoInNameNode other = (ds.hdfs.HdfsProto.FileInfoInNameNode) obj;

      if (hasFilename() != other.hasFilename()) return false;
      if (hasFilename()) {
        if (!getFilename()
            .equals(other.getFilename())) return false;
      }
      if (!getBlockList()
          .equals(other.getBlockList())) return false;
      if (hasWritemode() != other.hasWritemode()) return false;
      if (hasWritemode()) {
        if (getWritemode()
            != other.getWritemode()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFilename()) {
        hash = (37 * hash) + FILENAME_FIELD_NUMBER;
        hash = (53 * hash) + getFilename().hashCode();
      }
      if (getBlockCount() > 0) {
        hash = (37 * hash) + BLOCK_FIELD_NUMBER;
        hash = (53 * hash) + getBlockList().hashCode();
      }
      if (hasWritemode()) {
        hash = (37 * hash) + WRITEMODE_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getWritemode());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.FileInfoInNameNode parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.FileInfoInNameNode parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.FileInfoInNameNode parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.FileInfoInNameNode parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.FileInfoInNameNode parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.FileInfoInNameNode parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.FileInfoInNameNode parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.FileInfoInNameNode parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.FileInfoInNameNode parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.FileInfoInNameNode parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.FileInfoInNameNode parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.FileInfoInNameNode parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.FileInfoInNameNode prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * message for NameNode to map a file to blocks distributed in different Data Nodes
     * </pre>
     *
     * Protobuf type {@code hdfs.FileInfoInNameNode}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.FileInfoInNameNode)
        ds.hdfs.HdfsProto.FileInfoInNameNodeOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_FileInfoInNameNode_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_FileInfoInNameNode_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.FileInfoInNameNode.class, ds.hdfs.HdfsProto.FileInfoInNameNode.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.FileInfoInNameNode.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getBlockFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        filename_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        if (blockBuilder_ == null) {
          block_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          blockBuilder_.clear();
        }
        writemode_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_FileInfoInNameNode_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.FileInfoInNameNode getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.FileInfoInNameNode.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.FileInfoInNameNode build() {
        ds.hdfs.HdfsProto.FileInfoInNameNode result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.FileInfoInNameNode buildPartial() {
        ds.hdfs.HdfsProto.FileInfoInNameNode result = new ds.hdfs.HdfsProto.FileInfoInNameNode(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.filename_ = filename_;
        if (blockBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0)) {
            block_ = java.util.Collections.unmodifiableList(block_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.block_ = block_;
        } else {
          result.block_ = blockBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.writemode_ = writemode_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.FileInfoInNameNode) {
          return mergeFrom((ds.hdfs.HdfsProto.FileInfoInNameNode)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.FileInfoInNameNode other) {
        if (other == ds.hdfs.HdfsProto.FileInfoInNameNode.getDefaultInstance()) return this;
        if (other.hasFilename()) {
          bitField0_ |= 0x00000001;
          filename_ = other.filename_;
          onChanged();
        }
        if (blockBuilder_ == null) {
          if (!other.block_.isEmpty()) {
            if (block_.isEmpty()) {
              block_ = other.block_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureBlockIsMutable();
              block_.addAll(other.block_);
            }
            onChanged();
          }
        } else {
          if (!other.block_.isEmpty()) {
            if (blockBuilder_.isEmpty()) {
              blockBuilder_.dispose();
              blockBuilder_ = null;
              block_ = other.block_;
              bitField0_ = (bitField0_ & ~0x00000002);
              blockBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getBlockFieldBuilder() : null;
            } else {
              blockBuilder_.addAllMessages(other.block_);
            }
          }
        }
        if (other.hasWritemode()) {
          setWritemode(other.getWritemode());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasFilename()) {
          return false;
        }
        for (int i = 0; i < getBlockCount(); i++) {
          if (!getBlock(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.FileInfoInNameNode parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.FileInfoInNameNode) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object filename_ = "";
      /**
       * <code>required string filename = 1;</code>
       * @return Whether the filename field is set.
       */
      public boolean hasFilename() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string filename = 1;</code>
       * @return The filename.
       */
      public java.lang.String getFilename() {
        java.lang.Object ref = filename_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            filename_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string filename = 1;</code>
       * @return The bytes for filename.
       */
      public com.google.protobuf.ByteString
          getFilenameBytes() {
        java.lang.Object ref = filename_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          filename_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string filename = 1;</code>
       * @param value The filename to set.
       * @return This builder for chaining.
       */
      public Builder setFilename(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        filename_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string filename = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearFilename() {
        bitField0_ = (bitField0_ & ~0x00000001);
        filename_ = getDefaultInstance().getFilename();
        onChanged();
        return this;
      }
      /**
       * <code>required string filename = 1;</code>
       * @param value The bytes for filename to set.
       * @return This builder for chaining.
       */
      public Builder setFilenameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        filename_ = value;
        onChanged();
        return this;
      }

      private java.util.List<ds.hdfs.HdfsProto.FileInfoInNameNode.Block> block_ =
        java.util.Collections.emptyList();
      private void ensureBlockIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          block_ = new java.util.ArrayList<ds.hdfs.HdfsProto.FileInfoInNameNode.Block>(block_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          ds.hdfs.HdfsProto.FileInfoInNameNode.Block, ds.hdfs.HdfsProto.FileInfoInNameNode.Block.Builder, ds.hdfs.HdfsProto.FileInfoInNameNode.BlockOrBuilder> blockBuilder_;

      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public java.util.List<ds.hdfs.HdfsProto.FileInfoInNameNode.Block> getBlockList() {
        if (blockBuilder_ == null) {
          return java.util.Collections.unmodifiableList(block_);
        } else {
          return blockBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public int getBlockCount() {
        if (blockBuilder_ == null) {
          return block_.size();
        } else {
          return blockBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public ds.hdfs.HdfsProto.FileInfoInNameNode.Block getBlock(int index) {
        if (blockBuilder_ == null) {
          return block_.get(index);
        } else {
          return blockBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public Builder setBlock(
          int index, ds.hdfs.HdfsProto.FileInfoInNameNode.Block value) {
        if (blockBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureBlockIsMutable();
          block_.set(index, value);
          onChanged();
        } else {
          blockBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public Builder setBlock(
          int index, ds.hdfs.HdfsProto.FileInfoInNameNode.Block.Builder builderForValue) {
        if (blockBuilder_ == null) {
          ensureBlockIsMutable();
          block_.set(index, builderForValue.build());
          onChanged();
        } else {
          blockBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public Builder addBlock(ds.hdfs.HdfsProto.FileInfoInNameNode.Block value) {
        if (blockBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureBlockIsMutable();
          block_.add(value);
          onChanged();
        } else {
          blockBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public Builder addBlock(
          int index, ds.hdfs.HdfsProto.FileInfoInNameNode.Block value) {
        if (blockBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureBlockIsMutable();
          block_.add(index, value);
          onChanged();
        } else {
          blockBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public Builder addBlock(
          ds.hdfs.HdfsProto.FileInfoInNameNode.Block.Builder builderForValue) {
        if (blockBuilder_ == null) {
          ensureBlockIsMutable();
          block_.add(builderForValue.build());
          onChanged();
        } else {
          blockBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public Builder addBlock(
          int index, ds.hdfs.HdfsProto.FileInfoInNameNode.Block.Builder builderForValue) {
        if (blockBuilder_ == null) {
          ensureBlockIsMutable();
          block_.add(index, builderForValue.build());
          onChanged();
        } else {
          blockBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public Builder addAllBlock(
          java.lang.Iterable<? extends ds.hdfs.HdfsProto.FileInfoInNameNode.Block> values) {
        if (blockBuilder_ == null) {
          ensureBlockIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, block_);
          onChanged();
        } else {
          blockBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public Builder clearBlock() {
        if (blockBuilder_ == null) {
          block_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          blockBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public Builder removeBlock(int index) {
        if (blockBuilder_ == null) {
          ensureBlockIsMutable();
          block_.remove(index);
          onChanged();
        } else {
          blockBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public ds.hdfs.HdfsProto.FileInfoInNameNode.Block.Builder getBlockBuilder(
          int index) {
        return getBlockFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public ds.hdfs.HdfsProto.FileInfoInNameNode.BlockOrBuilder getBlockOrBuilder(
          int index) {
        if (blockBuilder_ == null) {
          return block_.get(index);  } else {
          return blockBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public java.util.List<? extends ds.hdfs.HdfsProto.FileInfoInNameNode.BlockOrBuilder> 
           getBlockOrBuilderList() {
        if (blockBuilder_ != null) {
          return blockBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(block_);
        }
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public ds.hdfs.HdfsProto.FileInfoInNameNode.Block.Builder addBlockBuilder() {
        return getBlockFieldBuilder().addBuilder(
            ds.hdfs.HdfsProto.FileInfoInNameNode.Block.getDefaultInstance());
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public ds.hdfs.HdfsProto.FileInfoInNameNode.Block.Builder addBlockBuilder(
          int index) {
        return getBlockFieldBuilder().addBuilder(
            index, ds.hdfs.HdfsProto.FileInfoInNameNode.Block.getDefaultInstance());
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode.Block block = 2;</code>
       */
      public java.util.List<ds.hdfs.HdfsProto.FileInfoInNameNode.Block.Builder> 
           getBlockBuilderList() {
        return getBlockFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          ds.hdfs.HdfsProto.FileInfoInNameNode.Block, ds.hdfs.HdfsProto.FileInfoInNameNode.Block.Builder, ds.hdfs.HdfsProto.FileInfoInNameNode.BlockOrBuilder> 
          getBlockFieldBuilder() {
        if (blockBuilder_ == null) {
          blockBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              ds.hdfs.HdfsProto.FileInfoInNameNode.Block, ds.hdfs.HdfsProto.FileInfoInNameNode.Block.Builder, ds.hdfs.HdfsProto.FileInfoInNameNode.BlockOrBuilder>(
                  block_,
                  ((bitField0_ & 0x00000002) != 0),
                  getParentForChildren(),
                  isClean());
          block_ = null;
        }
        return blockBuilder_;
      }

      private boolean writemode_ ;
      /**
       * <code>optional bool writemode = 3;</code>
       * @return Whether the writemode field is set.
       */
      public boolean hasWritemode() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bool writemode = 3;</code>
       * @return The writemode.
       */
      public boolean getWritemode() {
        return writemode_;
      }
      /**
       * <code>optional bool writemode = 3;</code>
       * @param value The writemode to set.
       * @return This builder for chaining.
       */
      public Builder setWritemode(boolean value) {
        bitField0_ |= 0x00000004;
        writemode_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool writemode = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearWritemode() {
        bitField0_ = (bitField0_ & ~0x00000004);
        writemode_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.FileInfoInNameNode)
    }

    // @@protoc_insertion_point(class_scope:hdfs.FileInfoInNameNode)
    private static final ds.hdfs.HdfsProto.FileInfoInNameNode DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.FileInfoInNameNode();
    }

    public static ds.hdfs.HdfsProto.FileInfoInNameNode getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<FileInfoInNameNode>
        PARSER = new com.google.protobuf.AbstractParser<FileInfoInNameNode>() {
      @java.lang.Override
      public FileInfoInNameNode parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new FileInfoInNameNode(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<FileInfoInNameNode> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<FileInfoInNameNode> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.FileInfoInNameNode getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FileListInNameNodeOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.FileListInNameNode)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
     */
    java.util.List<ds.hdfs.HdfsProto.FileInfoInNameNode> 
        getFileList();
    /**
     * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
     */
    ds.hdfs.HdfsProto.FileInfoInNameNode getFile(int index);
    /**
     * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
     */
    int getFileCount();
    /**
     * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
     */
    java.util.List<? extends ds.hdfs.HdfsProto.FileInfoInNameNodeOrBuilder> 
        getFileOrBuilderList();
    /**
     * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
     */
    ds.hdfs.HdfsProto.FileInfoInNameNodeOrBuilder getFileOrBuilder(
        int index);
  }
  /**
   * <pre>
   *message for NameNode to handle the list of files
   * </pre>
   *
   * Protobuf type {@code hdfs.FileListInNameNode}
   */
  public  static final class FileListInNameNode extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.FileListInNameNode)
      FileListInNameNodeOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use FileListInNameNode.newBuilder() to construct.
    private FileListInNameNode(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FileListInNameNode() {
      file_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new FileListInNameNode();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private FileListInNameNode(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                file_ = new java.util.ArrayList<ds.hdfs.HdfsProto.FileInfoInNameNode>();
                mutable_bitField0_ |= 0x00000001;
              }
              file_.add(
                  input.readMessage(ds.hdfs.HdfsProto.FileInfoInNameNode.PARSER, extensionRegistry));
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          file_ = java.util.Collections.unmodifiableList(file_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_FileListInNameNode_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_FileListInNameNode_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.FileListInNameNode.class, ds.hdfs.HdfsProto.FileListInNameNode.Builder.class);
    }

    public static final int FILE_FIELD_NUMBER = 1;
    private java.util.List<ds.hdfs.HdfsProto.FileInfoInNameNode> file_;
    /**
     * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
     */
    public java.util.List<ds.hdfs.HdfsProto.FileInfoInNameNode> getFileList() {
      return file_;
    }
    /**
     * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
     */
    public java.util.List<? extends ds.hdfs.HdfsProto.FileInfoInNameNodeOrBuilder> 
        getFileOrBuilderList() {
      return file_;
    }
    /**
     * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
     */
    public int getFileCount() {
      return file_.size();
    }
    /**
     * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
     */
    public ds.hdfs.HdfsProto.FileInfoInNameNode getFile(int index) {
      return file_.get(index);
    }
    /**
     * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
     */
    public ds.hdfs.HdfsProto.FileInfoInNameNodeOrBuilder getFileOrBuilder(
        int index) {
      return file_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getFileCount(); i++) {
        if (!getFile(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < file_.size(); i++) {
        output.writeMessage(1, file_.get(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < file_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, file_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.FileListInNameNode)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.FileListInNameNode other = (ds.hdfs.HdfsProto.FileListInNameNode) obj;

      if (!getFileList()
          .equals(other.getFileList())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getFileCount() > 0) {
        hash = (37 * hash) + FILE_FIELD_NUMBER;
        hash = (53 * hash) + getFileList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.FileListInNameNode parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.FileListInNameNode parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.FileListInNameNode parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.FileListInNameNode parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.FileListInNameNode parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.FileListInNameNode parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.FileListInNameNode parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.FileListInNameNode parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.FileListInNameNode parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.FileListInNameNode parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.FileListInNameNode parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.FileListInNameNode parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.FileListInNameNode prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *message for NameNode to handle the list of files
     * </pre>
     *
     * Protobuf type {@code hdfs.FileListInNameNode}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.FileListInNameNode)
        ds.hdfs.HdfsProto.FileListInNameNodeOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_FileListInNameNode_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_FileListInNameNode_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.FileListInNameNode.class, ds.hdfs.HdfsProto.FileListInNameNode.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.FileListInNameNode.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getFileFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (fileBuilder_ == null) {
          file_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          fileBuilder_.clear();
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_FileListInNameNode_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.FileListInNameNode getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.FileListInNameNode.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.FileListInNameNode build() {
        ds.hdfs.HdfsProto.FileListInNameNode result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.FileListInNameNode buildPartial() {
        ds.hdfs.HdfsProto.FileListInNameNode result = new ds.hdfs.HdfsProto.FileListInNameNode(this);
        int from_bitField0_ = bitField0_;
        if (fileBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            file_ = java.util.Collections.unmodifiableList(file_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.file_ = file_;
        } else {
          result.file_ = fileBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.FileListInNameNode) {
          return mergeFrom((ds.hdfs.HdfsProto.FileListInNameNode)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.FileListInNameNode other) {
        if (other == ds.hdfs.HdfsProto.FileListInNameNode.getDefaultInstance()) return this;
        if (fileBuilder_ == null) {
          if (!other.file_.isEmpty()) {
            if (file_.isEmpty()) {
              file_ = other.file_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureFileIsMutable();
              file_.addAll(other.file_);
            }
            onChanged();
          }
        } else {
          if (!other.file_.isEmpty()) {
            if (fileBuilder_.isEmpty()) {
              fileBuilder_.dispose();
              fileBuilder_ = null;
              file_ = other.file_;
              bitField0_ = (bitField0_ & ~0x00000001);
              fileBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getFileFieldBuilder() : null;
            } else {
              fileBuilder_.addAllMessages(other.file_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getFileCount(); i++) {
          if (!getFile(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.FileListInNameNode parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.FileListInNameNode) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<ds.hdfs.HdfsProto.FileInfoInNameNode> file_ =
        java.util.Collections.emptyList();
      private void ensureFileIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          file_ = new java.util.ArrayList<ds.hdfs.HdfsProto.FileInfoInNameNode>(file_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          ds.hdfs.HdfsProto.FileInfoInNameNode, ds.hdfs.HdfsProto.FileInfoInNameNode.Builder, ds.hdfs.HdfsProto.FileInfoInNameNodeOrBuilder> fileBuilder_;

      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public java.util.List<ds.hdfs.HdfsProto.FileInfoInNameNode> getFileList() {
        if (fileBuilder_ == null) {
          return java.util.Collections.unmodifiableList(file_);
        } else {
          return fileBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public int getFileCount() {
        if (fileBuilder_ == null) {
          return file_.size();
        } else {
          return fileBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public ds.hdfs.HdfsProto.FileInfoInNameNode getFile(int index) {
        if (fileBuilder_ == null) {
          return file_.get(index);
        } else {
          return fileBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public Builder setFile(
          int index, ds.hdfs.HdfsProto.FileInfoInNameNode value) {
        if (fileBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFileIsMutable();
          file_.set(index, value);
          onChanged();
        } else {
          fileBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public Builder setFile(
          int index, ds.hdfs.HdfsProto.FileInfoInNameNode.Builder builderForValue) {
        if (fileBuilder_ == null) {
          ensureFileIsMutable();
          file_.set(index, builderForValue.build());
          onChanged();
        } else {
          fileBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public Builder addFile(ds.hdfs.HdfsProto.FileInfoInNameNode value) {
        if (fileBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFileIsMutable();
          file_.add(value);
          onChanged();
        } else {
          fileBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public Builder addFile(
          int index, ds.hdfs.HdfsProto.FileInfoInNameNode value) {
        if (fileBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFileIsMutable();
          file_.add(index, value);
          onChanged();
        } else {
          fileBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public Builder addFile(
          ds.hdfs.HdfsProto.FileInfoInNameNode.Builder builderForValue) {
        if (fileBuilder_ == null) {
          ensureFileIsMutable();
          file_.add(builderForValue.build());
          onChanged();
        } else {
          fileBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public Builder addFile(
          int index, ds.hdfs.HdfsProto.FileInfoInNameNode.Builder builderForValue) {
        if (fileBuilder_ == null) {
          ensureFileIsMutable();
          file_.add(index, builderForValue.build());
          onChanged();
        } else {
          fileBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public Builder addAllFile(
          java.lang.Iterable<? extends ds.hdfs.HdfsProto.FileInfoInNameNode> values) {
        if (fileBuilder_ == null) {
          ensureFileIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, file_);
          onChanged();
        } else {
          fileBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public Builder clearFile() {
        if (fileBuilder_ == null) {
          file_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          fileBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public Builder removeFile(int index) {
        if (fileBuilder_ == null) {
          ensureFileIsMutable();
          file_.remove(index);
          onChanged();
        } else {
          fileBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public ds.hdfs.HdfsProto.FileInfoInNameNode.Builder getFileBuilder(
          int index) {
        return getFileFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public ds.hdfs.HdfsProto.FileInfoInNameNodeOrBuilder getFileOrBuilder(
          int index) {
        if (fileBuilder_ == null) {
          return file_.get(index);  } else {
          return fileBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public java.util.List<? extends ds.hdfs.HdfsProto.FileInfoInNameNodeOrBuilder> 
           getFileOrBuilderList() {
        if (fileBuilder_ != null) {
          return fileBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(file_);
        }
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public ds.hdfs.HdfsProto.FileInfoInNameNode.Builder addFileBuilder() {
        return getFileFieldBuilder().addBuilder(
            ds.hdfs.HdfsProto.FileInfoInNameNode.getDefaultInstance());
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public ds.hdfs.HdfsProto.FileInfoInNameNode.Builder addFileBuilder(
          int index) {
        return getFileFieldBuilder().addBuilder(
            index, ds.hdfs.HdfsProto.FileInfoInNameNode.getDefaultInstance());
      }
      /**
       * <code>repeated .hdfs.FileInfoInNameNode file = 1;</code>
       */
      public java.util.List<ds.hdfs.HdfsProto.FileInfoInNameNode.Builder> 
           getFileBuilderList() {
        return getFileFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          ds.hdfs.HdfsProto.FileInfoInNameNode, ds.hdfs.HdfsProto.FileInfoInNameNode.Builder, ds.hdfs.HdfsProto.FileInfoInNameNodeOrBuilder> 
          getFileFieldBuilder() {
        if (fileBuilder_ == null) {
          fileBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              ds.hdfs.HdfsProto.FileInfoInNameNode, ds.hdfs.HdfsProto.FileInfoInNameNode.Builder, ds.hdfs.HdfsProto.FileInfoInNameNodeOrBuilder>(
                  file_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          file_ = null;
        }
        return fileBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.FileListInNameNode)
    }

    // @@protoc_insertion_point(class_scope:hdfs.FileListInNameNode)
    private static final ds.hdfs.HdfsProto.FileListInNameNode DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.FileListInNameNode();
    }

    public static ds.hdfs.HdfsProto.FileListInNameNode getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<FileListInNameNode>
        PARSER = new com.google.protobuf.AbstractParser<FileListInNameNode>() {
      @java.lang.Override
      public FileListInNameNode parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new FileListInNameNode(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<FileListInNameNode> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<FileListInNameNode> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.FileListInNameNode getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface BlocksInDataNodeOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.BlocksInDataNode)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
     */
    java.util.List<ds.hdfs.HdfsProto.BlocksInDataNode.Block> 
        getBlockList();
    /**
     * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
     */
    ds.hdfs.HdfsProto.BlocksInDataNode.Block getBlock(int index);
    /**
     * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
     */
    int getBlockCount();
    /**
     * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
     */
    java.util.List<? extends ds.hdfs.HdfsProto.BlocksInDataNode.BlockOrBuilder> 
        getBlockOrBuilderList();
    /**
     * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
     */
    ds.hdfs.HdfsProto.BlocksInDataNode.BlockOrBuilder getBlockOrBuilder(
        int index);
  }
  /**
   * <pre>
   * message for DataNode to map the blocks to local location
   * </pre>
   *
   * Protobuf type {@code hdfs.BlocksInDataNode}
   */
  public  static final class BlocksInDataNode extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.BlocksInDataNode)
      BlocksInDataNodeOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use BlocksInDataNode.newBuilder() to construct.
    private BlocksInDataNode(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private BlocksInDataNode() {
      block_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new BlocksInDataNode();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private BlocksInDataNode(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                block_ = new java.util.ArrayList<ds.hdfs.HdfsProto.BlocksInDataNode.Block>();
                mutable_bitField0_ |= 0x00000001;
              }
              block_.add(
                  input.readMessage(ds.hdfs.HdfsProto.BlocksInDataNode.Block.PARSER, extensionRegistry));
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          block_ = java.util.Collections.unmodifiableList(block_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_BlocksInDataNode_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_BlocksInDataNode_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.BlocksInDataNode.class, ds.hdfs.HdfsProto.BlocksInDataNode.Builder.class);
    }

    public interface BlockOrBuilder extends
        // @@protoc_insertion_point(interface_extends:hdfs.BlocksInDataNode.Block)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <code>required int32 blocknumber = 1;</code>
       * @return Whether the blocknumber field is set.
       */
      boolean hasBlocknumber();
      /**
       * <code>required int32 blocknumber = 1;</code>
       * @return The blocknumber.
       */
      int getBlocknumber();

      /**
       * <code>optional string path = 2;</code>
       * @return Whether the path field is set.
       */
      boolean hasPath();
      /**
       * <code>optional string path = 2;</code>
       * @return The path.
       */
      java.lang.String getPath();
      /**
       * <code>optional string path = 2;</code>
       * @return The bytes for path.
       */
      com.google.protobuf.ByteString
          getPathBytes();
    }
    /**
     * Protobuf type {@code hdfs.BlocksInDataNode.Block}
     */
    public  static final class Block extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:hdfs.BlocksInDataNode.Block)
        BlockOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use Block.newBuilder() to construct.
      private Block(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Block() {
        path_ = "";
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(
          UnusedPrivateParameter unused) {
        return new Block();
      }

      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return this.unknownFields;
      }
      private Block(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        int mutable_bitField0_ = 0;
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                bitField0_ |= 0x00000001;
                blocknumber_ = input.readInt32();
                break;
              }
              case 18: {
                com.google.protobuf.ByteString bs = input.readBytes();
                bitField0_ |= 0x00000002;
                path_ = bs;
                break;
              }
              default: {
                if (!parseUnknownField(
                    input, unknownFields, extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlocksInDataNode_Block_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlocksInDataNode_Block_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.BlocksInDataNode.Block.class, ds.hdfs.HdfsProto.BlocksInDataNode.Block.Builder.class);
      }

      private int bitField0_;
      public static final int BLOCKNUMBER_FIELD_NUMBER = 1;
      private int blocknumber_;
      /**
       * <code>required int32 blocknumber = 1;</code>
       * @return Whether the blocknumber field is set.
       */
      public boolean hasBlocknumber() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required int32 blocknumber = 1;</code>
       * @return The blocknumber.
       */
      public int getBlocknumber() {
        return blocknumber_;
      }

      public static final int PATH_FIELD_NUMBER = 2;
      private volatile java.lang.Object path_;
      /**
       * <code>optional string path = 2;</code>
       * @return Whether the path field is set.
       */
      public boolean hasPath() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional string path = 2;</code>
       * @return The path.
       */
      public java.lang.String getPath() {
        java.lang.Object ref = path_;
        if (ref instanceof java.lang.String) {
          return (java.lang.String) ref;
        } else {
          com.google.protobuf.ByteString bs = 
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            path_ = s;
          }
          return s;
        }
      }
      /**
       * <code>optional string path = 2;</code>
       * @return The bytes for path.
       */
      public com.google.protobuf.ByteString
          getPathBytes() {
        java.lang.Object ref = path_;
        if (ref instanceof java.lang.String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          path_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        if (!hasBlocknumber()) {
          memoizedIsInitialized = 0;
          return false;
        }
        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (((bitField0_ & 0x00000001) != 0)) {
          output.writeInt32(1, blocknumber_);
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          com.google.protobuf.GeneratedMessageV3.writeString(output, 2, path_);
        }
        unknownFields.writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (((bitField0_ & 0x00000001) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt32Size(1, blocknumber_);
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, path_);
        }
        size += unknownFields.getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof ds.hdfs.HdfsProto.BlocksInDataNode.Block)) {
          return super.equals(obj);
        }
        ds.hdfs.HdfsProto.BlocksInDataNode.Block other = (ds.hdfs.HdfsProto.BlocksInDataNode.Block) obj;

        if (hasBlocknumber() != other.hasBlocknumber()) return false;
        if (hasBlocknumber()) {
          if (getBlocknumber()
              != other.getBlocknumber()) return false;
        }
        if (hasPath() != other.hasPath()) return false;
        if (hasPath()) {
          if (!getPath()
              .equals(other.getPath())) return false;
        }
        if (!unknownFields.equals(other.unknownFields)) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        if (hasBlocknumber()) {
          hash = (37 * hash) + BLOCKNUMBER_FIELD_NUMBER;
          hash = (53 * hash) + getBlocknumber();
        }
        if (hasPath()) {
          hash = (37 * hash) + PATH_FIELD_NUMBER;
          hash = (53 * hash) + getPath().hashCode();
        }
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static ds.hdfs.HdfsProto.BlocksInDataNode.Block parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ds.hdfs.HdfsProto.BlocksInDataNode.Block parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ds.hdfs.HdfsProto.BlocksInDataNode.Block parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ds.hdfs.HdfsProto.BlocksInDataNode.Block parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ds.hdfs.HdfsProto.BlocksInDataNode.Block parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ds.hdfs.HdfsProto.BlocksInDataNode.Block parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ds.hdfs.HdfsProto.BlocksInDataNode.Block parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ds.hdfs.HdfsProto.BlocksInDataNode.Block parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static ds.hdfs.HdfsProto.BlocksInDataNode.Block parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static ds.hdfs.HdfsProto.BlocksInDataNode.Block parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static ds.hdfs.HdfsProto.BlocksInDataNode.Block parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ds.hdfs.HdfsProto.BlocksInDataNode.Block parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(ds.hdfs.HdfsProto.BlocksInDataNode.Block prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code hdfs.BlocksInDataNode.Block}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:hdfs.BlocksInDataNode.Block)
          ds.hdfs.HdfsProto.BlocksInDataNode.BlockOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ds.hdfs.HdfsProto.internal_static_hdfs_BlocksInDataNode_Block_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ds.hdfs.HdfsProto.internal_static_hdfs_BlocksInDataNode_Block_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ds.hdfs.HdfsProto.BlocksInDataNode.Block.class, ds.hdfs.HdfsProto.BlocksInDataNode.Block.Builder.class);
        }

        // Construct using ds.hdfs.HdfsProto.BlocksInDataNode.Block.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          blocknumber_ = 0;
          bitField0_ = (bitField0_ & ~0x00000001);
          path_ = "";
          bitField0_ = (bitField0_ & ~0x00000002);
          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return ds.hdfs.HdfsProto.internal_static_hdfs_BlocksInDataNode_Block_descriptor;
        }

        @java.lang.Override
        public ds.hdfs.HdfsProto.BlocksInDataNode.Block getDefaultInstanceForType() {
          return ds.hdfs.HdfsProto.BlocksInDataNode.Block.getDefaultInstance();
        }

        @java.lang.Override
        public ds.hdfs.HdfsProto.BlocksInDataNode.Block build() {
          ds.hdfs.HdfsProto.BlocksInDataNode.Block result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public ds.hdfs.HdfsProto.BlocksInDataNode.Block buildPartial() {
          ds.hdfs.HdfsProto.BlocksInDataNode.Block result = new ds.hdfs.HdfsProto.BlocksInDataNode.Block(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) != 0)) {
            result.blocknumber_ = blocknumber_;
            to_bitField0_ |= 0x00000001;
          }
          if (((from_bitField0_ & 0x00000002) != 0)) {
            to_bitField0_ |= 0x00000002;
          }
          result.path_ = path_;
          result.bitField0_ = to_bitField0_;
          onBuilt();
          return result;
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }
        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof ds.hdfs.HdfsProto.BlocksInDataNode.Block) {
            return mergeFrom((ds.hdfs.HdfsProto.BlocksInDataNode.Block)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(ds.hdfs.HdfsProto.BlocksInDataNode.Block other) {
          if (other == ds.hdfs.HdfsProto.BlocksInDataNode.Block.getDefaultInstance()) return this;
          if (other.hasBlocknumber()) {
            setBlocknumber(other.getBlocknumber());
          }
          if (other.hasPath()) {
            bitField0_ |= 0x00000002;
            path_ = other.path_;
            onChanged();
          }
          this.mergeUnknownFields(other.unknownFields);
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          if (!hasBlocknumber()) {
            return false;
          }
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          ds.hdfs.HdfsProto.BlocksInDataNode.Block parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (ds.hdfs.HdfsProto.BlocksInDataNode.Block) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int bitField0_;

        private int blocknumber_ ;
        /**
         * <code>required int32 blocknumber = 1;</code>
         * @return Whether the blocknumber field is set.
         */
        public boolean hasBlocknumber() {
          return ((bitField0_ & 0x00000001) != 0);
        }
        /**
         * <code>required int32 blocknumber = 1;</code>
         * @return The blocknumber.
         */
        public int getBlocknumber() {
          return blocknumber_;
        }
        /**
         * <code>required int32 blocknumber = 1;</code>
         * @param value The blocknumber to set.
         * @return This builder for chaining.
         */
        public Builder setBlocknumber(int value) {
          bitField0_ |= 0x00000001;
          blocknumber_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>required int32 blocknumber = 1;</code>
         * @return This builder for chaining.
         */
        public Builder clearBlocknumber() {
          bitField0_ = (bitField0_ & ~0x00000001);
          blocknumber_ = 0;
          onChanged();
          return this;
        }

        private java.lang.Object path_ = "";
        /**
         * <code>optional string path = 2;</code>
         * @return Whether the path field is set.
         */
        public boolean hasPath() {
          return ((bitField0_ & 0x00000002) != 0);
        }
        /**
         * <code>optional string path = 2;</code>
         * @return The path.
         */
        public java.lang.String getPath() {
          java.lang.Object ref = path_;
          if (!(ref instanceof java.lang.String)) {
            com.google.protobuf.ByteString bs =
                (com.google.protobuf.ByteString) ref;
            java.lang.String s = bs.toStringUtf8();
            if (bs.isValidUtf8()) {
              path_ = s;
            }
            return s;
          } else {
            return (java.lang.String) ref;
          }
        }
        /**
         * <code>optional string path = 2;</code>
         * @return The bytes for path.
         */
        public com.google.protobuf.ByteString
            getPathBytes() {
          java.lang.Object ref = path_;
          if (ref instanceof String) {
            com.google.protobuf.ByteString b = 
                com.google.protobuf.ByteString.copyFromUtf8(
                    (java.lang.String) ref);
            path_ = b;
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }
        /**
         * <code>optional string path = 2;</code>
         * @param value The path to set.
         * @return This builder for chaining.
         */
        public Builder setPath(
            java.lang.String value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
          path_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional string path = 2;</code>
         * @return This builder for chaining.
         */
        public Builder clearPath() {
          bitField0_ = (bitField0_ & ~0x00000002);
          path_ = getDefaultInstance().getPath();
          onChanged();
          return this;
        }
        /**
         * <code>optional string path = 2;</code>
         * @param value The bytes for path to set.
         * @return This builder for chaining.
         */
        public Builder setPathBytes(
            com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
          path_ = value;
          onChanged();
          return this;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:hdfs.BlocksInDataNode.Block)
      }

      // @@protoc_insertion_point(class_scope:hdfs.BlocksInDataNode.Block)
      private static final ds.hdfs.HdfsProto.BlocksInDataNode.Block DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.BlocksInDataNode.Block();
      }

      public static ds.hdfs.HdfsProto.BlocksInDataNode.Block getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      @java.lang.Deprecated public static final com.google.protobuf.Parser<Block>
          PARSER = new com.google.protobuf.AbstractParser<Block>() {
        @java.lang.Override
        public Block parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new Block(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Block> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<Block> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlocksInDataNode.Block getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public static final int BLOCK_FIELD_NUMBER = 1;
    private java.util.List<ds.hdfs.HdfsProto.BlocksInDataNode.Block> block_;
    /**
     * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
     */
    public java.util.List<ds.hdfs.HdfsProto.BlocksInDataNode.Block> getBlockList() {
      return block_;
    }
    /**
     * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
     */
    public java.util.List<? extends ds.hdfs.HdfsProto.BlocksInDataNode.BlockOrBuilder> 
        getBlockOrBuilderList() {
      return block_;
    }
    /**
     * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
     */
    public int getBlockCount() {
      return block_.size();
    }
    /**
     * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
     */
    public ds.hdfs.HdfsProto.BlocksInDataNode.Block getBlock(int index) {
      return block_.get(index);
    }
    /**
     * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
     */
    public ds.hdfs.HdfsProto.BlocksInDataNode.BlockOrBuilder getBlockOrBuilder(
        int index) {
      return block_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getBlockCount(); i++) {
        if (!getBlock(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < block_.size(); i++) {
        output.writeMessage(1, block_.get(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < block_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, block_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.BlocksInDataNode)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.BlocksInDataNode other = (ds.hdfs.HdfsProto.BlocksInDataNode) obj;

      if (!getBlockList()
          .equals(other.getBlockList())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getBlockCount() > 0) {
        hash = (37 * hash) + BLOCK_FIELD_NUMBER;
        hash = (53 * hash) + getBlockList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.BlocksInDataNode parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.BlocksInDataNode parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlocksInDataNode parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.BlocksInDataNode parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlocksInDataNode parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.BlocksInDataNode parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlocksInDataNode parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.BlocksInDataNode parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlocksInDataNode parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.BlocksInDataNode parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.BlocksInDataNode parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.BlocksInDataNode parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.BlocksInDataNode prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * message for DataNode to map the blocks to local location
     * </pre>
     *
     * Protobuf type {@code hdfs.BlocksInDataNode}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.BlocksInDataNode)
        ds.hdfs.HdfsProto.BlocksInDataNodeOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlocksInDataNode_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlocksInDataNode_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.BlocksInDataNode.class, ds.hdfs.HdfsProto.BlocksInDataNode.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.BlocksInDataNode.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getBlockFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (blockBuilder_ == null) {
          block_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          blockBuilder_.clear();
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_BlocksInDataNode_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlocksInDataNode getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.BlocksInDataNode.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlocksInDataNode build() {
        ds.hdfs.HdfsProto.BlocksInDataNode result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.BlocksInDataNode buildPartial() {
        ds.hdfs.HdfsProto.BlocksInDataNode result = new ds.hdfs.HdfsProto.BlocksInDataNode(this);
        int from_bitField0_ = bitField0_;
        if (blockBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            block_ = java.util.Collections.unmodifiableList(block_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.block_ = block_;
        } else {
          result.block_ = blockBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.BlocksInDataNode) {
          return mergeFrom((ds.hdfs.HdfsProto.BlocksInDataNode)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.BlocksInDataNode other) {
        if (other == ds.hdfs.HdfsProto.BlocksInDataNode.getDefaultInstance()) return this;
        if (blockBuilder_ == null) {
          if (!other.block_.isEmpty()) {
            if (block_.isEmpty()) {
              block_ = other.block_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureBlockIsMutable();
              block_.addAll(other.block_);
            }
            onChanged();
          }
        } else {
          if (!other.block_.isEmpty()) {
            if (blockBuilder_.isEmpty()) {
              blockBuilder_.dispose();
              blockBuilder_ = null;
              block_ = other.block_;
              bitField0_ = (bitField0_ & ~0x00000001);
              blockBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getBlockFieldBuilder() : null;
            } else {
              blockBuilder_.addAllMessages(other.block_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getBlockCount(); i++) {
          if (!getBlock(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.BlocksInDataNode parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.BlocksInDataNode) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<ds.hdfs.HdfsProto.BlocksInDataNode.Block> block_ =
        java.util.Collections.emptyList();
      private void ensureBlockIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          block_ = new java.util.ArrayList<ds.hdfs.HdfsProto.BlocksInDataNode.Block>(block_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          ds.hdfs.HdfsProto.BlocksInDataNode.Block, ds.hdfs.HdfsProto.BlocksInDataNode.Block.Builder, ds.hdfs.HdfsProto.BlocksInDataNode.BlockOrBuilder> blockBuilder_;

      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public java.util.List<ds.hdfs.HdfsProto.BlocksInDataNode.Block> getBlockList() {
        if (blockBuilder_ == null) {
          return java.util.Collections.unmodifiableList(block_);
        } else {
          return blockBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public int getBlockCount() {
        if (blockBuilder_ == null) {
          return block_.size();
        } else {
          return blockBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public ds.hdfs.HdfsProto.BlocksInDataNode.Block getBlock(int index) {
        if (blockBuilder_ == null) {
          return block_.get(index);
        } else {
          return blockBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public Builder setBlock(
          int index, ds.hdfs.HdfsProto.BlocksInDataNode.Block value) {
        if (blockBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureBlockIsMutable();
          block_.set(index, value);
          onChanged();
        } else {
          blockBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public Builder setBlock(
          int index, ds.hdfs.HdfsProto.BlocksInDataNode.Block.Builder builderForValue) {
        if (blockBuilder_ == null) {
          ensureBlockIsMutable();
          block_.set(index, builderForValue.build());
          onChanged();
        } else {
          blockBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public Builder addBlock(ds.hdfs.HdfsProto.BlocksInDataNode.Block value) {
        if (blockBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureBlockIsMutable();
          block_.add(value);
          onChanged();
        } else {
          blockBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public Builder addBlock(
          int index, ds.hdfs.HdfsProto.BlocksInDataNode.Block value) {
        if (blockBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureBlockIsMutable();
          block_.add(index, value);
          onChanged();
        } else {
          blockBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public Builder addBlock(
          ds.hdfs.HdfsProto.BlocksInDataNode.Block.Builder builderForValue) {
        if (blockBuilder_ == null) {
          ensureBlockIsMutable();
          block_.add(builderForValue.build());
          onChanged();
        } else {
          blockBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public Builder addBlock(
          int index, ds.hdfs.HdfsProto.BlocksInDataNode.Block.Builder builderForValue) {
        if (blockBuilder_ == null) {
          ensureBlockIsMutable();
          block_.add(index, builderForValue.build());
          onChanged();
        } else {
          blockBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public Builder addAllBlock(
          java.lang.Iterable<? extends ds.hdfs.HdfsProto.BlocksInDataNode.Block> values) {
        if (blockBuilder_ == null) {
          ensureBlockIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, block_);
          onChanged();
        } else {
          blockBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public Builder clearBlock() {
        if (blockBuilder_ == null) {
          block_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          blockBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public Builder removeBlock(int index) {
        if (blockBuilder_ == null) {
          ensureBlockIsMutable();
          block_.remove(index);
          onChanged();
        } else {
          blockBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public ds.hdfs.HdfsProto.BlocksInDataNode.Block.Builder getBlockBuilder(
          int index) {
        return getBlockFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public ds.hdfs.HdfsProto.BlocksInDataNode.BlockOrBuilder getBlockOrBuilder(
          int index) {
        if (blockBuilder_ == null) {
          return block_.get(index);  } else {
          return blockBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public java.util.List<? extends ds.hdfs.HdfsProto.BlocksInDataNode.BlockOrBuilder> 
           getBlockOrBuilderList() {
        if (blockBuilder_ != null) {
          return blockBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(block_);
        }
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public ds.hdfs.HdfsProto.BlocksInDataNode.Block.Builder addBlockBuilder() {
        return getBlockFieldBuilder().addBuilder(
            ds.hdfs.HdfsProto.BlocksInDataNode.Block.getDefaultInstance());
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public ds.hdfs.HdfsProto.BlocksInDataNode.Block.Builder addBlockBuilder(
          int index) {
        return getBlockFieldBuilder().addBuilder(
            index, ds.hdfs.HdfsProto.BlocksInDataNode.Block.getDefaultInstance());
      }
      /**
       * <code>repeated .hdfs.BlocksInDataNode.Block block = 1;</code>
       */
      public java.util.List<ds.hdfs.HdfsProto.BlocksInDataNode.Block.Builder> 
           getBlockBuilderList() {
        return getBlockFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          ds.hdfs.HdfsProto.BlocksInDataNode.Block, ds.hdfs.HdfsProto.BlocksInDataNode.Block.Builder, ds.hdfs.HdfsProto.BlocksInDataNode.BlockOrBuilder> 
          getBlockFieldBuilder() {
        if (blockBuilder_ == null) {
          blockBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              ds.hdfs.HdfsProto.BlocksInDataNode.Block, ds.hdfs.HdfsProto.BlocksInDataNode.Block.Builder, ds.hdfs.HdfsProto.BlocksInDataNode.BlockOrBuilder>(
                  block_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          block_ = null;
        }
        return blockBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.BlocksInDataNode)
    }

    // @@protoc_insertion_point(class_scope:hdfs.BlocksInDataNode)
    private static final ds.hdfs.HdfsProto.BlocksInDataNode DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.BlocksInDataNode();
    }

    public static ds.hdfs.HdfsProto.BlocksInDataNode getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<BlocksInDataNode>
        PARSER = new com.google.protobuf.AbstractParser<BlocksInDataNode>() {
      @java.lang.Override
      public BlocksInDataNode parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new BlocksInDataNode(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<BlocksInDataNode> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<BlocksInDataNode> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.BlocksInDataNode getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReadBlockRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.ReadBlockRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required int32 blocknumber = 1;</code>
     * @return Whether the blocknumber field is set.
     */
    boolean hasBlocknumber();
    /**
     * <code>required int32 blocknumber = 1;</code>
     * @return The blocknumber.
     */
    int getBlocknumber();
  }
  /**
   * <pre>
   *message to read data from a block
   * </pre>
   *
   * Protobuf type {@code hdfs.ReadBlockRequest}
   */
  public  static final class ReadBlockRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.ReadBlockRequest)
      ReadBlockRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ReadBlockRequest.newBuilder() to construct.
    private ReadBlockRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReadBlockRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ReadBlockRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReadBlockRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              blocknumber_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_ReadBlockRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_ReadBlockRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.ReadBlockRequest.class, ds.hdfs.HdfsProto.ReadBlockRequest.Builder.class);
    }

    private int bitField0_;
    public static final int BLOCKNUMBER_FIELD_NUMBER = 1;
    private int blocknumber_;
    /**
     * <code>required int32 blocknumber = 1;</code>
     * @return Whether the blocknumber field is set.
     */
    public boolean hasBlocknumber() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required int32 blocknumber = 1;</code>
     * @return The blocknumber.
     */
    public int getBlocknumber() {
      return blocknumber_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasBlocknumber()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(1, blocknumber_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, blocknumber_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.ReadBlockRequest)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.ReadBlockRequest other = (ds.hdfs.HdfsProto.ReadBlockRequest) obj;

      if (hasBlocknumber() != other.hasBlocknumber()) return false;
      if (hasBlocknumber()) {
        if (getBlocknumber()
            != other.getBlocknumber()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasBlocknumber()) {
        hash = (37 * hash) + BLOCKNUMBER_FIELD_NUMBER;
        hash = (53 * hash) + getBlocknumber();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.ReadBlockRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.ReadBlockRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ReadBlockRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.ReadBlockRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ReadBlockRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.ReadBlockRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ReadBlockRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.ReadBlockRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ReadBlockRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.ReadBlockRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ReadBlockRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.ReadBlockRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.ReadBlockRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *message to read data from a block
     * </pre>
     *
     * Protobuf type {@code hdfs.ReadBlockRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.ReadBlockRequest)
        ds.hdfs.HdfsProto.ReadBlockRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_ReadBlockRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_ReadBlockRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.ReadBlockRequest.class, ds.hdfs.HdfsProto.ReadBlockRequest.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.ReadBlockRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        blocknumber_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_ReadBlockRequest_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.ReadBlockRequest getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.ReadBlockRequest.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.ReadBlockRequest build() {
        ds.hdfs.HdfsProto.ReadBlockRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.ReadBlockRequest buildPartial() {
        ds.hdfs.HdfsProto.ReadBlockRequest result = new ds.hdfs.HdfsProto.ReadBlockRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.blocknumber_ = blocknumber_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.ReadBlockRequest) {
          return mergeFrom((ds.hdfs.HdfsProto.ReadBlockRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.ReadBlockRequest other) {
        if (other == ds.hdfs.HdfsProto.ReadBlockRequest.getDefaultInstance()) return this;
        if (other.hasBlocknumber()) {
          setBlocknumber(other.getBlocknumber());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasBlocknumber()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.ReadBlockRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.ReadBlockRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int blocknumber_ ;
      /**
       * <code>required int32 blocknumber = 1;</code>
       * @return Whether the blocknumber field is set.
       */
      public boolean hasBlocknumber() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required int32 blocknumber = 1;</code>
       * @return The blocknumber.
       */
      public int getBlocknumber() {
        return blocknumber_;
      }
      /**
       * <code>required int32 blocknumber = 1;</code>
       * @param value The blocknumber to set.
       * @return This builder for chaining.
       */
      public Builder setBlocknumber(int value) {
        bitField0_ |= 0x00000001;
        blocknumber_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required int32 blocknumber = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearBlocknumber() {
        bitField0_ = (bitField0_ & ~0x00000001);
        blocknumber_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.ReadBlockRequest)
    }

    // @@protoc_insertion_point(class_scope:hdfs.ReadBlockRequest)
    private static final ds.hdfs.HdfsProto.ReadBlockRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.ReadBlockRequest();
    }

    public static ds.hdfs.HdfsProto.ReadBlockRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReadBlockRequest>
        PARSER = new com.google.protobuf.AbstractParser<ReadBlockRequest>() {
      @java.lang.Override
      public ReadBlockRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ReadBlockRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReadBlockRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReadBlockRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.ReadBlockRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReadBlockResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.ReadBlockResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional bytes data = 1;</code>
     * @return Whether the data field is set.
     */
    boolean hasData();
    /**
     * <code>optional bytes data = 1;</code>
     * @return The data.
     */
    com.google.protobuf.ByteString getData();

    /**
     * <pre>
     *On error, negative number is returned.
     * </pre>
     *
     * <code>optional int32 status = 2 [default = -1];</code>
     * @return Whether the status field is set.
     */
    boolean hasStatus();
    /**
     * <pre>
     *On error, negative number is returned.
     * </pre>
     *
     * <code>optional int32 status = 2 [default = -1];</code>
     * @return The status.
     */
    int getStatus();
  }
  /**
   * Protobuf type {@code hdfs.ReadBlockResponse}
   */
  public  static final class ReadBlockResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.ReadBlockResponse)
      ReadBlockResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ReadBlockResponse.newBuilder() to construct.
    private ReadBlockResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReadBlockResponse() {
      data_ = com.google.protobuf.ByteString.EMPTY;
      status_ = -1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ReadBlockResponse();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReadBlockResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              bitField0_ |= 0x00000001;
              data_ = input.readBytes();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              status_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_ReadBlockResponse_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_ReadBlockResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.ReadBlockResponse.class, ds.hdfs.HdfsProto.ReadBlockResponse.Builder.class);
    }

    private int bitField0_;
    public static final int DATA_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString data_;
    /**
     * <code>optional bytes data = 1;</code>
     * @return Whether the data field is set.
     */
    public boolean hasData() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional bytes data = 1;</code>
     * @return The data.
     */
    public com.google.protobuf.ByteString getData() {
      return data_;
    }

    public static final int STATUS_FIELD_NUMBER = 2;
    private int status_;
    /**
     * <pre>
     *On error, negative number is returned.
     * </pre>
     *
     * <code>optional int32 status = 2 [default = -1];</code>
     * @return Whether the status field is set.
     */
    public boolean hasStatus() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     *On error, negative number is returned.
     * </pre>
     *
     * <code>optional int32 status = 2 [default = -1];</code>
     * @return The status.
     */
    public int getStatus() {
      return status_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, data_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeInt32(2, status_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, data_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, status_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.ReadBlockResponse)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.ReadBlockResponse other = (ds.hdfs.HdfsProto.ReadBlockResponse) obj;

      if (hasData() != other.hasData()) return false;
      if (hasData()) {
        if (!getData()
            .equals(other.getData())) return false;
      }
      if (hasStatus() != other.hasStatus()) return false;
      if (hasStatus()) {
        if (getStatus()
            != other.getStatus()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasData()) {
        hash = (37 * hash) + DATA_FIELD_NUMBER;
        hash = (53 * hash) + getData().hashCode();
      }
      if (hasStatus()) {
        hash = (37 * hash) + STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getStatus();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.ReadBlockResponse parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.ReadBlockResponse parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ReadBlockResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.ReadBlockResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ReadBlockResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.ReadBlockResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ReadBlockResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.ReadBlockResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ReadBlockResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.ReadBlockResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.ReadBlockResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.ReadBlockResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.ReadBlockResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hdfs.ReadBlockResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.ReadBlockResponse)
        ds.hdfs.HdfsProto.ReadBlockResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_ReadBlockResponse_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_ReadBlockResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.ReadBlockResponse.class, ds.hdfs.HdfsProto.ReadBlockResponse.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.ReadBlockResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        data_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        status_ = -1;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_ReadBlockResponse_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.ReadBlockResponse getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.ReadBlockResponse.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.ReadBlockResponse build() {
        ds.hdfs.HdfsProto.ReadBlockResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.ReadBlockResponse buildPartial() {
        ds.hdfs.HdfsProto.ReadBlockResponse result = new ds.hdfs.HdfsProto.ReadBlockResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.data_ = data_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          to_bitField0_ |= 0x00000002;
        }
        result.status_ = status_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.ReadBlockResponse) {
          return mergeFrom((ds.hdfs.HdfsProto.ReadBlockResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.ReadBlockResponse other) {
        if (other == ds.hdfs.HdfsProto.ReadBlockResponse.getDefaultInstance()) return this;
        if (other.hasData()) {
          setData(other.getData());
        }
        if (other.hasStatus()) {
          setStatus(other.getStatus());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.ReadBlockResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.ReadBlockResponse) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private com.google.protobuf.ByteString data_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes data = 1;</code>
       * @return Whether the data field is set.
       */
      public boolean hasData() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional bytes data = 1;</code>
       * @return The data.
       */
      public com.google.protobuf.ByteString getData() {
        return data_;
      }
      /**
       * <code>optional bytes data = 1;</code>
       * @param value The data to set.
       * @return This builder for chaining.
       */
      public Builder setData(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        data_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes data = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearData() {
        bitField0_ = (bitField0_ & ~0x00000001);
        data_ = getDefaultInstance().getData();
        onChanged();
        return this;
      }

      private int status_ = -1;
      /**
       * <pre>
       *On error, negative number is returned.
       * </pre>
       *
       * <code>optional int32 status = 2 [default = -1];</code>
       * @return Whether the status field is set.
       */
      public boolean hasStatus() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       *On error, negative number is returned.
       * </pre>
       *
       * <code>optional int32 status = 2 [default = -1];</code>
       * @return The status.
       */
      public int getStatus() {
        return status_;
      }
      /**
       * <pre>
       *On error, negative number is returned.
       * </pre>
       *
       * <code>optional int32 status = 2 [default = -1];</code>
       * @param value The status to set.
       * @return This builder for chaining.
       */
      public Builder setStatus(int value) {
        bitField0_ |= 0x00000002;
        status_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *On error, negative number is returned.
       * </pre>
       *
       * <code>optional int32 status = 2 [default = -1];</code>
       * @return This builder for chaining.
       */
      public Builder clearStatus() {
        bitField0_ = (bitField0_ & ~0x00000002);
        status_ = -1;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.ReadBlockResponse)
    }

    // @@protoc_insertion_point(class_scope:hdfs.ReadBlockResponse)
    private static final ds.hdfs.HdfsProto.ReadBlockResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.ReadBlockResponse();
    }

    public static ds.hdfs.HdfsProto.ReadBlockResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReadBlockResponse>
        PARSER = new com.google.protobuf.AbstractParser<ReadBlockResponse>() {
      @java.lang.Override
      public ReadBlockResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ReadBlockResponse(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReadBlockResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReadBlockResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.ReadBlockResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface WriteBlockRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.WriteBlockRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required int32 blocknumber = 1;</code>
     * @return Whether the blocknumber field is set.
     */
    boolean hasBlocknumber();
    /**
     * <code>required int32 blocknumber = 1;</code>
     * @return The blocknumber.
     */
    int getBlocknumber();

    /**
     * <code>optional bytes data = 2;</code>
     * @return Whether the data field is set.
     */
    boolean hasData();
    /**
     * <code>optional bytes data = 2;</code>
     * @return The data.
     */
    com.google.protobuf.ByteString getData();

    /**
     * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
     */
    java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> 
        getReplicatedDatanodeList();
    /**
     * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
     */
    ds.hdfs.HdfsProto.DataNodeInfo getReplicatedDatanode(int index);
    /**
     * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
     */
    int getReplicatedDatanodeCount();
    /**
     * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
     */
    java.util.List<? extends ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
        getReplicatedDatanodeOrBuilderList();
    /**
     * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
     */
    ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getReplicatedDatanodeOrBuilder(
        int index);
  }
  /**
   * <pre>
   *message to write data to a block
   *In this project the replication factor is 2 for Replication Pipelining
   * </pre>
   *
   * Protobuf type {@code hdfs.WriteBlockRequest}
   */
  public  static final class WriteBlockRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.WriteBlockRequest)
      WriteBlockRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use WriteBlockRequest.newBuilder() to construct.
    private WriteBlockRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private WriteBlockRequest() {
      data_ = com.google.protobuf.ByteString.EMPTY;
      replicatedDatanode_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new WriteBlockRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private WriteBlockRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              blocknumber_ = input.readInt32();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              data_ = input.readBytes();
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) != 0)) {
                replicatedDatanode_ = new java.util.ArrayList<ds.hdfs.HdfsProto.DataNodeInfo>();
                mutable_bitField0_ |= 0x00000004;
              }
              replicatedDatanode_.add(
                  input.readMessage(ds.hdfs.HdfsProto.DataNodeInfo.PARSER, extensionRegistry));
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) != 0)) {
          replicatedDatanode_ = java.util.Collections.unmodifiableList(replicatedDatanode_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_WriteBlockRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_WriteBlockRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.WriteBlockRequest.class, ds.hdfs.HdfsProto.WriteBlockRequest.Builder.class);
    }

    private int bitField0_;
    public static final int BLOCKNUMBER_FIELD_NUMBER = 1;
    private int blocknumber_;
    /**
     * <code>required int32 blocknumber = 1;</code>
     * @return Whether the blocknumber field is set.
     */
    public boolean hasBlocknumber() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required int32 blocknumber = 1;</code>
     * @return The blocknumber.
     */
    public int getBlocknumber() {
      return blocknumber_;
    }

    public static final int DATA_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString data_;
    /**
     * <code>optional bytes data = 2;</code>
     * @return Whether the data field is set.
     */
    public boolean hasData() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bytes data = 2;</code>
     * @return The data.
     */
    public com.google.protobuf.ByteString getData() {
      return data_;
    }

    public static final int REPLICATEDDATANODE_FIELD_NUMBER = 3;
    private java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> replicatedDatanode_;
    /**
     * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
     */
    public java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> getReplicatedDatanodeList() {
      return replicatedDatanode_;
    }
    /**
     * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
     */
    public java.util.List<? extends ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
        getReplicatedDatanodeOrBuilderList() {
      return replicatedDatanode_;
    }
    /**
     * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
     */
    public int getReplicatedDatanodeCount() {
      return replicatedDatanode_.size();
    }
    /**
     * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
     */
    public ds.hdfs.HdfsProto.DataNodeInfo getReplicatedDatanode(int index) {
      return replicatedDatanode_.get(index);
    }
    /**
     * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
     */
    public ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getReplicatedDatanodeOrBuilder(
        int index) {
      return replicatedDatanode_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasBlocknumber()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(1, blocknumber_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(2, data_);
      }
      for (int i = 0; i < replicatedDatanode_.size(); i++) {
        output.writeMessage(3, replicatedDatanode_.get(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, blocknumber_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, data_);
      }
      for (int i = 0; i < replicatedDatanode_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, replicatedDatanode_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.WriteBlockRequest)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.WriteBlockRequest other = (ds.hdfs.HdfsProto.WriteBlockRequest) obj;

      if (hasBlocknumber() != other.hasBlocknumber()) return false;
      if (hasBlocknumber()) {
        if (getBlocknumber()
            != other.getBlocknumber()) return false;
      }
      if (hasData() != other.hasData()) return false;
      if (hasData()) {
        if (!getData()
            .equals(other.getData())) return false;
      }
      if (!getReplicatedDatanodeList()
          .equals(other.getReplicatedDatanodeList())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasBlocknumber()) {
        hash = (37 * hash) + BLOCKNUMBER_FIELD_NUMBER;
        hash = (53 * hash) + getBlocknumber();
      }
      if (hasData()) {
        hash = (37 * hash) + DATA_FIELD_NUMBER;
        hash = (53 * hash) + getData().hashCode();
      }
      if (getReplicatedDatanodeCount() > 0) {
        hash = (37 * hash) + REPLICATEDDATANODE_FIELD_NUMBER;
        hash = (53 * hash) + getReplicatedDatanodeList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.WriteBlockRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.WriteBlockRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.WriteBlockRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.WriteBlockRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.WriteBlockRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.WriteBlockRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.WriteBlockRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.WriteBlockRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.WriteBlockRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.WriteBlockRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.WriteBlockRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.WriteBlockRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.WriteBlockRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *message to write data to a block
     *In this project the replication factor is 2 for Replication Pipelining
     * </pre>
     *
     * Protobuf type {@code hdfs.WriteBlockRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.WriteBlockRequest)
        ds.hdfs.HdfsProto.WriteBlockRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_WriteBlockRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_WriteBlockRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.WriteBlockRequest.class, ds.hdfs.HdfsProto.WriteBlockRequest.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.WriteBlockRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getReplicatedDatanodeFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        blocknumber_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        data_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (replicatedDatanodeBuilder_ == null) {
          replicatedDatanode_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          replicatedDatanodeBuilder_.clear();
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_WriteBlockRequest_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.WriteBlockRequest getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.WriteBlockRequest.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.WriteBlockRequest build() {
        ds.hdfs.HdfsProto.WriteBlockRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.WriteBlockRequest buildPartial() {
        ds.hdfs.HdfsProto.WriteBlockRequest result = new ds.hdfs.HdfsProto.WriteBlockRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.blocknumber_ = blocknumber_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          to_bitField0_ |= 0x00000002;
        }
        result.data_ = data_;
        if (replicatedDatanodeBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)) {
            replicatedDatanode_ = java.util.Collections.unmodifiableList(replicatedDatanode_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.replicatedDatanode_ = replicatedDatanode_;
        } else {
          result.replicatedDatanode_ = replicatedDatanodeBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.WriteBlockRequest) {
          return mergeFrom((ds.hdfs.HdfsProto.WriteBlockRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.WriteBlockRequest other) {
        if (other == ds.hdfs.HdfsProto.WriteBlockRequest.getDefaultInstance()) return this;
        if (other.hasBlocknumber()) {
          setBlocknumber(other.getBlocknumber());
        }
        if (other.hasData()) {
          setData(other.getData());
        }
        if (replicatedDatanodeBuilder_ == null) {
          if (!other.replicatedDatanode_.isEmpty()) {
            if (replicatedDatanode_.isEmpty()) {
              replicatedDatanode_ = other.replicatedDatanode_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureReplicatedDatanodeIsMutable();
              replicatedDatanode_.addAll(other.replicatedDatanode_);
            }
            onChanged();
          }
        } else {
          if (!other.replicatedDatanode_.isEmpty()) {
            if (replicatedDatanodeBuilder_.isEmpty()) {
              replicatedDatanodeBuilder_.dispose();
              replicatedDatanodeBuilder_ = null;
              replicatedDatanode_ = other.replicatedDatanode_;
              bitField0_ = (bitField0_ & ~0x00000004);
              replicatedDatanodeBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getReplicatedDatanodeFieldBuilder() : null;
            } else {
              replicatedDatanodeBuilder_.addAllMessages(other.replicatedDatanode_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasBlocknumber()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.WriteBlockRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.WriteBlockRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int blocknumber_ ;
      /**
       * <code>required int32 blocknumber = 1;</code>
       * @return Whether the blocknumber field is set.
       */
      public boolean hasBlocknumber() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required int32 blocknumber = 1;</code>
       * @return The blocknumber.
       */
      public int getBlocknumber() {
        return blocknumber_;
      }
      /**
       * <code>required int32 blocknumber = 1;</code>
       * @param value The blocknumber to set.
       * @return This builder for chaining.
       */
      public Builder setBlocknumber(int value) {
        bitField0_ |= 0x00000001;
        blocknumber_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required int32 blocknumber = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearBlocknumber() {
        bitField0_ = (bitField0_ & ~0x00000001);
        blocknumber_ = 0;
        onChanged();
        return this;
      }

      private com.google.protobuf.ByteString data_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes data = 2;</code>
       * @return Whether the data field is set.
       */
      public boolean hasData() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bytes data = 2;</code>
       * @return The data.
       */
      public com.google.protobuf.ByteString getData() {
        return data_;
      }
      /**
       * <code>optional bytes data = 2;</code>
       * @param value The data to set.
       * @return This builder for chaining.
       */
      public Builder setData(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        data_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes data = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearData() {
        bitField0_ = (bitField0_ & ~0x00000002);
        data_ = getDefaultInstance().getData();
        onChanged();
        return this;
      }

      private java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> replicatedDatanode_ =
        java.util.Collections.emptyList();
      private void ensureReplicatedDatanodeIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          replicatedDatanode_ = new java.util.ArrayList<ds.hdfs.HdfsProto.DataNodeInfo>(replicatedDatanode_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> replicatedDatanodeBuilder_;

      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public java.util.List<ds.hdfs.HdfsProto.DataNodeInfo> getReplicatedDatanodeList() {
        if (replicatedDatanodeBuilder_ == null) {
          return java.util.Collections.unmodifiableList(replicatedDatanode_);
        } else {
          return replicatedDatanodeBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public int getReplicatedDatanodeCount() {
        if (replicatedDatanodeBuilder_ == null) {
          return replicatedDatanode_.size();
        } else {
          return replicatedDatanodeBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfo getReplicatedDatanode(int index) {
        if (replicatedDatanodeBuilder_ == null) {
          return replicatedDatanode_.get(index);
        } else {
          return replicatedDatanodeBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public Builder setReplicatedDatanode(
          int index, ds.hdfs.HdfsProto.DataNodeInfo value) {
        if (replicatedDatanodeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReplicatedDatanodeIsMutable();
          replicatedDatanode_.set(index, value);
          onChanged();
        } else {
          replicatedDatanodeBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public Builder setReplicatedDatanode(
          int index, ds.hdfs.HdfsProto.DataNodeInfo.Builder builderForValue) {
        if (replicatedDatanodeBuilder_ == null) {
          ensureReplicatedDatanodeIsMutable();
          replicatedDatanode_.set(index, builderForValue.build());
          onChanged();
        } else {
          replicatedDatanodeBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public Builder addReplicatedDatanode(ds.hdfs.HdfsProto.DataNodeInfo value) {
        if (replicatedDatanodeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReplicatedDatanodeIsMutable();
          replicatedDatanode_.add(value);
          onChanged();
        } else {
          replicatedDatanodeBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public Builder addReplicatedDatanode(
          int index, ds.hdfs.HdfsProto.DataNodeInfo value) {
        if (replicatedDatanodeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReplicatedDatanodeIsMutable();
          replicatedDatanode_.add(index, value);
          onChanged();
        } else {
          replicatedDatanodeBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public Builder addReplicatedDatanode(
          ds.hdfs.HdfsProto.DataNodeInfo.Builder builderForValue) {
        if (replicatedDatanodeBuilder_ == null) {
          ensureReplicatedDatanodeIsMutable();
          replicatedDatanode_.add(builderForValue.build());
          onChanged();
        } else {
          replicatedDatanodeBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public Builder addReplicatedDatanode(
          int index, ds.hdfs.HdfsProto.DataNodeInfo.Builder builderForValue) {
        if (replicatedDatanodeBuilder_ == null) {
          ensureReplicatedDatanodeIsMutable();
          replicatedDatanode_.add(index, builderForValue.build());
          onChanged();
        } else {
          replicatedDatanodeBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public Builder addAllReplicatedDatanode(
          java.lang.Iterable<? extends ds.hdfs.HdfsProto.DataNodeInfo> values) {
        if (replicatedDatanodeBuilder_ == null) {
          ensureReplicatedDatanodeIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, replicatedDatanode_);
          onChanged();
        } else {
          replicatedDatanodeBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public Builder clearReplicatedDatanode() {
        if (replicatedDatanodeBuilder_ == null) {
          replicatedDatanode_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          replicatedDatanodeBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public Builder removeReplicatedDatanode(int index) {
        if (replicatedDatanodeBuilder_ == null) {
          ensureReplicatedDatanodeIsMutable();
          replicatedDatanode_.remove(index);
          onChanged();
        } else {
          replicatedDatanodeBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfo.Builder getReplicatedDatanodeBuilder(
          int index) {
        return getReplicatedDatanodeFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfoOrBuilder getReplicatedDatanodeOrBuilder(
          int index) {
        if (replicatedDatanodeBuilder_ == null) {
          return replicatedDatanode_.get(index);  } else {
          return replicatedDatanodeBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public java.util.List<? extends ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
           getReplicatedDatanodeOrBuilderList() {
        if (replicatedDatanodeBuilder_ != null) {
          return replicatedDatanodeBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(replicatedDatanode_);
        }
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfo.Builder addReplicatedDatanodeBuilder() {
        return getReplicatedDatanodeFieldBuilder().addBuilder(
            ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public ds.hdfs.HdfsProto.DataNodeInfo.Builder addReplicatedDatanodeBuilder(
          int index) {
        return getReplicatedDatanodeFieldBuilder().addBuilder(
            index, ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hdfs.DataNodeInfo replicatedDatanode = 3;</code>
       */
      public java.util.List<ds.hdfs.HdfsProto.DataNodeInfo.Builder> 
           getReplicatedDatanodeBuilderList() {
        return getReplicatedDatanodeFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder> 
          getReplicatedDatanodeFieldBuilder() {
        if (replicatedDatanodeBuilder_ == null) {
          replicatedDatanodeBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              ds.hdfs.HdfsProto.DataNodeInfo, ds.hdfs.HdfsProto.DataNodeInfo.Builder, ds.hdfs.HdfsProto.DataNodeInfoOrBuilder>(
                  replicatedDatanode_,
                  ((bitField0_ & 0x00000004) != 0),
                  getParentForChildren(),
                  isClean());
          replicatedDatanode_ = null;
        }
        return replicatedDatanodeBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.WriteBlockRequest)
    }

    // @@protoc_insertion_point(class_scope:hdfs.WriteBlockRequest)
    private static final ds.hdfs.HdfsProto.WriteBlockRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.WriteBlockRequest();
    }

    public static ds.hdfs.HdfsProto.WriteBlockRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<WriteBlockRequest>
        PARSER = new com.google.protobuf.AbstractParser<WriteBlockRequest>() {
      @java.lang.Override
      public WriteBlockRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new WriteBlockRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<WriteBlockRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<WriteBlockRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.WriteBlockRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface WriteBlockResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.WriteBlockResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int32 Status = 1 [default = -1];</code>
     * @return Whether the status field is set.
     */
    boolean hasStatus();
    /**
     * <code>optional int32 Status = 1 [default = -1];</code>
     * @return The status.
     */
    int getStatus();
  }
  /**
   * Protobuf type {@code hdfs.WriteBlockResponse}
   */
  public  static final class WriteBlockResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.WriteBlockResponse)
      WriteBlockResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use WriteBlockResponse.newBuilder() to construct.
    private WriteBlockResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private WriteBlockResponse() {
      status_ = -1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new WriteBlockResponse();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private WriteBlockResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              status_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_WriteBlockResponse_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_WriteBlockResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.WriteBlockResponse.class, ds.hdfs.HdfsProto.WriteBlockResponse.Builder.class);
    }

    private int bitField0_;
    public static final int STATUS_FIELD_NUMBER = 1;
    private int status_;
    /**
     * <code>optional int32 Status = 1 [default = -1];</code>
     * @return Whether the status field is set.
     */
    public boolean hasStatus() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional int32 Status = 1 [default = -1];</code>
     * @return The status.
     */
    public int getStatus() {
      return status_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(1, status_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, status_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.WriteBlockResponse)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.WriteBlockResponse other = (ds.hdfs.HdfsProto.WriteBlockResponse) obj;

      if (hasStatus() != other.hasStatus()) return false;
      if (hasStatus()) {
        if (getStatus()
            != other.getStatus()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasStatus()) {
        hash = (37 * hash) + STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getStatus();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.WriteBlockResponse parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.WriteBlockResponse parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.WriteBlockResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.WriteBlockResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.WriteBlockResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.WriteBlockResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.WriteBlockResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.WriteBlockResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.WriteBlockResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.WriteBlockResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.WriteBlockResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.WriteBlockResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.WriteBlockResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hdfs.WriteBlockResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.WriteBlockResponse)
        ds.hdfs.HdfsProto.WriteBlockResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_WriteBlockResponse_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_WriteBlockResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.WriteBlockResponse.class, ds.hdfs.HdfsProto.WriteBlockResponse.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.WriteBlockResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        status_ = -1;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_WriteBlockResponse_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.WriteBlockResponse getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.WriteBlockResponse.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.WriteBlockResponse build() {
        ds.hdfs.HdfsProto.WriteBlockResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.WriteBlockResponse buildPartial() {
        ds.hdfs.HdfsProto.WriteBlockResponse result = new ds.hdfs.HdfsProto.WriteBlockResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.status_ = status_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.WriteBlockResponse) {
          return mergeFrom((ds.hdfs.HdfsProto.WriteBlockResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.WriteBlockResponse other) {
        if (other == ds.hdfs.HdfsProto.WriteBlockResponse.getDefaultInstance()) return this;
        if (other.hasStatus()) {
          setStatus(other.getStatus());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.WriteBlockResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.WriteBlockResponse) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int status_ = -1;
      /**
       * <code>optional int32 Status = 1 [default = -1];</code>
       * @return Whether the status field is set.
       */
      public boolean hasStatus() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional int32 Status = 1 [default = -1];</code>
       * @return The status.
       */
      public int getStatus() {
        return status_;
      }
      /**
       * <code>optional int32 Status = 1 [default = -1];</code>
       * @param value The status to set.
       * @return This builder for chaining.
       */
      public Builder setStatus(int value) {
        bitField0_ |= 0x00000001;
        status_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 Status = 1 [default = -1];</code>
       * @return This builder for chaining.
       */
      public Builder clearStatus() {
        bitField0_ = (bitField0_ & ~0x00000001);
        status_ = -1;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.WriteBlockResponse)
    }

    // @@protoc_insertion_point(class_scope:hdfs.WriteBlockResponse)
    private static final ds.hdfs.HdfsProto.WriteBlockResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.WriteBlockResponse();
    }

    public static ds.hdfs.HdfsProto.WriteBlockResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<WriteBlockResponse>
        PARSER = new com.google.protobuf.AbstractParser<WriteBlockResponse>() {
      @java.lang.Override
      public WriteBlockResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new WriteBlockResponse(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<WriteBlockResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<WriteBlockResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.WriteBlockResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DataNodeInfoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hdfs.DataNodeInfo)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string servername = 1;</code>
     * @return Whether the servername field is set.
     */
    boolean hasServername();
    /**
     * <code>optional string servername = 1;</code>
     * @return The servername.
     */
    java.lang.String getServername();
    /**
     * <code>optional string servername = 1;</code>
     * @return The bytes for servername.
     */
    com.google.protobuf.ByteString
        getServernameBytes();

    /**
     * <code>optional string ipaddr = 2;</code>
     * @return Whether the ipaddr field is set.
     */
    boolean hasIpaddr();
    /**
     * <code>optional string ipaddr = 2;</code>
     * @return The ipaddr.
     */
    java.lang.String getIpaddr();
    /**
     * <code>optional string ipaddr = 2;</code>
     * @return The bytes for ipaddr.
     */
    com.google.protobuf.ByteString
        getIpaddrBytes();

    /**
     * <code>optional int32 portnum = 3;</code>
     * @return Whether the portnum field is set.
     */
    boolean hasPortnum();
    /**
     * <code>optional int32 portnum = 3;</code>
     * @return The portnum.
     */
    int getPortnum();
  }
  /**
   * <pre>
   *message for DataNode: id(server name), ip addr, port
   * </pre>
   *
   * Protobuf type {@code hdfs.DataNodeInfo}
   */
  public  static final class DataNodeInfo extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hdfs.DataNodeInfo)
      DataNodeInfoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DataNodeInfo.newBuilder() to construct.
    private DataNodeInfo(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DataNodeInfo() {
      servername_ = "";
      ipaddr_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DataNodeInfo();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DataNodeInfo(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              servername_ = bs;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              ipaddr_ = bs;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              portnum_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_DataNodeInfo_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ds.hdfs.HdfsProto.internal_static_hdfs_DataNodeInfo_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ds.hdfs.HdfsProto.DataNodeInfo.class, ds.hdfs.HdfsProto.DataNodeInfo.Builder.class);
    }

    private int bitField0_;
    public static final int SERVERNAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object servername_;
    /**
     * <code>optional string servername = 1;</code>
     * @return Whether the servername field is set.
     */
    public boolean hasServername() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional string servername = 1;</code>
     * @return The servername.
     */
    public java.lang.String getServername() {
      java.lang.Object ref = servername_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          servername_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string servername = 1;</code>
     * @return The bytes for servername.
     */
    public com.google.protobuf.ByteString
        getServernameBytes() {
      java.lang.Object ref = servername_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        servername_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int IPADDR_FIELD_NUMBER = 2;
    private volatile java.lang.Object ipaddr_;
    /**
     * <code>optional string ipaddr = 2;</code>
     * @return Whether the ipaddr field is set.
     */
    public boolean hasIpaddr() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional string ipaddr = 2;</code>
     * @return The ipaddr.
     */
    public java.lang.String getIpaddr() {
      java.lang.Object ref = ipaddr_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          ipaddr_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string ipaddr = 2;</code>
     * @return The bytes for ipaddr.
     */
    public com.google.protobuf.ByteString
        getIpaddrBytes() {
      java.lang.Object ref = ipaddr_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        ipaddr_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int PORTNUM_FIELD_NUMBER = 3;
    private int portnum_;
    /**
     * <code>optional int32 portnum = 3;</code>
     * @return Whether the portnum field is set.
     */
    public boolean hasPortnum() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional int32 portnum = 3;</code>
     * @return The portnum.
     */
    public int getPortnum() {
      return portnum_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, servername_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, ipaddr_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeInt32(3, portnum_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, servername_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, ipaddr_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, portnum_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ds.hdfs.HdfsProto.DataNodeInfo)) {
        return super.equals(obj);
      }
      ds.hdfs.HdfsProto.DataNodeInfo other = (ds.hdfs.HdfsProto.DataNodeInfo) obj;

      if (hasServername() != other.hasServername()) return false;
      if (hasServername()) {
        if (!getServername()
            .equals(other.getServername())) return false;
      }
      if (hasIpaddr() != other.hasIpaddr()) return false;
      if (hasIpaddr()) {
        if (!getIpaddr()
            .equals(other.getIpaddr())) return false;
      }
      if (hasPortnum() != other.hasPortnum()) return false;
      if (hasPortnum()) {
        if (getPortnum()
            != other.getPortnum()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasServername()) {
        hash = (37 * hash) + SERVERNAME_FIELD_NUMBER;
        hash = (53 * hash) + getServername().hashCode();
      }
      if (hasIpaddr()) {
        hash = (37 * hash) + IPADDR_FIELD_NUMBER;
        hash = (53 * hash) + getIpaddr().hashCode();
      }
      if (hasPortnum()) {
        hash = (37 * hash) + PORTNUM_FIELD_NUMBER;
        hash = (53 * hash) + getPortnum();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ds.hdfs.HdfsProto.DataNodeInfo parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.DataNodeInfo parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.DataNodeInfo parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.DataNodeInfo parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.DataNodeInfo parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ds.hdfs.HdfsProto.DataNodeInfo parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.DataNodeInfo parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.DataNodeInfo parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.DataNodeInfo parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.DataNodeInfo parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ds.hdfs.HdfsProto.DataNodeInfo parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ds.hdfs.HdfsProto.DataNodeInfo parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ds.hdfs.HdfsProto.DataNodeInfo prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *message for DataNode: id(server name), ip addr, port
     * </pre>
     *
     * Protobuf type {@code hdfs.DataNodeInfo}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hdfs.DataNodeInfo)
        ds.hdfs.HdfsProto.DataNodeInfoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_DataNodeInfo_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_DataNodeInfo_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ds.hdfs.HdfsProto.DataNodeInfo.class, ds.hdfs.HdfsProto.DataNodeInfo.Builder.class);
      }

      // Construct using ds.hdfs.HdfsProto.DataNodeInfo.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        servername_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        ipaddr_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        portnum_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ds.hdfs.HdfsProto.internal_static_hdfs_DataNodeInfo_descriptor;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.DataNodeInfo getDefaultInstanceForType() {
        return ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance();
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.DataNodeInfo build() {
        ds.hdfs.HdfsProto.DataNodeInfo result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public ds.hdfs.HdfsProto.DataNodeInfo buildPartial() {
        ds.hdfs.HdfsProto.DataNodeInfo result = new ds.hdfs.HdfsProto.DataNodeInfo(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.servername_ = servername_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          to_bitField0_ |= 0x00000002;
        }
        result.ipaddr_ = ipaddr_;
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.portnum_ = portnum_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ds.hdfs.HdfsProto.DataNodeInfo) {
          return mergeFrom((ds.hdfs.HdfsProto.DataNodeInfo)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ds.hdfs.HdfsProto.DataNodeInfo other) {
        if (other == ds.hdfs.HdfsProto.DataNodeInfo.getDefaultInstance()) return this;
        if (other.hasServername()) {
          bitField0_ |= 0x00000001;
          servername_ = other.servername_;
          onChanged();
        }
        if (other.hasIpaddr()) {
          bitField0_ |= 0x00000002;
          ipaddr_ = other.ipaddr_;
          onChanged();
        }
        if (other.hasPortnum()) {
          setPortnum(other.getPortnum());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ds.hdfs.HdfsProto.DataNodeInfo parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ds.hdfs.HdfsProto.DataNodeInfo) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object servername_ = "";
      /**
       * <code>optional string servername = 1;</code>
       * @return Whether the servername field is set.
       */
      public boolean hasServername() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional string servername = 1;</code>
       * @return The servername.
       */
      public java.lang.String getServername() {
        java.lang.Object ref = servername_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            servername_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string servername = 1;</code>
       * @return The bytes for servername.
       */
      public com.google.protobuf.ByteString
          getServernameBytes() {
        java.lang.Object ref = servername_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          servername_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string servername = 1;</code>
       * @param value The servername to set.
       * @return This builder for chaining.
       */
      public Builder setServername(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        servername_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string servername = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearServername() {
        bitField0_ = (bitField0_ & ~0x00000001);
        servername_ = getDefaultInstance().getServername();
        onChanged();
        return this;
      }
      /**
       * <code>optional string servername = 1;</code>
       * @param value The bytes for servername to set.
       * @return This builder for chaining.
       */
      public Builder setServernameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        servername_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object ipaddr_ = "";
      /**
       * <code>optional string ipaddr = 2;</code>
       * @return Whether the ipaddr field is set.
       */
      public boolean hasIpaddr() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional string ipaddr = 2;</code>
       * @return The ipaddr.
       */
      public java.lang.String getIpaddr() {
        java.lang.Object ref = ipaddr_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            ipaddr_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string ipaddr = 2;</code>
       * @return The bytes for ipaddr.
       */
      public com.google.protobuf.ByteString
          getIpaddrBytes() {
        java.lang.Object ref = ipaddr_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          ipaddr_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string ipaddr = 2;</code>
       * @param value The ipaddr to set.
       * @return This builder for chaining.
       */
      public Builder setIpaddr(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        ipaddr_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string ipaddr = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearIpaddr() {
        bitField0_ = (bitField0_ & ~0x00000002);
        ipaddr_ = getDefaultInstance().getIpaddr();
        onChanged();
        return this;
      }
      /**
       * <code>optional string ipaddr = 2;</code>
       * @param value The bytes for ipaddr to set.
       * @return This builder for chaining.
       */
      public Builder setIpaddrBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        ipaddr_ = value;
        onChanged();
        return this;
      }

      private int portnum_ ;
      /**
       * <code>optional int32 portnum = 3;</code>
       * @return Whether the portnum field is set.
       */
      public boolean hasPortnum() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional int32 portnum = 3;</code>
       * @return The portnum.
       */
      public int getPortnum() {
        return portnum_;
      }
      /**
       * <code>optional int32 portnum = 3;</code>
       * @param value The portnum to set.
       * @return This builder for chaining.
       */
      public Builder setPortnum(int value) {
        bitField0_ |= 0x00000004;
        portnum_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 portnum = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearPortnum() {
        bitField0_ = (bitField0_ & ~0x00000004);
        portnum_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hdfs.DataNodeInfo)
    }

    // @@protoc_insertion_point(class_scope:hdfs.DataNodeInfo)
    private static final ds.hdfs.HdfsProto.DataNodeInfo DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ds.hdfs.HdfsProto.DataNodeInfo();
    }

    public static ds.hdfs.HdfsProto.DataNodeInfo getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<DataNodeInfo>
        PARSER = new com.google.protobuf.AbstractParser<DataNodeInfo>() {
      @java.lang.Override
      public DataNodeInfo parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DataNodeInfo(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DataNodeInfo> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DataNodeInfo> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public ds.hdfs.HdfsProto.DataNodeInfo getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_OpenFileRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_OpenFileRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_OpenFileResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_OpenFileResponse_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_CloseFileRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_CloseFileRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_CloseFileResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_CloseFileResponse_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_AssignBlockRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_AssignBlockRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_AssignBlockResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_AssignBlockResponse_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_ListFileRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_ListFileRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_ListFileResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_ListFileResponse_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_BlockLocationsRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_BlockLocationsRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_BlockLocationsResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_BlockLocationsResponse_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_BlockReportRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_BlockReportRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_BlockReportResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_BlockReportResponse_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_HeartBeatRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_HeartBeatRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_HeartBeatResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_HeartBeatResponse_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_FileInfoInNameNode_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_FileInfoInNameNode_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_FileInfoInNameNode_Block_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_FileInfoInNameNode_Block_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_FileListInNameNode_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_FileListInNameNode_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_BlocksInDataNode_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_BlocksInDataNode_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_BlocksInDataNode_Block_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_BlocksInDataNode_Block_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_ReadBlockRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_ReadBlockRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_ReadBlockResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_ReadBlockResponse_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_WriteBlockRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_WriteBlockRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_WriteBlockResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_WriteBlockResponse_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hdfs_DataNodeInfo_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hdfs_DataNodeInfo_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\nhdfs.proto\022\004hdfs\"\207\001\n\017OpenFileRequest\022\020" +
      "\n\010filename\030\001 \002(\t\0222\n\004flag\030\002 \001(\0162\032.hdfs.Op" +
      "enFileRequest.Flag:\010O_RDONLY\".\n\004Flag\022\014\n\010" +
      "O_RDONLY\020\000\022\014\n\010O_WRONLY\020\001\022\n\n\006O_RDWR\020\002\"C\n\020" +
      "OpenFileResponse\022\032\n\016filedescriptor\030\001 \002(\005" +
      ":\002-1\022\023\n\013blocknumber\030\002 \003(\005\"*\n\020CloseFileRe" +
      "quest\022\026\n\016filedescriptor\030\001 \001(\005\"\'\n\021CloseFi" +
      "leResponse\022\022\n\006status\030\001 \001(\005:\002-1\",\n\022Assign" +
      "BlockRequest\022\026\n\016filedescriptor\030\001 \001(\005\"d\n\023" +
      "AssignBlockResponse\022\023\n\013blocknumber\030\001 \001(\005" +
      "\022$\n\010datanode\030\002 \003(\0132\022.hdfs.DataNodeInfo\022\022" +
      "\n\006status\030\003 \001(\005:\002-1\"\036\n\017ListFileRequest\022\013\n" +
      "\003dir\030\001 \001(\t\"8\n\020ListFileResponse\022\020\n\010filena" +
      "me\030\001 \003(\t\022\022\n\006status\030\002 \001(\005:\002-1\",\n\025BlockLoc" +
      "ationsRequest\022\023\n\013blocknumber\030\001 \001(\005\"R\n\026Bl" +
      "ockLocationsResponse\022$\n\010datanode\030\001 \003(\0132\022" +
      ".hdfs.DataNodeInfo\022\022\n\006status\030\002 \001(\005:\002-1\"J" +
      "\n\022BlockReportRequest\022\016\n\006blocks\030\001 \003(\005\022$\n\010" +
      "datanode\030\002 \002(\0132\022.hdfs.DataNodeInfo\")\n\023Bl" +
      "ockReportResponse\022\022\n\006status\030\001 \001(\005:\002-1\"8\n" +
      "\020HeartBeatRequest\022$\n\010datanode\030\001 \001(\0132\022.hd" +
      "fs.DataNodeInfo\"\'\n\021HeartBeatResponse\022\022\n\006" +
      "status\030\001 \001(\005:\002-1\"\254\001\n\022FileInfoInNameNode\022" +
      "\020\n\010filename\030\001 \002(\t\022-\n\005block\030\002 \003(\0132\036.hdfs." +
      "FileInfoInNameNode.Block\022\021\n\twritemode\030\003 " +
      "\001(\010\032B\n\005Block\022\023\n\013blocknumber\030\001 \002(\005\022$\n\010dat" +
      "anode\030\002 \003(\0132\022.hdfs.DataNodeInfo\"<\n\022FileL" +
      "istInNameNode\022&\n\004file\030\001 \003(\0132\030.hdfs.FileI" +
      "nfoInNameNode\"k\n\020BlocksInDataNode\022+\n\005blo" +
      "ck\030\001 \003(\0132\034.hdfs.BlocksInDataNode.Block\032*" +
      "\n\005Block\022\023\n\013blocknumber\030\001 \002(\005\022\014\n\004path\030\002 \001" +
      "(\t\"\'\n\020ReadBlockRequest\022\023\n\013blocknumber\030\001 " +
      "\002(\005\"5\n\021ReadBlockResponse\022\014\n\004data\030\001 \001(\014\022\022" +
      "\n\006status\030\002 \001(\005:\002-1\"f\n\021WriteBlockRequest\022" +
      "\023\n\013blocknumber\030\001 \002(\005\022\014\n\004data\030\002 \001(\014\022.\n\022re" +
      "plicatedDatanode\030\003 \003(\0132\022.hdfs.DataNodeIn" +
      "fo\"(\n\022WriteBlockResponse\022\022\n\006Status\030\001 \001(\005" +
      ":\002-1\"C\n\014DataNodeInfo\022\022\n\nservername\030\001 \001(\t" +
      "\022\016\n\006ipaddr\030\002 \001(\t\022\017\n\007portnum\030\003 \001(\005B\024\n\007ds." +
      "hdfsB\tHdfsProto"
    };
    descriptor = com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
        });
    internal_static_hdfs_OpenFileRequest_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_hdfs_OpenFileRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_OpenFileRequest_descriptor,
        new java.lang.String[] { "Filename", "Flag", });
    internal_static_hdfs_OpenFileResponse_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_hdfs_OpenFileResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_OpenFileResponse_descriptor,
        new java.lang.String[] { "Filedescriptor", "Blocknumber", });
    internal_static_hdfs_CloseFileRequest_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_hdfs_CloseFileRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_CloseFileRequest_descriptor,
        new java.lang.String[] { "Filedescriptor", });
    internal_static_hdfs_CloseFileResponse_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_hdfs_CloseFileResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_CloseFileResponse_descriptor,
        new java.lang.String[] { "Status", });
    internal_static_hdfs_AssignBlockRequest_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_hdfs_AssignBlockRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_AssignBlockRequest_descriptor,
        new java.lang.String[] { "Filedescriptor", });
    internal_static_hdfs_AssignBlockResponse_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_hdfs_AssignBlockResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_AssignBlockResponse_descriptor,
        new java.lang.String[] { "Blocknumber", "Datanode", "Status", });
    internal_static_hdfs_ListFileRequest_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_hdfs_ListFileRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_ListFileRequest_descriptor,
        new java.lang.String[] { "Dir", });
    internal_static_hdfs_ListFileResponse_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_hdfs_ListFileResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_ListFileResponse_descriptor,
        new java.lang.String[] { "Filename", "Status", });
    internal_static_hdfs_BlockLocationsRequest_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_hdfs_BlockLocationsRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_BlockLocationsRequest_descriptor,
        new java.lang.String[] { "Blocknumber", });
    internal_static_hdfs_BlockLocationsResponse_descriptor =
      getDescriptor().getMessageTypes().get(9);
    internal_static_hdfs_BlockLocationsResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_BlockLocationsResponse_descriptor,
        new java.lang.String[] { "Datanode", "Status", });
    internal_static_hdfs_BlockReportRequest_descriptor =
      getDescriptor().getMessageTypes().get(10);
    internal_static_hdfs_BlockReportRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_BlockReportRequest_descriptor,
        new java.lang.String[] { "Blocks", "Datanode", });
    internal_static_hdfs_BlockReportResponse_descriptor =
      getDescriptor().getMessageTypes().get(11);
    internal_static_hdfs_BlockReportResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_BlockReportResponse_descriptor,
        new java.lang.String[] { "Status", });
    internal_static_hdfs_HeartBeatRequest_descriptor =
      getDescriptor().getMessageTypes().get(12);
    internal_static_hdfs_HeartBeatRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_HeartBeatRequest_descriptor,
        new java.lang.String[] { "Datanode", });
    internal_static_hdfs_HeartBeatResponse_descriptor =
      getDescriptor().getMessageTypes().get(13);
    internal_static_hdfs_HeartBeatResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_HeartBeatResponse_descriptor,
        new java.lang.String[] { "Status", });
    internal_static_hdfs_FileInfoInNameNode_descriptor =
      getDescriptor().getMessageTypes().get(14);
    internal_static_hdfs_FileInfoInNameNode_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_FileInfoInNameNode_descriptor,
        new java.lang.String[] { "Filename", "Block", "Writemode", });
    internal_static_hdfs_FileInfoInNameNode_Block_descriptor =
      internal_static_hdfs_FileInfoInNameNode_descriptor.getNestedTypes().get(0);
    internal_static_hdfs_FileInfoInNameNode_Block_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_FileInfoInNameNode_Block_descriptor,
        new java.lang.String[] { "Blocknumber", "Datanode", });
    internal_static_hdfs_FileListInNameNode_descriptor =
      getDescriptor().getMessageTypes().get(15);
    internal_static_hdfs_FileListInNameNode_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_FileListInNameNode_descriptor,
        new java.lang.String[] { "File", });
    internal_static_hdfs_BlocksInDataNode_descriptor =
      getDescriptor().getMessageTypes().get(16);
    internal_static_hdfs_BlocksInDataNode_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_BlocksInDataNode_descriptor,
        new java.lang.String[] { "Block", });
    internal_static_hdfs_BlocksInDataNode_Block_descriptor =
      internal_static_hdfs_BlocksInDataNode_descriptor.getNestedTypes().get(0);
    internal_static_hdfs_BlocksInDataNode_Block_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_BlocksInDataNode_Block_descriptor,
        new java.lang.String[] { "Blocknumber", "Path", });
    internal_static_hdfs_ReadBlockRequest_descriptor =
      getDescriptor().getMessageTypes().get(17);
    internal_static_hdfs_ReadBlockRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_ReadBlockRequest_descriptor,
        new java.lang.String[] { "Blocknumber", });
    internal_static_hdfs_ReadBlockResponse_descriptor =
      getDescriptor().getMessageTypes().get(18);
    internal_static_hdfs_ReadBlockResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_ReadBlockResponse_descriptor,
        new java.lang.String[] { "Data", "Status", });
    internal_static_hdfs_WriteBlockRequest_descriptor =
      getDescriptor().getMessageTypes().get(19);
    internal_static_hdfs_WriteBlockRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_WriteBlockRequest_descriptor,
        new java.lang.String[] { "Blocknumber", "Data", "ReplicatedDatanode", });
    internal_static_hdfs_WriteBlockResponse_descriptor =
      getDescriptor().getMessageTypes().get(20);
    internal_static_hdfs_WriteBlockResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_WriteBlockResponse_descriptor,
        new java.lang.String[] { "Status", });
    internal_static_hdfs_DataNodeInfo_descriptor =
      getDescriptor().getMessageTypes().get(21);
    internal_static_hdfs_DataNodeInfo_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hdfs_DataNodeInfo_descriptor,
        new java.lang.String[] { "Servername", "Ipaddr", "Portnum", });
  }

  // @@protoc_insertion_point(outer_class_scope)
}
